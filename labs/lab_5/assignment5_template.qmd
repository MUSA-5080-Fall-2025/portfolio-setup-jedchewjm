---
title: "Assignment 5: Space-Time Prediction of Indego Bike Share Demand"
author: "Jed Chew and Muhammad Al Abbas"
date: 12/1/2025
format:
  html:
    code-fold: show
    code-tools: true
    toc: true
    toc-depth: 3
    toc-location: left
    theme: cosmo
    embed-resources: true
editor: visual
execute:
  warning: false
  message: false
---

# The Rebalancing Challenge in Philadelphia

Philadelphia's Indego bike share system faces the same operational challenge as every bike share system: **rebalancing bikes to meet anticipated demand**.

Imagine you're an Indego operations manager at 6:00 AM on a Monday morning. You have 200 stations across Philadelphia, limited trucks and staff for moving bikes, and 2-3 hours before morning rush hour demand peaks. **Which stations will run out of bikes by 8:30 AM?**

This lab will teach you to build predictive models that forecast bike share demand across **space** (different stations) and **time** (different hours) to help solve this operational problem.

## Learning Objectives

By the end of this assignment, you will be able to:

1.  **Understand panel data structure** for space-time analysis
2.  **Create temporal lag variables** to capture demand persistence
3.  **Build multiple predictive models** with increasing complexity
4.  **Validate models temporally** (train on past, test on future)
5.  **Analyze prediction errors** in both space and time
6.  **Engineer new features** based on error patterns
7.  **Critically evaluate** when prediction errors matter most

```{r setup}
#| message: false
#| warning: false
#| results: 'hide'

library(tidyverse)
library(lubridate)
library(sf)
library(tigris)
library(tidycensus)
library(broom)
library(here)
library(riem)  # For Philadelphia weather from ASOS stations

# Visualization
library(viridis)
library(gridExtra)
library(knitr)
library(kableExtra)
library(gganimate)

options(scipen = 999)
```

```{r themes}
plotTheme <- theme(
  plot.title = element_text(size = 14, face = "bold"),
  plot.subtitle = element_text(size = 10),
  plot.caption = element_text(size = 8),
  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
  axis.text.y = element_text(size = 10),
  axis.title = element_text(size = 11, face = "bold"),
  panel.background = element_blank(),
  panel.grid.major = element_line(colour = "#D0D0D0", size = 0.2),
  panel.grid.minor = element_blank(),
  axis.ticks = element_blank(),
  legend.position = "right"
)

mapTheme <- theme(
  plot.title = element_text(size = 14, face = "bold"),
  plot.subtitle = element_text(size = 10),
  plot.caption = element_text(size = 8),
  axis.line = element_blank(),
  axis.text = element_blank(),
  axis.ticks = element_blank(),
  axis.title = element_blank(),
  panel.background = element_blank(),
  panel.border = element_blank(),
  panel.grid.major = element_line(colour = 'transparent'),
  panel.grid.minor = element_blank(),
  legend.position = "right",
  plot.margin = margin(1, 1, 1, 1, 'cm'),
  legend.key.height = unit(1, "cm"),
  legend.key.width = unit(0.2, "cm")
)

palette5 <- c("#eff3ff", "#bdd7e7", "#6baed6", "#3182bd", "#08519c")
```

```{r census key}
#| include: false

census_api_key("fe841b7ef0aa73d9579f0517bd1c8f26d33c789b")
```

## Part 1: Data Import & Preparation

### 1.1 \| Load Indego Trip Data

**Data Dictionary**

-   **trip_id:** Locally unique integer that identifies the trip
-   **duration:** Length of trip in minutes
-   **start_time & end_time**
-   **start_station; start_lat; start_lon**
-   **end_station; end_lat; end_lon**
-   **bike_id:** Locally unique integer that identifies the bike
-   **plan_duration:** The number of days that the plan the passholder is using entitles them to ride; 0 is used for a single ride plan (Walk-up)
-   **trip_route_category:** “Round Trip” for trips starting and ending at the same station or “One Way” for all other trips
-   **passholder_type:** The name of the passholder’s plan
-   **bike_type:** The kind of bike used on the trip, including standard pedal-powered bikes or electric assist bikes

```{r, include = FALSE}
getwd()
```

```{r load-indego, cache = TRUE}
indego <- read_csv("data/indego-trips-2025-q1.csv")
indego_q2 <- read_csv("data/indego-trips-2025-q2.csv")
indego_q3 <- read_csv("data/indego-trips-2025-q3.csv")
```

```{r, glimpse-indego, include = FALSE}
# Quick look at the data
head(indego)
head(indego_q2)
head(indego_q3)
```

### 1.2 \| Create Time Bins

-   Helper function to create time bins – aggregate trips into hourly intervals for panel data structure

```{r time-bins}
indego <- indego %>%
  mutate(
    # Parse datetime
    start_datetime = mdy_hm(start_time),
    end_datetime = mdy_hm(end_time),
    
    # Create hourly bins
    interval60 = floor_date(start_datetime, unit = "hour"),
    
    # Extract time features
    week = week(interval60),
    month = month(interval60, label = TRUE),
    dotw = wday(interval60, label = TRUE),
    hour = hour(interval60),
    date = as.Date(interval60),
    
    # Create useful indicators
    weekend = ifelse(dotw %in% c("Sat", "Sun"), 1, 0),
    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)
  )
```

### 1.3 \| Exploratory Data Analysis

**Daily Trip Counts**

```{r trips_over_time}
daily_trips <- indego %>%
  group_by(date) %>%
  summarize(trips = n())

ggplot(daily_trips, aes(x = date, y = trips)) +
  geom_line(color = "#3182bd", linewidth = 1) +
  geom_smooth(se = FALSE, color = "red", linetype = "dashed") +
  labs(
    title = "Indego Daily Ridership - Q1 2025",
    subtitle = "Winter demand patterns in Philadelphia",
    x = "Date",
    y = "Daily Trips",
    caption = "Source: Indego bike share"
  ) +
  plotTheme
```

**Hourly Patterns**

```{r hourly_patterns}
# Average trips by hour and day type
hourly_patterns <- indego %>%
  group_by(hour, weekend) %>%
  summarize(avg_trips = n() / n_distinct(date)) %>%
  mutate(day_type = ifelse(weekend == 1, "Weekend", "Weekday"))

ggplot(hourly_patterns, aes(x = hour, y = avg_trips, color = day_type)) +
  geom_line(linewidth = 1.2) +
  scale_color_manual(values = c("Weekday" = "#08519c", "Weekend" = "#6baed6")) +
  labs(
    title = "Average Hourly Ridership Patterns - Q1 2025",
    subtitle = "Clear commute patterns on weekdays",
    x = "Hour of Day",
    y = "Average Trips per Hour",
    color = "Day Type"
  ) +
  plotTheme
```

**Top Stations**

```{r}
# Most popular origin stations
top_stations <- indego %>%
  count(start_station, start_lat, start_lon, name = "trips") %>%
  arrange(desc(trips)) %>%
  head(20)

kable(top_stations, 
      caption = "Top 20 Indego Stations by Trip Origins - Q1 2025",
      format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

::: callout-note
## Observed Patterns for Q1 2025

-   **Seasonal Demand:** generally, ridership demand increases from January to March as the weather in Philadelphia gets warmer. However, there is significant fluctuation in daily ridership for Q1 2025.
-   **Hourly Ridership:** on weekdays, there is a clear morning and evening rush hour. On weekend, there appears to be a gentle crest in activity around midday to evening (around 10am to 7pm)
:::

------------------------------------------------------------------------

## Part 2: Philadelphia Census Data

### 2.1 \| Load Philadelphia Census Data

```{r load-census, cache = TRUE, progress = FALSE, results = 'hide'}
# Get Philadelphia census tracts
philly_census <- get_acs(
  geography = "tract",
  variables = c(
    "B01003_001",  # Total population
    "B19013_001",  # Median household income
    "B08301_001",  # Total commuters
    "B08301_010",  # Commute by transit
    "B02001_002",  # White alone
    "B25077_001"   # Median home value
  ),
  state = "PA",
  county = "Philadelphia",
  year = 2022,
  geometry = TRUE,
  output = "wide"
) %>%
  rename(
    Total_Pop = B01003_001E,
    Med_Inc = B19013_001E,
    Total_Commuters = B08301_001E,
    Transit_Commuters = B08301_010E,
    White_Pop = B02001_002E,
    Med_Home_Value = B25077_001E
  ) %>%
  mutate(
    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,
    Percent_White = (White_Pop / Total_Pop) * 100
  ) %>%
  st_transform(crs = 4326)  # WGS84 for lat/lon matching
```

### 2.2 \| Map Philadelphia Context

```{r map-philly}
# Map median income
ggplot() +
  geom_sf(data = philly_census, aes(fill = Med_Inc), color = NA) +
  scale_fill_viridis(
    option = "viridis",
    name = "Median\nIncome",
    labels = scales::dollar
  ) +
  labs(
    title = "Philadelphia Median Household Income by Census Tract",
    subtitle = "Context for understanding bike share demand patterns"
  ) +
  # Stations 
  geom_point(
    data = indego,
    aes(x = start_lon, y = start_lat),
    color = "red", size = 0.4, alpha = 0.6
  ) +
  mapTheme
```

### 2.3 \| Join Census Data to Stations

```{r visualize-fishnet}
# Create sf object for stations
stations_sf <- indego %>%
  distinct(start_station, start_lat, start_lon) %>%
  filter(!is.na(start_lat), !is.na(start_lon)) %>%
  st_as_sf(coords = c("start_lon", "start_lat"), crs = 4326)

# Spatial join to get census tract for each station
stations_census <- st_join(stations_sf, philly_census, left = TRUE) %>%
  st_drop_geometry()
```

**Left-Join Census Data to Q1 Indego Data**

```{r}
# Flag stations in non-residential census tracts
stations_for_map <- indego %>%
  distinct(start_station, start_lat, start_lon) %>%
  filter(!is.na(start_lat), !is.na(start_lon)) %>%
  left_join(
    stations_census %>% select(start_station, Med_Inc),
    by = "start_station"
  ) %>%
  mutate(has_census = !is.na(Med_Inc))

# Add back to trip data
indego_census <- indego %>%
  left_join(
    stations_census %>% 
      select(start_station, Med_Inc, Percent_Taking_Transit, 
             Percent_White, Total_Pop),
    by = "start_station"
  )

# Prepare data for visualization
stations_for_map <- indego %>%
  distinct(start_station, start_lat, start_lon) %>%
  filter(!is.na(start_lat), !is.na(start_lon)) %>%
  left_join(
    stations_census %>% select(start_station, Med_Inc),
    by = "start_station"
  ) %>%
  mutate(has_census = !is.na(Med_Inc))

count(stations_for_map, has_census)
```

```{r}
# Create the map showing problem stations
ggplot() +
  geom_sf(data = philly_census, aes(fill = Med_Inc), color = "white", size = 0.1) +
  scale_fill_viridis(
    option = "viridis",
    name = "Median\nIncome",
    labels = scales::dollar,
    na.value = "grey90"
  ) +
  # Stations with census data (small grey dots)
  geom_point(
    data = stations_for_map %>% filter(has_census),
    aes(x = start_lon, y = start_lat),
    color = "grey30", size = 1, alpha = 0.6
  ) +
  # Stations WITHOUT census data (red X marks the spot)
  geom_point(
    data = stations_for_map %>% filter(!has_census),
    aes(x = start_lon, y = start_lat),
    color = "red", size = 1, shape = 4, stroke = 1.5
  ) +
  labs(
    title = "Philadelphia Median Household Income by Census Tract",
    subtitle = "Indego stations shown (RED = no census data match)",
    caption = "Red X marks indicate stations that didn't join to census tracts"
  ) +
  mapTheme
```

### 2.4 \| Dealing with Missing Data

We need to decide what to do with the non-residential bike share stations. For this example, we are going to remove them.

This is not necessarily the right way to do things always, but for the sake of simplicity, we are narrowing our scope to only stations in residential neighborhoods. We might opt to create a separate model for non-residential stations.

```{r}
# Identify which stations to keep
valid_stations <- stations_census %>%
  filter(!is.na(Med_Inc)) %>%
  pull(start_station)

# Filter trip data to valid stations only
indego_census <- indego %>%
  filter(start_station %in% valid_stations) %>%
  left_join(
    stations_census %>% 
      select(start_station, Med_Inc, Percent_Taking_Transit, 
             Percent_White, Total_Pop),
    by = "start_station"
  )
```

------------------------------------------------------------------------

## Part 3: Get Weather Data

### 3.1 \| Weather Data for Q1 2025

```{r get-wea}
#| message: false
#| warning: false

# Get weather from Philadelphia International Airport (KPHL)
# This covers Q1 2025: January 1 - March 31
weather_data <- riem_measures(
  station = "PHL",  # Philadelphia International Airport
  date_start = "2025-01-01",
  date_end = "2025-03-31"
)

# Process weather data
weather_processed <- weather_data %>%
  mutate(
    interval60 = floor_date(valid, unit = "hour"),
    Temperature = tmpf,  # Temperature in Fahrenheit
    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches
    Wind_Speed = sknt  # Wind speed in knots
  ) %>%
  select(interval60, Temperature, Precipitation, Wind_Speed) %>%
  # updated in-class code to only keep the first row for each hour
  distinct(interval60, .keep_all = TRUE) 

# Check for missing hours and interpolate if needed
weather_complete <- weather_processed %>%
  complete(interval60 = seq(min(interval60), max(interval60), by = "hour")) %>%
  fill(Temperature, Precipitation, Wind_Speed, .direction = "down")

# Look at the weather
summary(weather_complete %>% select(Temperature, Precipitation, Wind_Speed))
```

### 3.2 \| Weather Data for Q2 2025

```{r}
weather_q2 <- riem_measures(
  station = "PHL",  # Philadelphia International Airport
  date_start = "2025-04-01",
  date_end = "2025-06-30"
)

# Process weather data
weather_q2 <- weather_q2 %>%
  mutate(
    interval60 = floor_date(valid, unit = "hour"),
    Temperature = tmpf,  # Temperature in Fahrenheit
    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches
    Wind_Speed = sknt  # Wind speed in knots
  ) %>%
  select(interval60, Temperature, Precipitation, Wind_Speed) %>%
  # updated in-class code to only keep the first row for each hour
  distinct(interval60, .keep_all = TRUE) 

# Check for missing hours and interpolate if needed
weather_q2_complete <- weather_q2 %>%
  complete(interval60 = seq(min(interval60), max(interval60), by = "hour")) %>%
  fill(Temperature, Precipitation, Wind_Speed, .direction = "down")

# Look at the weather
summary(weather_q2_complete %>% select(Temperature, Precipitation, Wind_Speed))
```

### 3.3 \| Weather Data for Q3 2025

```{r}
weather_q3 <- riem_measures(
  station = "PHL",  # Philadelphia International Airport
  date_start = "2025-07-01",
  date_end = "2025-09-30"
)

# Process weather data
weather_q3 <- weather_q3 %>%
  mutate(
    interval60 = floor_date(valid, unit = "hour"),
    Temperature = tmpf,  # Temperature in Fahrenheit
    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches
    Wind_Speed = sknt  # Wind speed in knots
  ) %>%
  select(interval60, Temperature, Precipitation, Wind_Speed) %>%
  # updated in-class code to only keep the first row for each hour
  distinct(interval60, .keep_all = TRUE) 

# Check for missing hours and interpolate if needed
weather_q3_complete <- weather_q3 %>%
  complete(interval60 = seq(min(interval60), max(interval60), by = "hour")) %>%
  fill(Temperature, Precipitation, Wind_Speed, .direction = "down")

# Look at the weather
summary(weather_q3_complete %>% select(Temperature, Precipitation, Wind_Speed))
```

### 3.4 \| Visualize Weather Patterns

```{r}
ggplot(weather_complete, aes(x = interval60, y = Temperature)) +
  geom_line(color = "#3182bd", alpha = 0.7) +
  geom_smooth(se = FALSE, color = "red") +
  labs(
    title = "Philadelphia Temperature - Q1 2025",
    subtitle = "Winter to Early Spring Transition",
    x = "Date",
    y = "Temperature (°F)"
  ) +
  plotTheme
```

```{r}
ggplot(weather_q2_complete, aes(x = interval60, y = Temperature)) +
  geom_line(color = "#3182bd", alpha = 0.7) +
  geom_smooth(se = FALSE, color = "red") +
  labs(
    title = "Philadelphia Temperature - Q2 2025",
    subtitle = "Spring to Summer Transition",
    x = "Date",
    y = "Temperature (°F)"
  ) +
  plotTheme
```

```{r}
ggplot(weather_q3_complete, aes(x = interval60, y = Temperature)) +
  geom_line(color = "#3182bd", alpha = 0.7) +
  geom_smooth(se = FALSE, color = "red") +
  labs(
    title = "Philadelphia Temperature - Q3 2025",
    subtitle = "Summer to Fall Transition",
    x = "Date",
    y = "Temperature (°F)"
  ) +
  plotTheme
```

```{r}
ggplot(weather_complete, aes(x = interval60, y = Precipitation)) +
  geom_line(color = "#3182bd", alpha = 0.7) +
  labs(
    title = "Philadelphia Precipitation - Q1 2025",
    subtitle = "Winter to Early Spring Transition",
    x = "Date",
    y = "Hourly Precipitation (inches)"
  ) +
  plotTheme
```

```{r}
ggplot(weather_q2_complete, aes(x = interval60, y = Precipitation)) +
  geom_line(color = "#3182bd", alpha = 0.7) +
  labs(
    title = "Philadelphia Precipitation - Q2 2025",
    subtitle = "Spring to Summer Transition",
    x = "Date",
    y = "Hourly Precipitation (inches)"
  ) +
  plotTheme
```

```{r}
ggplot(weather_q3_complete, aes(x = interval60, y = Precipitation)) +
  geom_line(color = "#3182bd", alpha = 0.7) +
  labs(
    title = "Philadelphia Precipitation - Q3 2025",
    subtitle = "Summer to Fall Transition",
    x = "Date",
    y = "Hourly Precipitation (inches)"
  ) +
  plotTheme
```

```{r}
# Combined 3x3 Panel Visualization of Weather Data by Quarter
weather_long <- bind_rows(
  weather_complete    %>% mutate(Quarter = "Q1 2025"),
  weather_q2_complete %>% mutate(Quarter = "Q2 2025"),
  weather_q3_complete %>% mutate(Quarter = "Q3 2025")
) %>%
  pivot_longer(
    cols = c(Precipitation, Temperature, Wind_Speed),
    names_to = "Measure",
    values_to = "Value"
  ) %>%
  mutate(
    Measure = factor(Measure, levels = c("Precipitation", "Temperature", "Wind_Speed")),
    Quarter = factor(Quarter, levels = c("Q1 2025", "Q2 2025", "Q3 2025"))
  )

ggplot(weather_long, aes(x = interval60, y = Value)) +
  geom_line(alpha = 0.7) +
  facet_grid(Measure ~ Quarter, scales = "free") +
  scale_x_datetime(date_breaks = "1 month", date_labels = "%b") +
  labs(
    title = "Philadelphia Weather by Quarter - 2025",
    x = "Date / Time",
    y = NULL
  ) +
  plotTheme
```

------------------------------------------------------------------------

## Part 4: Create Space-Time Panel

### 4.1 \| Aggregate Trips to Station-Hour Level

**Q1 2025**

```{r}
# Count trips by station-hour
trips_panel <- indego_census %>%
  group_by(interval60, start_station, start_lat, start_lon,
           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%
  summarize(Trip_Count = n()) %>%
  ungroup()

# How many station-hour observations?
nrow(trips_panel)

# How many unique stations?
length(unique(trips_panel$start_station))

# How many unique hours?
length(unique(trips_panel$interval60))
```

### 4.2 \| Create Complete Panel Structure

Not every station has trips every hour. We need a **complete panel** where every station-hour combination exists (even if Trip_Count = 0).

```{r}
# Calculate expected panel size
n_stations <- length(unique(trips_panel$start_station))
n_hours <- length(unique(trips_panel$interval60))
expected_rows <- n_stations * n_hours

cat("Expected panel rows:", format(expected_rows, big.mark = ","), "\n")
cat("Current rows:", format(nrow(trips_panel), big.mark = ","), "\n")
cat("Missing rows:", format(expected_rows - nrow(trips_panel), big.mark = ","), "\n")

# Create complete panel
study_panel <- expand.grid(
  interval60 = unique(trips_panel$interval60),
  start_station = unique(trips_panel$start_station)
) %>%
  # Join trip counts
  left_join(trips_panel, by = c("interval60", "start_station")) %>%
  # Replace NA trip counts with 0
  mutate(Trip_Count = replace_na(Trip_Count, 0))

# Fill in station attributes (they're the same for all hours)
station_attributes <- trips_panel %>%
  group_by(start_station) %>%
  summarize(
    start_lat = first(start_lat),
    start_lon = first(start_lon),
    Med_Inc = first(Med_Inc),
    Percent_Taking_Transit = first(Percent_Taking_Transit),
    Percent_White = first(Percent_White),
    Total_Pop = first(Total_Pop)
  )

study_panel <- study_panel %>%
  left_join(station_attributes, by = "start_station")

# Verify we have complete panel
cat("Complete panel rows:", format(nrow(study_panel), big.mark = ","), "\n")
```

**Add Time Features**

```{r}
study_panel <- study_panel %>%
  mutate(
    week = week(interval60),
    month = month(interval60, label = TRUE),
    dotw = wday(interval60, label = TRUE),
    hour = hour(interval60),
    date = as.Date(interval60),
    weekend = ifelse(dotw %in% c("Sat", "Sun"), 1, 0),
    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)
  )
```

**Join Weather Data**

```{r}
study_panel <- study_panel %>%
  left_join(weather_complete, by = "interval60")
summary(study_panel %>% select(Trip_Count, Temperature, Precipitation))
```

------------------------------------------------------------------------

## Part 5: Create Temporal Lag Variables

Temporal Persistence: past demand predicts future demand

### 5.1 \| Create Temporal Lags

```{r}
# Sort by station and time
study_panel <- study_panel %>%
  arrange(start_station, interval60)

# Create lag variables WITHIN each station
study_panel <- study_panel %>%
  group_by(start_station) %>%
  mutate(
    lag1Hour = lag(Trip_Count, 1),
    lag2Hours = lag(Trip_Count, 2),
    lag3Hours = lag(Trip_Count, 3),
    lag12Hours = lag(Trip_Count, 12),
    lag1day = lag(Trip_Count, 24)
  ) %>%
  ungroup()

# Remove rows with NA lags (first 24 hours for each station)
study_panel_complete <- study_panel %>%
  filter(!is.na(lag1day))

cat("Rows after removing NA lags:", format(nrow(study_panel_complete), big.mark = ","), "\n")
```

### 5.2 \| Visualize Lag Correlations

```{r}
# Sample one station to visualize
example_station <- study_panel_complete %>%
  filter(start_station == first(start_station)) %>%
  head(168)  # One week

# Plot actual vs lagged demand
ggplot(example_station, aes(x = interval60)) +
  geom_line(aes(y = Trip_Count, color = "Current"), linewidth = 1) +
  geom_line(aes(y = lag1Hour, color = "1 Hour Ago"), linewidth = 1, alpha = 0.7) +
  geom_line(aes(y = lag1day, color = "24 Hours Ago"), linewidth = 1, alpha = 0.7) +
  scale_color_manual(values = c(
    "Current" = "#08519c",
    "1 Hour Ago" = "#3182bd",
    "24 Hours Ago" = "#6baed6"
  )) +
  labs(
    title = "Temporal Lag Patterns at One Station",
    subtitle = "Past demand predicts future demand",
    x = "Date-Time",
    y = "Trip Count",
    color = "Time Period"
  ) +
  plotTheme
```

------------------------------------------------------------------------

## Part 6: Build 5 Predictive Models of Increasing Complexity

### Temporal Train/Test Split

Approach: Train on Past Data and Test on Future Data

```{r temporal-split}
# Train on weeks 1-9 (Jan 1 - early March)
# Test on weeks 10-13 (rest of March)

# Which stations have trips in BOTH early and late periods?
early_stations <- study_panel_complete %>%
  filter(week < 10) %>%
  filter(Trip_Count > 0) %>%
  distinct(start_station) %>%
  pull(start_station)

late_stations <- study_panel_complete %>%
  filter(week >= 10) %>%
  filter(Trip_Count > 0) %>%
  distinct(start_station) %>%
  pull(start_station)

# Keep only stations that appear in BOTH periods
common_stations <- intersect(early_stations, late_stations)


# Filter panel to only common stations
study_panel_complete <- study_panel_complete %>%
  filter(start_station %in% common_stations)

# NOW create train/test split
train <- study_panel_complete %>%
  filter(week < 10)

test <- study_panel_complete %>%
  filter(week >= 10)

cat("Training observations:", format(nrow(train), big.mark = ","), "\n")
cat("Testing observations:", format(nrow(test), big.mark = ","), "\n")
```

### Model 1: Baseline (Time + Weather)

```{r model-1}
# Create day of week factor with treatment (dummy) coding
train <- train %>%
  mutate(dotw_simple = factor(dotw, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")))

# Set contrasts to treatment coding (dummy variables)
contrasts(train$dotw_simple) <- contr.treatment(7)

model1 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,
  data = train
)
summary(model1)
```

The model uses Monday as the baseline. Each coefficient represents the difference in expected trips per station-hour compared to Monday. For example, dow_simple2 = Tuesday.

**Weekday Pattern (Tue-Fri):**

-   All weekdays have positive coefficients (0.029 to 0.052)
-   Tuesday has the highest weekday effect (+0.052)
-   Weekdays likely benefit from concentrated commuting patterns

**Weekend Pattern (Sat-Sun):**

-   Both weekend days have negative coefficients (-0.061 and -0.065)
-   This means fewer trips per station-hour than Monday

### Model 2: Add Temporal Lags

```{r model-2}
model2 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation + 
    lag1Hour + lag3Hours + lag1day, # temporal lags
  data = train
)
summary(model2)
```

### Model 3: Add Demographics

```{r model-3}
model3 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
    lag1Hour + lag3Hours + lag1day +
    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y, # demographics
  data = train
)
cat("Model 3 R-squared:", summary(model3)$r.squared, "\n")
cat("Model 3 Adj R-squared:", summary(model3)$adj.r.squared, "\n")
```

### Model 4: Add Station Fixed Effects

Station fixed effects capture baseline differences in demand across stations – some are just busier than others.

```{r model-4}
model4 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
    lag1Hour + lag3Hours + lag1day +
    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +
    as.factor(start_station), # station fixed effects
  data = train
)

cat("Model 4 R-squared:", summary(model4)$r.squared, "\n")
cat("Model 4 Adj R-squared:", summary(model4)$adj.r.squared, "\n")
```

### Model 5: Add Rush Hour Interaction

```{r model-5}
model5 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +
    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +
    as.factor(start_station) +
    rush_hour * weekend,  # Rush hour effects different on weekends
  data = train
)

cat("Model 5 R-squared:", summary(model5)$r.squared, "\n")
cat("Model 5 Adj R-squared:", summary(model5)$adj.r.squared, "\n")
```

------------------------------------------------------------------------

## Part 7: Model Evaluation

### 7.1 \| Predictions on Test Set and MAE

```{r}
# Create day of week factor with treatment (dummy) coding
test <- test %>%
  mutate(dotw_simple = factor(dotw, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")))

# Set contrasts to treatment coding (dummy variables)
contrasts(test$dotw_simple) <- contr.treatment(7)

test <- test %>%
  mutate(
    pred1 = predict(model1, newdata = test),
    pred2 = predict(model2, newdata = test),
    pred3 = predict(model3, newdata = test),
    pred4 = predict(model4, newdata = test),
    pred5 = predict(model5, newdata = test)
  )

# Calculate MAE for each model
mae_results <- data.frame(
  Model = c(
    "1. Time + Weather",
    "2. + Temporal Lags",
    "3. + Demographics",
    "4. + Station FE",
    "5. + Rush Hour Interaction"
  ),
  MAE = c(
    mean(abs(test$Trip_Count - test$pred1), na.rm = TRUE),
    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),
    mean(abs(test$Trip_Count - test$pred3), na.rm = TRUE),
    mean(abs(test$Trip_Count - test$pred4), na.rm = TRUE),
    mean(abs(test$Trip_Count - test$pred5), na.rm = TRUE)
  )
)

kable(mae_results, 
      digits = 2,
      caption = "Mean Absolute Error by Model (Test Set)",
      col.names = c("Model", "MAE (trips)")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

### 7.2 \| Visualize Model Comparison

```{r}
ggplot(mae_results, aes(x = reorder(Model, -MAE), y = MAE)) +
  geom_col(fill = "#3182bd", alpha = 0.8) +
  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +
  labs(
    title = "Model Performance Comparison",
    subtitle = "Lower MAE = Better Predictions",
    x = "Model",
    y = "Mean Absolute Error (trips)"
  ) +
  plotTheme +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

------------------------------------------------------------------------

## Part 8: Space-Time Error Analysis using Best Model

We conduct space-time error analysis using **Model 2 (Time + Weather + Temporal Lags)** which has the lowest MAE for Q1 2025 test data.

### 8.1 \| Observed vs Predicted

```{r obs-vs-pred}
test <- test %>%
  mutate(
    error = Trip_Count - pred2,
    abs_error = abs(error),
    time_of_day = case_when(
      hour < 7 ~ "Overnight",
      hour >= 7 & hour < 10 ~ "AM Rush",
      hour >= 10 & hour < 15 ~ "Mid-Day",
      hour >= 15 & hour <= 18 ~ "PM Rush",
      hour > 18 ~ "Evening"
    )
  )

# Scatter plot by time and day type
ggplot(test, aes(x = Trip_Count, y = pred2)) +
  geom_point(alpha = 0.2, color = "#3182bd") +
  geom_abline(slope = 1, intercept = 0, color = "red", linewidth = 1) +
  geom_smooth(method = "lm", se = FALSE, color = "darkgreen") +
  facet_grid(weekend ~ time_of_day) +
  labs(
    title = "Observed vs. Predicted Bike Trips",
    subtitle = "Model 2 performance by time period",
    x = "Observed Trips",
    y = "Predicted Trips",
    caption = "Red line = perfect predictions; Green line = actual model fit"
  ) +
  plotTheme
```

### 8.2 \| Spatial Error Patterns

-   Create error maps
-   Identify neighborhoods with high errors
-   Hypothesize why (missing features? different demand patterns?)

**Calculate MAE by Station**

```{r spatial-errors}
# Calculate MAE by Station
station_errors <- test %>%
  filter(!is.na(pred2)) %>%
  group_by(start_station, start_lat.x, start_lon.y) %>%
  summarize(
    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),
    avg_demand = mean(Trip_Count, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(!is.na(start_lat.x), !is.na(start_lon.y))
```

**Visualize**

```{r}
# Base Map
base_map <- ggplot() +
  geom_sf(data = philly_census,
          fill = "grey95", color = "white", linewidth = 0.2) +
  mapTheme
```

```{r}
# Map 1: Prediction Errors (MAE)
p_err <- base_map +
  geom_point(
    data = station_errors,
    aes(x = start_lon.y, y = start_lat.x, color = MAE),
    size = 0.6,
    alpha = 0.85
  ) +
  scale_color_viridis_c(
    option   = "plasma",
    direction = -1,
    name     = "MAE (trips)"
  ) +
  labs(
    title    = "Prediction Errors",
    subtitle = "MAE per station"
  ) +
  theme(
    legend.title = element_text(size = 10),
    legend.text  = element_text(size = 8)
  )

# Map 2: Average Trip Demand
p_demand <- base_map +
  geom_point(
    data = station_errors,
    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),
    size = 0.6,
    alpha = 0.85
  ) +
  scale_color_viridis_c(
    option   = "viridis",
    direction = 1,
    name     = "Avg demand\n(trips/hr)"
  ) +
  labs(
    title    = "Average Demand",
    subtitle = "Trips per station-hour"
  ) +
  theme(
    legend.title = element_text(size = 10),
    legend.text  = element_text(size = 8)
  )

grid.arrange(p_err, p_demand, ncol = 2)
```

### 8.3 \| Temporal Error Patterns

-   When are errors highest?
-   Do certain hours/days have systematic under/over-prediction?
-   Are there seasonal patterns?

```{r temporal-errors}
# MAE by time of day and day type
temporal_errors <- test %>%
  group_by(time_of_day, weekend) %>%
  summarize(
    MAE = mean(abs_error, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(day_type = ifelse(weekend == 1, "Weekend", "Weekday"))

ggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +
  geom_col(position = "dodge") +
  scale_fill_manual(values = c("Weekday" = "#08519c", "Weekend" = "#6baed6")) +
  labs(
    title = "Prediction Errors by Time Period",
    subtitle = "When is the model struggling most?",
    x = "Time of Day",
    y = "Mean Absolute Error (trips)",
    fill = "Day Type"
  ) +
  plotTheme +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### 8.4 \| Demographic Patterns

-   Relate errors to census characteristics
-   Are certain communities systematically harder to predict?
-   What are the equity implications?

```{r demographic-errors}
# Join demographic data to station errors
station_errors_demo <- station_errors %>%
  left_join(
    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),
    by = "start_station"
  ) %>%
  filter(!is.na(Med_Inc))

# Create plots
p1 <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +
  geom_point(alpha = 0.5, color = "#3182bd") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  scale_x_continuous(labels = scales::dollar) +
  labs(title = "Errors vs. Median Income", x = "Median Income", y = "MAE") +
  plotTheme

p2 <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +
  geom_point(alpha = 0.5, color = "#3182bd") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Errors vs. Transit Usage", x = "% Taking Transit", y = "MAE") +
  plotTheme

p3 <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +
  geom_point(alpha = 0.5, color = "#3182bd") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Errors vs. Race", x = "% White", y = "MAE") +
  plotTheme

grid.arrange(p1, p2, p3, ncol = 2)
```

------------------------------------------------------------------------

## Part 9: Replicate with Q2 2025

1.  **Download data** from: <https://www.rideindego.com/about/data/>
2.  **Adapt this code** to work with your quarter:
    -   Update date ranges for weather data
    -   Check for any data structure changes
    -   Create the same 5 models
    -   Calculate MAE for each model
3.  **Compare results** to Q1 2025:
    -   How do MAE values compare? Why might they differ?
    -   Are temporal patterns different (e.g., summer vs. winter)?
    -   Which features are most important in your quarter?

### 9.1 \| Data Cleaning/Wrangling for Q2 2025

**Create Time Bins**

```{r}
indego_q2 <- indego_q2 %>%
  mutate(
    start_datetime = mdy_hm(start_time),
    end_datetime = mdy_hm(end_time),
    
    # Create hourly bins and extract time features
    interval60 = floor_date(start_datetime, unit = "hour"),
    week = week(interval60),
    month = month(interval60, label = TRUE),
    dotw = wday(interval60, label = TRUE),
    hour = hour(interval60),
    date = as.Date(interval60),
    
    # Create useful indicators
    weekend = ifelse(dotw %in% c("Sat", "Sun"), 1, 0),
    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)
  )
```

**Daily Trip Counts**

```{r}
daily_trips <- indego_q2 %>%
  group_by(date) %>%
  summarize(trips = n())

ggplot(daily_trips, aes(x = date, y = trips)) +
  geom_line(color = "#3182bd", linewidth = 1) +
  geom_smooth(se = FALSE, color = "red", linetype = "dashed") +
  labs(
    title = "Indego Daily Ridership - Q2 2025",
    subtitle = "Spring demand patterns in Philadelphia",
    x = "Date",
    y = "Daily Trips",
    caption = "Source: Indego bike share"
  ) +
  plotTheme
```

**Filter out Non-Residential Bike Share Stations**

```{r}
# Filter trip data to valid stations only
indego_q2_census <- indego_q2 %>%
  filter(start_station %in% valid_stations) %>%
  left_join(
    stations_census %>% 
      select(start_station, Med_Inc, Percent_Taking_Transit, 
             Percent_White, Total_Pop),
    by = "start_station"
  )
```

### 9.2 \| Space-Time Panel

**Aggregate Trips to Station-Hour Level**

```{r}
trips_q2_panel <- indego_q2_census %>%
  group_by(interval60, start_station, start_lat, start_lon,
           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%
  summarize(Trip_Count = n()) %>%
  ungroup()
```

**Create Complete Panel**

```{r}
study_q2_panel <- expand.grid(
  interval60 = unique(trips_q2_panel$interval60),
  start_station = unique(trips_q2_panel$start_station)
) %>%
  # Join trip counts
  left_join(trips_q2_panel, by = c("interval60", "start_station")) %>%
  # Replace NA trip counts with 0
  mutate(Trip_Count = replace_na(Trip_Count, 0))

# Fill in station attributes (they're the same for all hours)
station_q2_attributes <- trips_q2_panel %>%
  group_by(start_station) %>%
  summarize(
    start_lat = first(start_lat),
    start_lon = first(start_lon),
    Med_Inc = first(Med_Inc),
    Percent_Taking_Transit = first(Percent_Taking_Transit),
    Percent_White = first(Percent_White),
    Total_Pop = first(Total_Pop)
  )

study_q2_panel <- study_q2_panel %>%
  left_join(station_q2_attributes, by = "start_station")
```

**Add Time Features**

```{r}
study_q2_panel <- study_q2_panel %>%
  mutate(
    week = week(interval60),
    month = month(interval60, label = TRUE),
    dotw = wday(interval60, label = TRUE),
    hour = hour(interval60),
    date = as.Date(interval60),
    weekend = ifelse(dotw %in% c("Sat", "Sun"), 1, 0),
    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)
  )
```

**Join Weather Data**

```{r}
study_q2_panel <- study_q2_panel %>%
  left_join(weather_q2, by = "interval60")
summary(study_q2_panel %>% select(Trip_Count, Temperature, Precipitation))
```

### 9.3 \| Create Temporal Lag Variables

```{r}
study_q2 <- study_q2_panel %>%
  arrange(start_station, interval60)

# Create lag variables WITHIN each station
study_q2 <- study_q2 %>%
  group_by(start_station) %>%
  mutate(
    lag1Hour = lag(Trip_Count, 1),
    lag2Hours = lag(Trip_Count, 2),
    lag3Hours = lag(Trip_Count, 3),
    lag12Hours = lag(Trip_Count, 12),
    lag1day = lag(Trip_Count, 24)
  ) %>%
  ungroup()

# Remove rows with NA lags (first 24 hours for each station)
study_q2_complete <- study_q2 %>%
  filter(!is.na(lag1day))
```

### 9.4 \| Build 5 Predictive Models

**Temporal Train/Test Split**

```{r}
#| eval: false
count(study_q2_complete, week)
study_q2_complete
```

```{r}
# Train on Weeks 14-22
# Test on Weeks 23-26
early_q2_stations <- study_q2_complete %>%
  filter(week < 23) %>%
  filter(Trip_Count > 0) %>%
  distinct(start_station) %>%
  pull(start_station)

late_q2_stations <- study_q2_complete %>%
  filter(week >= 23) %>%
  filter(Trip_Count > 0) %>%
  distinct(start_station) %>%
  pull(start_station)

common_q2_stations <- intersect(early_q2_stations, 
                                late_q2_stations)
```

```{r}
# Filter panel to only common stations
study_q2_complete <- study_q2_complete %>%
  filter(start_station %in% common_q2_stations)

# create train/test split
train_q2 <- study_q2_complete %>%
  filter(week < 23)

test_q2 <- study_q2_complete %>%
  filter(week >= 23)

cat("Training observations:", format(nrow(train_q2), big.mark = ","), "\n")
```

**Model 1: Baseline (Time + Weather)**

```{r}
train_q2 <- train_q2 %>%
  mutate(dotw_simple = factor(dotw, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")))

contrasts(train_q2$dotw_simple) <- contr.treatment(7)

model1_q2 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,
  data = train_q2
)
summary(model1_q2)
```

**Model 2: Add Temporal Lags**

```{r}
model2_q2 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation + 
    lag1Hour + lag3Hours + lag1day,
  data = train_q2
)
summary(model2_q2)
```

**Model 3: Add Demographics**

```{r}
model3_q2 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
    lag1Hour + lag3Hours + lag1day +
    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y,
  data = train_q2
)
cat("Model 3 R-squared:", summary(model3_q2)$r.squared, "\n")
cat("Model 3 Adj R-squared:", summary(model3_q2)$adj.r.squared, "\n")
```

**Model 4: Add Station Fixed Effects**

```{r}
model4_q2 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
    lag1Hour + lag3Hours + lag1day +
    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +
    as.factor(start_station),
  data = train_q2
)

cat("Model 4 R-squared:", summary(model4_q2)$r.squared, "\n")
cat("Model 4 Adj R-squared:", summary(model4_q2)$adj.r.squared, "\n")
```

**Model 5: Add Rush Hour Interaction**

```{r}
model5_q2 <- lm(
  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +
    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +
    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +
    as.factor(start_station) +
    rush_hour * weekend,  # Rush hour effects different on weekends
  data = train_q2
)

cat("Model 5 R-squared:", summary(model5_q2)$r.squared, "\n")
cat("Model 5 Adj R-squared:", summary(model5_q2)$adj.r.squared, "\n")
```

### 9.5 \| Model Evaluation

**Prediction on Test Set and MAE**

```{r}
# Create day of week factor with treatment (dummy) coding
test_q2 <- test_q2 %>%
  mutate(dotw_simple = factor(dotw, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")))

test_q2 <- test_q2 %>%
  mutate(
    pred1 = predict(model1_q2, newdata = test_q2),
    pred2 = predict(model2_q2, newdata = test_q2),
    pred3 = predict(model3_q2, newdata = test_q2),
    pred4 = predict(model4_q2, newdata = test_q2),
    pred5 = predict(model5_q2, newdata = test_q2)
  )

# Calculate MAE for each model
mae_results_q2 <- data.frame(
  Model = c(
    "1. Time + Weather",
    "2. + Temporal Lags",
    "3. + Demographics",
    "4. + Station FE",
    "5. + Rush Hour Interaction"
  ),
  MAE = c(
    mean(abs(test_q2$Trip_Count - test_q2$pred1), na.rm = TRUE),
    mean(abs(test_q2$Trip_Count - test_q2$pred2), na.rm = TRUE),
    mean(abs(test_q2$Trip_Count - test_q2$pred3), na.rm = TRUE),
    mean(abs(test_q2$Trip_Count - test_q2$pred4), na.rm = TRUE),
    mean(abs(test_q2$Trip_Count - test_q2$pred5), na.rm = TRUE)
  )
)

kable(mae_results_q2, 
      digits = 2,
      caption = "Mean Absolute Error by Model (Test Set) - Q2 2025",
      col.names = c("Model", "MAE (trips)")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

**Visualize Model Comparison**

```{r}
ggplot(mae_results_q2, aes(x = reorder(Model, -MAE), y = MAE)) +
  geom_col(fill = "#3182bd", alpha = 0.8) +
  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +
  labs(
    title = "Model Performance Comparison - Q2 2025",
    subtitle = "Lower MAE = Better Predictions",
    x = "Model",
    y = "Mean Absolute Error (trips)"
  ) +
  plotTheme +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### 9.6 \| Space-Time Error Analysis

```{r}
test_q2 <- test_q2 %>%
  mutate(
    error = Trip_Count - pred2,
    abs_error = abs(error),
    time_of_day = case_when(
      hour < 7 ~ "Overnight",
      hour >= 7 & hour < 10 ~ "AM Rush",
      hour >= 10 & hour < 15 ~ "Mid-Day",
      hour >= 15 & hour <= 18 ~ "PM Rush",
      hour > 18 ~ "Evening"
    )
  )

# Scatter plot by time and day type
ggplot(test_q2, aes(x = Trip_Count, y = pred2)) +
  geom_point(alpha = 0.2, color = "#3182bd") +
  geom_abline(slope = 1, intercept = 0, color = "red", linewidth = 1) +
  geom_smooth(method = "lm", se = FALSE, color = "darkgreen") +
  facet_grid(weekend ~ time_of_day) +
  labs(
    title = "Observed vs. Predicted Bike Trips - Q2 2025",
    subtitle = "Model 2 performance by time period",
    x = "Observed Trips",
    y = "Predicted Trips",
    caption = "Red line = perfect predictions; Green line = actual model fit"
  ) +
  plotTheme
```

**Spatial Patterns**

```{r}
# Calculate MAE by Station
station_errors_q2 <- test_q2 %>%
  filter(!is.na(pred2)) %>%
  group_by(start_station, start_lat.x, start_lon.y) %>%
  summarize(
    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),
    avg_demand = mean(Trip_Count, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(!is.na(start_lat.x), !is.na(start_lon.y))

# Base Map
base_map <- ggplot() +
  geom_sf(data = philly_census,
          fill = "grey95", color = "white", linewidth = 0.2) +
  mapTheme

# Map 1: Prediction Errors (MAE)
p_err_q2 <- base_map +
  geom_point(
    data = station_errors_q2,
    aes(x = start_lon.y, y = start_lat.x, color = MAE),
    size = 0.6, alpha = 0.85
  ) +
  scale_color_viridis_c(option = "plasma", direction = -1, name = "MAE (trips)") +
  labs(
    title    = "Prediction Errors",
    subtitle = "MAE per station"
  ) +
  theme(
    legend.title = element_text(size = 10),
    legend.text  = element_text(size = 8)
  )

# Map 2: Average Trip Demand
p_demand_q2 <- base_map +
  geom_point(
    data = station_errors_q2,
    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),
    size = 0.6, alpha = 0.85
  ) +
  scale_color_viridis_c(option = "viridis",
    direction = 1, name = "Avg demand\n(trips/hr)"
  ) +
  labs(
    title    = "Average Demand",
    subtitle = "Trips per station-hour"
  ) +
  theme(
    legend.title = element_text(size = 10),
    legend.text  = element_text(size = 8)
  )

grid.arrange(p_err_q2, p_demand_q2, ncol = 2)
```

**Temporal Patterns**

```{r}
# MAE by time of y and day type
temporal_errors_q2 <- test_q2 %>%
  group_by(time_of_day, weekend) %>%
  summarize(
    MAE = mean(abs_error, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(day_type = ifelse(weekend == 1, "Weekend", "Weekday"))

ggplot(temporal_errors_q2, aes(x = time_of_day, y = MAE, fill = day_type)) +
  geom_col(position = "dodge") +
  scale_fill_manual(values = c("Weekday" = "#08519c", "Weekend" = "#6baed6")) +
  labs(
    title = "Prediction Errors by Time Period - Q2 2025",
    subtitle = "When is the model struggling most?",
    x = "Time of Day",
    y = "MAE (trips)",
    fill = "Day Type"
  ) +
  plotTheme +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**Demographic Patterns**

```{r}
# Join demographic data to station errors
station_errors_demo_q2 <- station_errors_q2 %>%
  left_join(
    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),
    by = "start_station"
  ) %>%
  filter(!is.na(Med_Inc))

# Create plots
p1_q2 <- ggplot(station_errors_demo_q2, aes(x = Med_Inc, y = MAE)) +
  geom_point(alpha = 0.5, color = "#3182bd") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  scale_x_continuous(labels = scales::dollar) +
  labs(title = "Errors vs. Median Income", x = "Median Income", y = "MAE") +
  plotTheme

p2_q2 <- ggplot(station_errors_demo_q2, aes(x = Percent_Taking_Transit, y = MAE)) +
  geom_point(alpha = 0.5, color = "#3182bd") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Errors vs. Transit Usage", x = "% Taking Transit", y = "MAE") +
  plotTheme

p3_q2 <- ggplot(station_errors_demo_q2, aes(x = Percent_White, y = MAE)) +
  geom_point(alpha = 0.5, color = "#3182bd") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Errors vs. Race", x = "% White", y = "MAE") +
  plotTheme

grid.arrange(p1_q2, p2_q2, p3_q2, ncol = 2)
```

## Part 10: Error Analysis for Q2 2025 vs Q1 2025

**Compare MAE Across Quarters**

```{r}
mae_all <- bind_rows(
  mae_results    %>% mutate(Quarter = "Q1 2025"),
  mae_results_q2 %>% mutate(Quarter = "Q2 2025")
)
mae_wide <- mae_all %>%
  pivot_wider(names_from = Quarter, values_from = MAE)

kable(
  mae_wide,
  digits  = 2,
  caption = "Mean Absolute Error by Model: Q1 vs Q2 2025",
  col.names = c("Model", "Q1 2025 MAE (trips)", "Q2 2025 MAE (trips)")
) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

ggplot(mae_all, aes(x = Model, y = MAE, fill = Quarter)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(
    title = "Model Performance by Quarter",
    y = "MAE (trips)",
    x = NULL
  ) +
  theme_minimal()
```

**Temporal Error Patterns**

```{r}
## 2. Temporal error patterns (time-of-day, by quarter
temporal_all <- bind_rows(
  temporal_errors    %>% mutate(Quarter = "Q1 2025"),
  temporal_errors_q2 %>% mutate(Quarter = "Q2 2025")
) %>%
  # Optional: enforce an ordering of time-of-day buckets if you have them
  mutate(
    time_of_day = factor(time_of_day,
                         levels = unique(time_of_day))  # or your own ordered vector
  )

ggplot(temporal_all,
       aes(x = time_of_day, y = MAE, fill = Quarter)) +
  geom_col(position = "dodge") +
  facet_wrap(~ day_type) +
  labs(
    title = "Prediction Errors by Time of Day",
    subtitle = "Q1 vs Q2 2025",
    x = "Time of Day",
    y = "Mean Absolute Error (trips)",
    fill = "Quarter"
  ) +
  plotTheme +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

**Spatial Error Patterns**

```{r}
stations_all <- bind_rows(
  station_errors    %>% mutate(Quarter = "Q1 2025"),
  station_errors_q2 %>% mutate(Quarter = "Q2 2025")
)

ggplot() +
  geom_sf(data = philly_census,
          fill = "grey95", color = "white", linewidth = 0.2) +
  geom_point(
    data = stations_all,
    aes(x = start_lon.y, y = start_lat.x, color = MAE),
    size  = 1.3,
    alpha = 0.85
  ) +
  facet_wrap(~ Quarter) +
  scale_color_viridis_c(name = "MAE (trips)") +
  labs(
    title = "Spatial Distribution of Prediction Errors",
    subtitle = "Station-level MAE by quarter",
    x = NULL, y = NULL
  ) +
  mapTheme
```

**Which Features Matter Most?**

```{r}
# NOTE: this is a simple coefficient comparison; ideally predictors are standardized.

imp_q1 <- tidy(model2) %>%
  filter(term != "(Intercept)") %>%
  mutate(Quarter = "Q1 2025")

imp_q2 <- tidy(model2_q2) %>%
  filter(term != "(Intercept)") %>%
  mutate(Quarter = "Q2 2025")

imp_all <- bind_rows(imp_q1, imp_q2) %>%
  mutate(abs_est = abs(estimate)) %>%
  group_by(Quarter) %>%
  slice_max(order_by = abs_est, n = 10) %>%
  ungroup()

ggplot(imp_all,
       aes(x = reorder(term, abs_est), y = abs_est, fill = Quarter)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs(
    title = "Most Influential Features (Model 2)",
    x = "Predictor (top 10 per quarter)",
    y = "|Coefficient|"
  ) +
  theme_minimal()
```

------------------------------------------------------------------------

## Part 11: Feature Engineering & model improvement

Based on your error analysis, add 2-3 NEW features to improve the model:

**Potential features to consider:**

*Temporal features:*

-   Holiday indicators (Memorial Day, July 4th, Labor Day)
-   School calendar (Penn, Drexel, Temple in session?)
-   Special events (concerts, sports games, conventions)
-   Day of month (payday effects?)

*Weather features:*

-   Feels-like temperature (wind chill/heat index)
-   "Perfect biking weather" indicator (60-75°F, no rain)
-   Precipitation forecast (not just current)
-   Weekend + nice weather interaction

*Spatial features:*

-   Distance to Center City
-   Distance to nearest university
-   Distance to nearest park
-   Points of interest nearby (restaurants, offices, bars)
-   Station capacity
-   Bike lane connectivity

*Trip history features:*

-   Rolling 7-day average demand
-   Same hour last week
-   Station "type" clustering (residential, commercial, tourist)

**Implementation:**

-   Add your features to the best model
-   Compare MAE before and after
-   Explain *why* you chose these features
-   Did they improve predictions? Where?

**Try a poisson model for count data**

-   Does this improve model fit?

### Refined Rush Hour (Code Shell)

```{r}
#| eval: false

panel_df <- panel_df %>%
  mutate(
    # Weekday flag (commute concept)
    is_weekday = dotw %in% c("Mon", "Tue", "Wed", "Thu", "Fri"),

    # Classic commute rush hour, but ONLY on weekdays
    rush_hour = ifelse(is_weekday & hour %in% c(7, 8, 9, 16, 17, 18), 1L, 0L),

    # Separate AM / PM peaks (handy for interactions)
    am_peak = ifelse(is_weekday & hour %in% c(7, 8, 9), 1L, 0L),
    pm_peak = ifelse(is_weekday & hour %in% c(16, 17, 18), 1L, 0L),

    # Weekend “leisure peak” – people ride mid-day instead of commute times
    weekend_midday_peak = ifelse(!is_weekday & hour %in% 11:17, 1L, 0L)
  )
```

### Weather-Based Features (Code Shell)

-   can try interactions like rush_hour \* perfect_bike_weather

```{r}
#| eval: false

panel_df <- panel_df %>%
  mutate(
    perfect_bike_weather = ifelse(
      !is.na(feel) &
        feel >= 55 & feel <= 80 &        # comfy feels-like temp
        Precipitation == 0 &             # no rain
        Wind_Speed <= 15,                # not too windy
      1L, 0L
    ),

    bad_weather = ifelse(
      !is.na(feel) &
        (feel < 40 | feel > 90 |         # too cold/hot by feels-like
         Precipitation > 0.01 |
         Wind_Speed > 20),
      1L, 0L
    )
  )

```

### Poisson Model (Code Shell)

```{r}
#| eval: false

# Fit Poisson model
model_poisson <- glm(
  countBurglaries ~ Abandoned_Cars + Abandoned_Cars.nn + abandoned.isSig.dist,
  data = fishnet,
  family = poisson(link = "log")
)

# Exponentiate coefficients for interpretation
summary(model_poisson)
exp(coef(model_poisson))

# Example output:
#                        exp(coef)
# (Intercept)            0.234
# Abandoned_Cars         1.151
# Abandoned_Cars.nn      0.998
# abandoned.isSig.dist   0.999

# Interpretation:
# - Each additional abandoned car → 15.1% increase in expected burglaries
# - Each meter from nearest abandoned car → 0.2% decrease in expected burglaries
```

**Poisson: Check for Overdispersion**

```{r}
#| eval: false

#  Calculate dispersion parameter
dispersion <- sum(residuals(model_pois, type = "pearson")^2) / 
               model_pois$df.residual

cat("Dispersion parameter:", round(dispersion, 3), "\n")

# Rule of thumb:
# < 1.5: Poisson OK
# 1.5 - 3: Mild overdispersion, NegBin recommended (negative binomial)
# > 3: Serious overdispersion, NegBin essential
```

------------------------------------------------------------------------

## Conclusion: Critical Reflection

Write 1-2 paragraphs addressing:

1.  **Operational implications:**
    -   Is your final MAE "good enough" for Indego to use?
    -   When do prediction errors cause problems for rebalancing?
    -   Would you recommend deploying this system? Under what conditions?
2.  **Equity considerations:**
    -   Do prediction errors disproportionately affect certain neighborhoods?
    -   Could this system worsen existing disparities in bike access?
    -   What safeguards would you recommend?
3.  **Model limitations:**
    -   What patterns is your model missing?
    -   What assumptions might not hold in real deployment?
    -   How would you improve this with more time/data?

------------------------------------------------------------------------

### Brief report summarizing (with supporting data & visualization):

-   Your quarter and why you chose it
-   Model comparison results
-   Error analysis insights
-   New features you added and why
-   Critical reflection on deployment

------------------------------------------------------------------------

### Fun Animations

```{r, eval = FALSE}
rideshare_animation <-
  ggplot() +
    geom_sf(data = ride.animation.data, aes(fill = Trips)) +
    scale_fill_manual(values = palette5) +
    labs(title = "Rideshare pickups for one day in November 2018",
         subtitle = "15 minute intervals: {current_frame}") +
    transition_manual(interval15) + # new map generated for each 15-min interval
    mapTheme()

# create 20-sec gif    
animate(rideshare_animation, duration=20, renderer = gifski_renderer())
```
