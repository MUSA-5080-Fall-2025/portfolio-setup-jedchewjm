{
  "hash": "6ccfc8b7e72ebcceed7d8baa655fa45b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Assignment 4: Predictive Policing & Analysis\"\nauthor: \"Jed Chew\"\ndate: 11/10/2025\nformat:\n  pdf:\n    toc: true\n    toc-depth: 3\n    number-sections: true\n  html:\n    code-fold: show\n    code-tools: true\n    toc: true\n    toc-depth: 3\n    toc-location: left\n    theme: cosmo\n    embed-resources: true\neditor: visual\nexecute:\n  warning: false\n  message: false\n---\n\n## About This Exercise\n\nIn this lab, you will apply the spatial predictive modeling techniques demonstrated in the class exercise to a 311 service request type of your choice. You will build a complete spatial predictive model, document your process, and interpret your results.\n\n# Learning Objectives\n\nBy the end of this exercise, you will be able to:\n\n1.  Create a fishnet grid for aggregating point-level crime data\n2.  Calculate spatial features including k-nearest neighbors and distance measures\n3.  Diagnose spatial autocorrelation using Local Moran's I\n4.  Fit and interpret Poisson and Negative Binomial regression for count data\n5.  Implement spatial cross-validation (Leave-One-Group-Out)\n6.  Compare model predictions to a Kernel Density Estimation baseline\n7.  Evaluate model performance using appropriate metrics\n\n# Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(tidyverse)      # Data manipulation\nlibrary(sf)             # Spatial operations\nlibrary(here)           # Relative file paths\nlibrary(viridis)        # Color scales\nlibrary(terra)          # Raster operations (replaces 'raster')\nlibrary(spdep)          # Spatial dependence\nlibrary(FNN)            # Fast nearest neighbors\nlibrary(MASS)           # Negative binomial regression\nlibrary(patchwork)      # Plot composition (replaces grid/gridExtra)\nlibrary(knitr)          # Tables\nlibrary(kableExtra)     # Table formatting\nlibrary(classInt)       # Classification intervals\nlibrary(here)\n\n# Spatstat split into sub-packages\nlibrary(spatstat.geom)    # Spatial geometries\nlibrary(spatstat.explore) # Spatial exploration/KDE\n\n# Set options\noptions(scipen = 999)  # No scientific notation\nset.seed(5080)         # Reproducibility\n\n# Create consistent theme for visualizations\ntheme_crime <- function(base_size = 11) {\n  theme_minimal(base_size = base_size) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = base_size + 1),\n      plot.subtitle = element_text(color = \"gray30\", size = base_size - 1),\n      legend.position = \"right\",\n      panel.grid.minor = element_blank(),\n      axis.text = element_blank(),\n      axis.title = element_blank()\n    )\n}\n\n# Set as default\ntheme_set(theme_crime())\n\n# Set Working Directory\nsetwd(\"C:/Users/chewj/Documents/MUSA/Github/portfolio-setup-jedchewjm/labs/lab_4\")\n\ncat(\"✓ All packages loaded successfully!\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ All packages loaded successfully!\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"✓ Working directory:\", getwd(), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Working directory: C:/Users/chewj/Documents/MUSA/Github/portfolio-setup-jedchewjm/labs/lab_4 \n```\n\n\n:::\n:::\n\n\n# Part 1: Analyze Chosen 311 Violation Type\n\n# Choose your 311 Violation Type\n\n-   Browse the available service request types (e.g., Graffiti Removal, Pothole Repair, Street Light Out, Sanitation Code Violations, etc.) and **choose one violation type** that interests you.\n\n-   Chicago 311 Service Requests dataset: [**https://data.cityofchicago.org/stories/s/311-Dataset-Changes-12-11-2018/d7nq-5g7t**](https://data.cityofchicago.org/stories/s/311-Dataset-Changes-12-11-2018/d7nq-5g7t)\n\n-   Use `ESRI:102271` (Illinois State Plane East, NAD83, US Feet) as CRS\n\n### 1.1 \\| Load Chicago Spatial Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load police districts (used for spatial cross-validation)\npoliceDistricts <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(District = dist_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `OGRGeoJSON' from data source \n  `https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON' \n  using driver `GeoJSON'\nSimple feature collection with 25 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -87.94011 ymin: 41.64455 xmax: -87.52414 ymax: 42.02303\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load police beats (smaller administrative units)\npoliceBeats <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(Beat = beat_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `OGRGeoJSON' from data source \n  `https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON' \n  using driver `GeoJSON'\nSimple feature collection with 277 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -87.94011 ymin: 41.64455 xmax: -87.52414 ymax: 42.02303\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load Chicago boundary\nchicagoBoundary <- \n  st_read(\"https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson\") %>%\n  st_transform('ESRI:102271')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `chicagoBoundary' from data source \n  `https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1 feature and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -87.8367 ymin: 41.64454 xmax: -87.52414 ymax: 42.02304\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"✓ Loaded spatial boundaries\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Loaded spatial boundaries\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police districts:\", nrow(policeDistricts), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police districts: 25 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police beats:\", nrow(policeBeats), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police beats: 277 \n```\n\n\n:::\n:::\n\n\n### 1.2 \\| Load Burglary Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load from provided data file (downloaded from Chicago open data portal)\nburglaries <- st_read(\"data/burglaries.shp\") %>% \n  st_transform('ESRI:102271')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `burglaries' from data source \n  `C:\\Users\\chewj\\Documents\\MUSA\\Github\\portfolio-setup-jedchewjm\\labs\\lab_4\\data\\burglaries.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 7482 features and 22 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 340492 ymin: 552959.6 xmax: 367153.5 ymax: 594815.1\nProjected CRS: NAD83(HARN) / Illinois East\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check the data\ncat(\"\\n✓ Loaded burglary data\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Loaded burglary data\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of burglaries:\", nrow(burglaries), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of burglaries: 7482 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - CRS:\", st_crs(burglaries)$input, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - CRS: ESRI:102271 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Date range:\", min(burglaries$date, na.rm = TRUE), \"to\", \n    max(burglaries$date, na.rm = TRUE), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Date range: Inf to -Inf \n```\n\n\n:::\n:::\n\n\n### 1.3 \\| Visualize Point Data & Describe Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simple point map\np1 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = burglaries, color = \"#d62828\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Burglary Locations\",\n    subtitle = paste0(\"Chicago 2017, n = \", nrow(burglaries))\n  )\n\n# Density surface using modern syntax\np2 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = data.frame(st_coordinates(burglaries)),\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"  # Modern ggplot2 syntax (not guide = FALSE)\n  ) +\n  labs(\n    title = \"Density Surface\",\n    subtitle = \"Kernel density estimation\"\n  )\n\n# Combine plots using patchwork (modern approach)\np1 + p2 + \n  plot_annotation(\n    title = \"Spatial Distribution of Burglaries in Chicago\",\n    tag_levels = 'A'\n  )\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-pdf/visualize-points-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n::: callout-note\n## Observed Patterns\n\n-   Lorem Ipsum\n-   Lorem Ipsum\n:::\n\n# Part 2: Create Fishnet Grid\n\nA **fishnet grid** converts irregular point data into a regular grid of cells where we can aggregate counts / calculate spatial features / apply regression models\n\n### 2.1 \\| Create 500 m x 500 m Fishnet Grid\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create 500m x 500m grid\nfishnet <- st_make_grid(\n  chicagoBoundary,\n  cellsize = 500,  # 500 meters per cell\n  square = TRUE\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Keep only cells that intersect Chicago\nfishnet <- fishnet[chicagoBoundary, ]\n\n# View basic info\ncat(\"✓ Created fishnet grid\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Created fishnet grid\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of cells:\", nrow(fishnet), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of cells: 2458 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell size:\", 500, \"x\", 500, \"meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell size: 500 x 500 meters\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell area:\", round(st_area(fishnet[1,])), \"square meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell area: 250000 square meters\n```\n\n\n:::\n:::\n\n\n### 2.2 \\| Aggregate \\<Burglaries\\> to Grid\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Spatial join: which cell contains each burglary?\nburglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countBurglaries = n())\n\n# Join back to fishnet (cells with 0 burglaries will be NA)\nfishnet <- fishnet %>%\n  left_join(burglaries_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries = replace_na(countBurglaries, 0))\n\n# Summary statistics\ncat(\"\\nBurglary count distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nBurglary count distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$countBurglaries)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   3.042   5.000  40.000 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nCells with zero burglaries:\", \n    sum(fishnet$countBurglaries == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$countBurglaries == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCells with zero burglaries: 781 / 2458 ( 31.8 %)\n```\n\n\n:::\n:::\n\n\n### 2.3 \\| Visualize Count Distribution\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize aggregated counts\nggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"Burglaries\",\n    option = \"plasma\",\n    trans = \"sqrt\",  # Square root for better visualization of skewed data\n    breaks = c(0, 1, 5, 10, 20, 40)\n  ) +\n  labs(\n    title = \"Burglary Counts by Grid Cell\",\n    subtitle = \"500m x 500m cells, Chicago 2017\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-pdf/visualize-fishnet-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n# Part 3: Create a Kernel Density Estimate (KDE) Baseline\n\n-   KDE represents our null hypothesis: burglaries happen where they happened before, with no other information\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert burglaries to ppp (point pattern) format for spatstat\nburglaries_ppp <- as.ppp(\n  st_coordinates(burglaries),\n  W = as.owin(st_bbox(chicagoBoundary))\n)\n\n# Calculate KDE with 1km bandwidth\nkde_burglaries <- density.ppp(\n  burglaries_ppp,\n  sigma = 1000,  # 1km bandwidth\n  edge = TRUE    # Edge correction\n)\n\n# Convert to terra raster (modern approach, not raster::raster)\nkde_raster <- rast(kde_burglaries)\n\n# Extract KDE values to fishnet cells\nfishnet <- fishnet %>%\n  mutate(\n    kde_value = terra::extract(\n      kde_raster,\n      vect(fishnet),\n      fun = mean,\n      na.rm = TRUE\n    )[, 2]  # Extract just the values column\n  )\n\ncat(\"✓ Calculated KDE baseline\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated KDE baseline\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data = fishnet, aes(fill = kde_value), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"KDE Value\",\n    option = \"plasma\"\n  ) +\n  labs(\n    title = \"Kernel Density Estimation Baseline\",\n    subtitle = \"Simple spatial smoothing of burglary locations\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-pdf/visualize-kde-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n# Part 4: Create Spatial Predictor Variables\n\nNow we'll create features that might help predict burglaries. We'll use \"broken windows theory\" logic: signs of disorder predict crime.\n\n### 4.1 \\| Load 311 Abandoned Vehicle Calls\n\n\n::: {.cell}\n\n```{.r .cell-code}\nabandoned_cars <- read_csv(\"data/abandoned_cars_2017.csv\")%>%\n  filter(!is.na(Latitude), !is.na(Longitude)) %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %>%\n  st_transform('ESRI:102271')\n\ncat(\"✓ Loaded abandoned vehicle calls\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Loaded abandoned vehicle calls\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of calls:\", nrow(abandoned_cars), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of calls: 31390 \n```\n\n\n:::\n:::\n\n\n::: callout-note\n## Data Loading Note\n\nThe data was downloaded from Chicago's Open Data Portal. You can now request an api from the Chicago portal and tap into the data there.\n\n**Consider:** How might the 311 reporting system itself be biased? Who calls 311? What neighborhoods have better 311 awareness?\n:::\n\n### 4.2 \\| Count of Abandoned Cars per Cell\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Aggregate abandoned car calls to fishnet\nabandoned_fishnet <- st_join(abandoned_cars, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(abandoned_cars = n())\n\n# Join to fishnet\nfishnet <- fishnet %>%\n  left_join(abandoned_fishnet, by = \"uniqueID\") %>%\n  mutate(abandoned_cars = replace_na(abandoned_cars, 0))\n\ncat(\"Abandoned car distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAbandoned car distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$abandoned_cars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    2.00    9.00   12.74   19.00  123.00 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = abandoned_cars), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"magma\") +\n  labs(title = \"Abandoned Vehicle 311 Calls\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\") +\n  labs(title = \"Burglaries\") +\n  theme_crime()\n\np1 + p2 +\n  plot_annotation(title = \"Are abandoned cars and burglaries correlated?\")\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-pdf/visualize-abandoned-cars-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n### 4.3 \\| k-Nearest Neighbors (kNN) Features\n\nCount in a cell is one measure. Distance to the nearest 3 abandoned cars captures local context.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate mean distance to 3 nearest abandoned cars\n# (Do this OUTSIDE of mutate to avoid sf conflicts)\n\n# Get coordinates\nfishnet_coords <- st_coordinates(st_centroid(fishnet))\nabandoned_coords <- st_coordinates(abandoned_cars)\n\n# Calculate k nearest neighbors and distances\nnn_result <- get.knnx(abandoned_coords, fishnet_coords, k = 3)\n\n# Add to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    abandoned_cars.nn = rowMeans(nn_result$nn.dist)\n  )\n\ncat(\"✓ Calculated nearest neighbor distances\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated nearest neighbor distances\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$abandoned_cars.nn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n   4.386   88.247  143.293  246.946  271.283 2195.753 \n```\n\n\n:::\n:::\n\n\n### 4.4 \\| Local Moran's I; Identify Hotspots; Distance to Hot Spots\n\nLet's identify clusters of abandoned cars using Local Moran's I, then calculate distance to these hot spots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate Local Moran's I\ncalculate_local_morans <- function(data, variable, k = 5) {\n  \n  # Create spatial weights\n  coords <- st_coordinates(st_centroid(data))\n  neighbors <- knn2nb(knearneigh(coords, k = k))\n  weights <- nb2listw(neighbors, style = \"W\", zero.policy = TRUE)\n  \n  # Calculate Local Moran's I\n  local_moran <- localmoran(data[[variable]], weights)\n  \n  # Classify clusters\n  mean_val <- mean(data[[variable]], na.rm = TRUE)\n  \n  data %>%\n    mutate(\n      local_i = local_moran[, 1],\n      p_value = local_moran[, 5],\n      is_significant = p_value < 0.05,\n      \n      moran_class = case_when(\n        !is_significant ~ \"Not Significant\",\n        local_i > 0 & .data[[variable]] > mean_val ~ \"High-High\",\n        local_i > 0 & .data[[variable]] <= mean_val ~ \"Low-Low\",\n        local_i < 0 & .data[[variable]] > mean_val ~ \"High-Low\",\n        local_i < 0 & .data[[variable]] <= mean_val ~ \"Low-High\",\n        TRUE ~ \"Not Significant\"\n      )\n    )\n}\n\n# Apply to abandoned cars\nfishnet <- calculate_local_morans(fishnet, \"abandoned_cars\", k = 5)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize hot spots\nggplot() +\n  geom_sf(\n    data = fishnet, \n    aes(fill = moran_class), \n    color = NA\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"High-High\" = \"#d7191c\",\n      \"High-Low\" = \"#fdae61\",\n      \"Low-High\" = \"#abd9e9\",\n      \"Low-Low\" = \"#2c7bb6\",\n      \"Not Significant\" = \"gray90\"\n    ),\n    name = \"Cluster Type\"\n  ) +\n  labs(\n    title = \"Local Moran's I: Abandoned Car Clusters\",\n    subtitle = \"High-High = Hot spots of disorder\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-pdf/visualize-morans-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get centroids of \"High-High\" cells (hot spots)\nhotspots <- fishnet %>%\n  filter(moran_class == \"High-High\") %>%\n  st_centroid()\n\n# Calculate distance from each cell to nearest hot spot\nif (nrow(hotspots) > 0) {\n  fishnet <- fishnet %>%\n    mutate(\n      dist_to_hotspot = as.numeric(\n        st_distance(st_centroid(fishnet), hotspots %>% st_union())\n      )\n    )\n  \n  cat(\"✓ Calculated distance to abandoned car hot spots\\n\")\n  cat(\"  - Number of hot spot cells:\", nrow(hotspots), \"\\n\")\n} else {\n  fishnet <- fishnet %>%\n    mutate(dist_to_hotspot = 0)\n  cat(\"⚠ No significant hot spots found\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated distance to abandoned car hot spots\n  - Number of hot spot cells: 275 \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Part 5: Join Police Districts for Cross-Validation\n\nWe'll use police districts for our spatial cross-validation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join district information to fishnet\nfishnet <- st_join(\n  fishnet,\n  policeDistricts,\n  join = st_within,\n  left = TRUE\n) %>%\n  filter(!is.na(District))  # Remove cells outside districts\n\ncat(\"✓ Joined police districts\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Joined police districts\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Districts:\", length(unique(fishnet$District)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Districts: 22 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cells:\", nrow(fishnet), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cells: 1708 \n```\n\n\n:::\n:::\n\n\n# Part 6: Count Regression Model Fitting\n\n### 6.1 \\| Poisson Regression\n\nBurglary counts are count data (0, 1, 2, 3...). We'll use **Poisson regression**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create clean modeling dataset\nfishnet_model <- fishnet %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    uniqueID,\n    District,\n    countBurglaries,\n    abandoned_cars,\n    abandoned_cars.nn,\n    dist_to_hotspot\n  ) %>%\n  na.omit()  # Remove any remaining NAs\n\ncat(\"✓ Prepared modeling data\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Prepared modeling data\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Observations:\", nrow(fishnet_model), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Observations: 1708 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Variables:\", ncol(fishnet_model), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Variables: 6 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Poisson regression\nmodel_poisson <- glm(\n  countBurglaries ~ abandoned_cars + abandoned_cars.nn + \n    dist_to_hotspot,\n  data = fishnet_model,\n  family = \"poisson\"\n)\n\n# Summary\nsummary(model_poisson)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = countBurglaries ~ abandoned_cars + abandoned_cars.nn + \n    dist_to_hotspot, family = \"poisson\", data = fishnet_model)\n\nCoefficients:\n                      Estimate   Std. Error z value            Pr(>|z|)    \n(Intercept)        1.976262369  0.042512701  46.486 <0.0000000000000002 ***\nabandoned_cars    -0.001360741  0.001089805  -1.249               0.212    \nabandoned_cars.nn -0.004965200  0.000198914 -24.962 <0.0000000000000002 ***\ndist_to_hotspot    0.000002874  0.000006206   0.463               0.643    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 6710.3  on 1707  degrees of freedom\nResidual deviance: 5070.6  on 1704  degrees of freedom\nAIC: 9138.9\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n### 6.2 \\| Check for Overdispersion\n\nPoisson regression assumes mean = variance. Real count data often violates this (overdispersion).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate dispersion parameter\ndispersion <- sum(residuals(model_poisson, type = \"pearson\")^2) / \n              model_poisson$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDispersion parameter: 3.38 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Rule of thumb: >1.5 suggests overdispersion\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRule of thumb: >1.5 suggests overdispersion\n```\n\n\n:::\n\n```{.r .cell-code}\nif (dispersion > 1.5) {\n  cat(\"⚠ Overdispersion detected! Consider Negative Binomial model.\\n\")\n} else {\n  cat(\"✓ Dispersion looks okay for Poisson model.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n⚠ Overdispersion detected! Consider Negative Binomial model.\n```\n\n\n:::\n:::\n\n\n### 6.3 \\| Negative Binomial Regression\n\nIf overdispersed, use **Negative Binomial regression** (more flexible).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Negative Binomial model\nmodel_nb <- glm.nb(\n  countBurglaries ~ abandoned_cars + abandoned_cars.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Summary\nsummary(model_nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = countBurglaries ~ abandoned_cars + abandoned_cars.nn + \n    dist_to_hotspot, data = fishnet_model, init.theta = 1.603099596, \n    link = log)\n\nCoefficients:\n                      Estimate   Std. Error z value            Pr(>|z|)    \n(Intercept)        2.092907737  0.077469423  27.016 <0.0000000000000002 ***\nabandoned_cars    -0.002006352  0.002091851  -0.959               0.337    \nabandoned_cars.nn -0.005844829  0.000321389 -18.186 <0.0000000000000002 ***\ndist_to_hotspot    0.000006861  0.000011049   0.621               0.535    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.6031) family taken to be 1)\n\n    Null deviance: 2534.0  on 1707  degrees of freedom\nResidual deviance: 1796.6  on 1704  degrees of freedom\nAIC: 7522.6\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.6031 \n          Std. Err.:  0.0888 \n\n 2 x log-likelihood:  -7512.5850 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare AIC (lower is better)\ncat(\"\\nModel Comparison:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel Comparison:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Poisson AIC:\", round(AIC(model_poisson), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPoisson AIC: 9138.9 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Negative Binomial AIC:\", round(AIC(model_nb), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNegative Binomial AIC: 7522.6 \n```\n\n\n:::\n:::\n\n\n### 6.4 \\| Compare Model Fit (AIC)\n\n-   To clarify what does AIC mean??\n\n# Part 7: Spatial LOGO-CV (2017)\n\n**Leave-One-Group-Out (LOGO) Cross-Validation** trains on all districts except one, then tests on the held-out district.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get unique districts\ndistricts <- unique(fishnet_model$District)\ncv_results <- tibble()\n\ncat(\"Running LOGO Cross-Validation...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning LOGO Cross-Validation...\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (i in seq_along(districts)) {\n  \n  test_district <- districts[i]\n  \n  # Split data\n  train_data <- fishnet_model %>% filter(District != test_district)\n  test_data <- fishnet_model %>% filter(District == test_district)\n  \n  # Fit model on training data\n  model_cv <- glm.nb(\n    countBurglaries ~ abandoned_cars + abandoned_cars.nn + \n      dist_to_hotspot,\n    data = train_data\n  )\n  \n  # Predict on test data\n  test_data <- test_data %>%\n    mutate(\n      prediction = predict(model_cv, test_data, type = \"response\")\n    )\n  \n  # Calculate metrics\n  mae <- mean(abs(test_data$countBurglaries - test_data$prediction))\n  rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))\n  \n  # Store results\n  cv_results <- bind_rows(\n    cv_results,\n    tibble(\n      fold = i,\n      test_district = test_district,\n      n_test = nrow(test_data),\n      mae = mae,\n      rmse = rmse\n    )\n  )\n  \n  cat(\"  Fold\", i, \"/\", length(districts), \"- District\", test_district, \n      \"- MAE:\", round(mae, 2), \"\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Fold 1 / 22 - District 5 - MAE: 2.04 \n  Fold 2 / 22 - District 4 - MAE: 1.84 \n  Fold 3 / 22 - District 22 - MAE: 2.26 \n  Fold 4 / 22 - District 6 - MAE: 3.3 \n  Fold 5 / 22 - District 8 - MAE: 2.53 \n  Fold 6 / 22 - District 7 - MAE: 3.08 \n  Fold 7 / 22 - District 3 - MAE: 6.05 \n  Fold 8 / 22 - District 2 - MAE: 2.69 \n  Fold 9 / 22 - District 9 - MAE: 2.16 \n  Fold 10 / 22 - District 10 - MAE: 2.19 \n  Fold 11 / 22 - District 1 - MAE: 1.76 \n  Fold 12 / 22 - District 12 - MAE: 3.1 \n  Fold 13 / 22 - District 15 - MAE: 2.08 \n  Fold 14 / 22 - District 11 - MAE: 3.19 \n  Fold 15 / 22 - District 18 - MAE: 2.75 \n  Fold 16 / 22 - District 25 - MAE: 2.75 \n  Fold 17 / 22 - District 14 - MAE: 2.96 \n  Fold 18 / 22 - District 19 - MAE: 2.1 \n  Fold 19 / 22 - District 16 - MAE: 2.98 \n  Fold 20 / 22 - District 17 - MAE: 2.17 \n  Fold 21 / 22 - District 20 - MAE: 2.68 \n  Fold 22 / 22 - District 24 - MAE: 2.65 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Overall results\ncat(\"\\n✓ Cross-Validation Complete\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Cross-Validation Complete\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean MAE:\", round(mean(cv_results$mae), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean MAE: 2.7 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean RMSE:\", round(mean(cv_results$rmse), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean RMSE: 3.61 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Show results\ncv_results %>%\n  arrange(desc(mae)) %>%\n  kable(\n    digits = 2,\n    caption = \"LOGO CV Results by District\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n\n\\begin{longtable}[t]{rlrrr}\n\\caption{\\label{tab:cv-results-table}LOGO CV Results by District}\\\\\n\\toprule\nfold & test\\_district & n\\_test & mae & rmse\\\\\n\\midrule\n7 & 3 & 43 & 6.05 & 8.08\\\\\n4 & 6 & 63 & 3.30 & 4.75\\\\\n14 & 11 & 43 & 3.19 & 4.09\\\\\n12 & 12 & 73 & 3.10 & 4.62\\\\\n6 & 7 & 52 & 3.08 & 4.07\\\\\n\\addlinespace\n19 & 16 & 129 & 2.98 & 3.48\\\\\n17 & 14 & 46 & 2.96 & 4.24\\\\\n16 & 25 & 85 & 2.75 & 3.62\\\\\n15 & 18 & 30 & 2.75 & 4.15\\\\\n8 & 2 & 56 & 2.69 & 3.60\\\\\n\\addlinespace\n21 & 20 & 30 & 2.68 & 3.11\\\\\n22 & 24 & 41 & 2.65 & 2.98\\\\\n5 & 8 & 197 & 2.53 & 3.48\\\\\n3 & 22 & 112 & 2.26 & 2.83\\\\\n10 & 10 & 63 & 2.19 & 3.09\\\\\n\\addlinespace\n20 & 17 & 82 & 2.17 & 2.60\\\\\n9 & 9 & 107 & 2.16 & 2.59\\\\\n18 & 19 & 63 & 2.10 & 2.57\\\\\n13 & 15 & 32 & 2.08 & 2.67\\\\\n1 & 5 & 98 & 2.04 & 3.09\\\\\n\\addlinespace\n2 & 4 & 235 & 1.84 & 3.69\\\\\n11 & 1 & 28 & 1.76 & 2.11\\\\\n\\bottomrule\n\\end{longtable}\n\n\n:::\n:::\n\n\n# Part 8: Model Predictions and Comparison\n\n### 8.1 \\| Generate Final Predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit final model on all data\nfinal_model <- glm.nb(\n  countBurglaries ~ abandoned_cars + abandoned_cars.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Add predictions back to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    prediction_nb = predict(final_model, fishnet_model, type = \"response\")[match(uniqueID, fishnet_model$uniqueID)]\n  )\n\n# Also add KDE predictions (normalize to same scale as counts)\nkde_sum <- sum(fishnet$kde_value, na.rm = TRUE)\ncount_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)\nfishnet <- fishnet %>%\n  mutate(\n    prediction_kde = (kde_value / kde_sum) * count_sum\n  )\n```\n:::\n\n\n### 8.2 \\| Compare Model vs. KDE Baseline\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create three maps\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Actual Burglaries\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Model Predictions (Neg. Binomial)\") +\n  theme_crime()\n\np3 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"KDE Baseline Predictions\") +\n  theme_crime()\n\np1 + p2 + p3 +\n  plot_annotation(\n    title = \"Actual vs. Predicted Burglaries\",\n    subtitle = \"Does our complex model outperform simple KDE?\"\n  )\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-pdf/compare-models-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate performance metrics\ncomparison <- fishnet %>%\n  st_drop_geometry() %>%\n  filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%\n  summarize(\n    model_mae = mean(abs(countBurglaries - prediction_nb)),\n    model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),\n    kde_mae = mean(abs(countBurglaries - prediction_kde)),\n    kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))\n  )\n\ncomparison %>%\n  pivot_longer(everything(), names_to = \"metric\", values_to = \"value\") %>%\n  separate(metric, into = c(\"approach\", \"metric\"), sep = \"_\") %>%\n  pivot_wider(names_from = metric, values_from = value) %>%\n  kable(\n    digits = 2,\n    caption = \"Model Performance Comparison\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n\n\\begin{longtable}[t]{lrr}\n\\caption{\\label{tab:model-comparison-metrics}Model Performance Comparison}\\\\\n\\toprule\napproach & mae & rmse\\\\\n\\midrule\nmodel & 2.48 & 3.59\\\\\nkde & 2.06 & 2.95\\\\\n\\bottomrule\n\\end{longtable}\n\n\n:::\n:::\n\n\n### 8.3 \\| Where Does the Model Work Well?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate errors\nfishnet <- fishnet %>%\n  mutate(\n    error_nb = countBurglaries - prediction_nb,\n    error_kde = countBurglaries - prediction_kde,\n    abs_error_nb = abs(error_nb),\n    abs_error_kde = abs(error_kde)\n  )\n\n# Map errors\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +\n  scale_fill_gradient2(\n    name = \"Error\",\n    low = \"#2166ac\", mid = \"white\", high = \"#b2182b\",\n    midpoint = 0,\n    limits = c(-10, 10)\n  ) +\n  labs(title = \"Model Errors (Actual - Predicted)\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Abs. Error\", option = \"magma\") +\n  labs(title = \"Absolute Model Errors\") +\n  theme_crime()\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](assignment4_template_files/figure-pdf/prediction-errors-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n### 8.4 \\| Assess Model Performance ACross Time\n\n# Part 9: Summary Statistics \n\n### 9.1 \\| Model Summary Table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create nice summary table\nmodel_summary <- broom::tidy(final_model, exponentiate = TRUE) %>%\n  mutate(\n    across(where(is.numeric), ~round(., 3))\n  )\n\nmodel_summary %>%\n  kable(\n    caption = \"Final Negative Binomial Model Coefficients (Exponentiated)\",\n    col.names = c(\"Variable\", \"Rate Ratio\", \"Std. Error\", \"Z\", \"P-Value\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%\n  footnote(\n    general = \"Rate ratios > 1 indicate positive association with burglary counts.\"\n  )\n```\n\n::: {.cell-output-display}\n\n\\begin{longtable}[t]{lrrrr}\n\\caption{\\label{tab:model-summary-table}Final Negative Binomial Model Coefficients (Exponentiated)}\\\\\n\\toprule\nVariable & Rate Ratio & Std. Error & Z & P-Value\\\\\n\\midrule\n(Intercept) & 8.108 & 0.077 & 27.016 & 0.000\\\\\nabandoned\\_cars & 0.998 & 0.002 & -0.959 & 0.337\\\\\nabandoned\\_cars.nn & 0.994 & 0.000 & -18.186 & 0.000\\\\\ndist\\_to\\_hotspot & 1.000 & 0.000 & 0.621 & 0.535\\\\\n\\bottomrule\n\\multicolumn{5}{l}{\\rule{0pt}{1em}\\textit{Note: }}\\\\\n\\multicolumn{5}{l}{\\rule{0pt}{1em}Rate ratios > 1 indicate positive association with burglary counts.}\\\\\n\\end{longtable}\n\n\n:::\n:::\n\n\n## Key Findings Checklist\n\n**Technical Performance:**\n\n-   Cross-validation MAE: 2.7\n-   Model vs. KDE: \\[Which performed better?\\]\n-   Most predictive variable: \\[Which had largest effect?\\]\n\n**Spatial Patterns:**\n\n-   Burglaries are \\[evenly distributed / clustered\\]\n-   Hot spots are located in \\[describe\\]\n-   Model errors show \\[random / systematic\\] patterns\n\n**Model Limitations:**\n\n-   Overdispersion: \\[Yes/No\\]\n-   Spatial autocorrelation in residuals: \\[Test this!\\]\n-   Cells with zero counts: \\[What % of data?\\]\n",
    "supporting": [
      "assignment4_template_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\n\\usepackage{longtable}\n\\usepackage{array}\n\\usepackage{multirow}\n\\usepackage{wrapfig}\n\\usepackage{float}\n\\usepackage{colortbl}\n\\usepackage{pdflscape}\n\\usepackage{tabu}\n\\usepackage{threeparttable}\n\\usepackage{threeparttablex}\n\\usepackage[normalem]{ulem}\n\\usepackage{makecell}\n\\usepackage{xcolor}\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}