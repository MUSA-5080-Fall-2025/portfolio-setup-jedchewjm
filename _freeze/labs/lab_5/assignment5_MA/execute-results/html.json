{
  "hash": "eb12af5cc78a3ba98a0b6f8790df8914",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Assignment 5: Space-Time Prediction of Indego Bike Share Demand\"\nauthor: \"Jed Chew and Mohamad AlAbbas\"\ndate: 12/1/2025\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Show code\"\n    code-tools: true\n    toc: true\n    toc-depth: 3\n    toc-location: left\n    theme: cosmo\n    embed-resources: true\neditor: visual\nexecute:\n  warning: false\n  message: false\n---\n\n# Report: Rebalancing Indego Bikes in Philadelphia\n\n## Introduction\n\nIndego’s rebalancing problem is really an **availability** problem: riders don’t experience “demand,” they experience whether a station has **a bike when they want to start** and **an open dock when they want to end**. When stations drift into stockouts (no bikes) or dockouts (no empty docks), the system loses trips, frustrates riders, and can even push people back toward less sustainable modes. Because rebalancing trucks, staff, and time are limited—especially in the short window before commute peaks—Indego benefits from forecasting which stations are most likely to become constrained so it can **restock bikes proactively** and keep service reliable across the network.\n\nGetting availability right also matters because rebalancing decisions compound: moving bikes to fix one hotspot can unintentionally create shortages elsewhere. Prediction tools are valuable when they help operations managers prioritize scarce capacity—flagging likely stockout stations with enough lead time to act—while minimizing wasted trips from over-reacting to noise. In that sense, the goal of forecasting isn’t perfect point prediction; it’s maintaining **consistent access** by preventing the most disruptive availability failures before they happen.\n\nIn class we had constructed models that captured Q1 of 2025 bike ridership. Now, we replicate the full modeling pipeline in Q2 2025 (April–June) and compare it to Q1 2025 (January–March) because Indego demand is seasonal and model performance can shift when the system moves from winter commuting patterns into spring and early-summer riding. Importantly, this is not a test where a Q1-trained model is applied to Q2. Instead, we retrain the same set of model specifications within each quarter (same variables, same lag structure, same train/test logic), and then evaluate performance on a within-quarter future period. This design lets us answer a different operational question: when Indego updates or refits its forecasting system for a new season, do the same feature choices still deliver accurate predictions, and do the same types of errors show up in the same places and times? By holding the modeling recipe constant while allowing coefficients to re-estimate each quarter, differences in MAE and error patterns can be interpreted as evidence of behavioral seasonality and changing station dynamics, rather than simple model transfer failure.\n\n## Model Comparison & Error Analysis Insights\n\n::: {#fig-q2-errors}\n![Model Performance By Quartile (Q1 & Q2) in Trips](imgs/mae_compare.png){width=\"700\"} Figure 1: Model Performance By Quartile (Q1 & Q2) in Trips\n:::\n\nAcross both quarters, Model 2 (Time + Weather + Temporal Lags) consistently delivers the best predictive performance, making it our preferred operational baseline. In Q1 2025, MAE drops from 0.62 in the simple time-and-weather baseline (Model 1) to 0.54 once we add lagged demand (Model 2). That improvement is exactly what we would expect in bike share systems: station-hour demand is highly persistent, so recent past usage is one of the most reliable signals for near-future demand. By contrast, Models 3–5 perform noticeably worse in Q1 (MAE 0.75–0.77), suggesting that adding demographic context, station fixed effects, or the rush-hour interaction does not translate into better out-of-sample prediction in this setup.\n\nThe same story holds, and is even clearer, in Q2 2025, though accuracy is lower overall. MAE is 0.84 for Model 1 and improves to 0.70 for Model 2, again showing that temporal persistence is doing the heavy lifting. However, Q2 errors are systematically higher than Q1 for every model (e.g., Model 2 rises from 0.54 → 0.70), which is consistent with Q2 having more volatile demand patterns (spring/summer riding, events, tourism, and generally more “irregular” trip behavior). Importantly, the feature-rich models still do not help here: Models 3–5 range from 0.92 to 0.96, reinforcing that complexity alone doesn’t guarantee better forecasts, especially when the added predictors are either weakly related to hour-to-hour variation or introduce noise/overfitting.\n\n<div>\n\n::::: columns\n::: column\n![](imgs/temp_error.png){width=\"100%\"}\n:::\n\n::: column\n![](imgs/Spatial_error.png){width=\"100%\"}\n:::\n:::::\n\nPrediction errors (time + space), Q2 2025\n\n</div>\n\nFigure 2(a) shows a clear and consistent time-of-day structure in prediction error for Model 2 across both quarters. Errors are lowest overnight (when demand is near-zero and more stable) and rise sharply during peak travel periods, especially the PM rush hour, which is the highest-error block on both weekdays and weekends. Importantly, errors are systematically higher in Q2 than Q1 across nearly every time block—consistent with the overall MAE comparison (Model 2: 0.70 in Q2 vs. 0.54 in Q1). This does not mean the same trained model “transfers” equally well across seasons; rather, it suggests that even when the model is retrained in each quarter, the same structural weakness remains: it struggles most when demand is most volatile (commute peaks, leisure surges, and rapid within-day shifts).\n\nSpatially Fig 2(b), the largest station-level MAEs cluster in and around Center City and University City, while many peripheral stations show lower errors. This pattern aligns with the idea that stations in the urban core experience high volume and higher variance: more trips, more directional commuting waves, and more sensitivity to factors not included in the model. Note that the map is MAE (absolute error), so it reflects magnitude rather than whether predictions are systematically over- or under-shooting. Still, the core clustering strongly suggests the model is missing predictors that matter most precisely where operations pressure is highest—i.e., the stations where stockouts/dockouts are most likely to occur and where rebalancing decisions are most consequential.\n\n## New Features & Assessments\n\nThe error diagnostics suggest that Model 2’s weakest performance occurs precisely when demand is least stable—especially during the PM rush hour and, more broadly, during periods when trip volumes shift quickly within the day. Overnight hours, when travel is sparse and predictable, show the lowest MAE, while peak periods show the highest MAE. This pattern implies that simple short-run persistence (e.g., lag1Hour, lag3Hours, lag1day) captures routine momentum, but may still miss weekly regularities or recurring schedule-driven behavior that reappears on a weekly cycle. For this reason, in Part 11 we extend the lag structure by adding lag1week (same hour one week ago) to help the model learn repeated weekly patterns that are especially relevant for commuting rhythms and consistently scheduled activities.\n\nA second takeaway is that Q2 errors are consistently higher than Q1 across most time buckets, which suggests that spring/early summer demand is not just “more demand,” but more variable demand—likely shaped by calendar-based disruptions (holidays, long weekends, and end-of-semester transitions) that aren’t fully summarized by weather + hour + day-of-week alone. To address this, Part 11 introduces holiday indicators plus day-before/day-after holiday flags, which are designed to capture the predictable spikes and dips that happen around long weekends and public holidays, when commuting drops but recreational riding may rise and timing may shift.\n\nFinally, the spatial concentration of higher errors around Center City and University City suggests that the model struggles most in places where cycling patterns are shaped by institutional schedules and periodic population surges (students, campus commuters), not only by the usual time/weather structure. That directly motivates adding university calendar flags (in-session vs. no-classes periods). These features aim to capture systematic changes in trip generation near major campuses that would otherwise appear to the model as “unexplained noise,” especially in the core neighborhoods where the MAE is highest and where operational rebalancing decisions matter most.\n\n::: {#tbl-part11-mae}\n| Quarter | Original Baseline Model 2 | Model 2 (Quad Weather) | Model 2 + Calendar | delta_MAE |\n|---------------|--------------:|--------------:|--------------:|--------------:|\n| Q1 2025 | 0.535 | 0.528 | 0.531 | 0.003 |\n| Q2 2025 | 0.698 | 0.694 | 0.694 | 0.000 |\n\n: MAE Comparison + Delta (Calendar - Baseline)\n:::\n\nThe Table above shows three versions of Model 2 evaluated within each quarter: the original linear-weather specification, an updated version with quadratic weather terms plus an added weekly lag, and a further-augmented version that adds holiday timing and university calendar indicators. In Q1 2025, moving from the original baseline (MAE = 0.535) to the quadratic-weather + weekly-lag version produces a small improvement (MAE = 0.528), suggesting that modest nonlinearity in weather response and weekly repetition helps capture some demand structure that linear terms and shorter lags miss. However, adding the holiday and university calendar features slightly worsens error (MAE = 0.531), yielding a positive delta (ΔMAE = +0.003; +0.584%). This implies that, in Q1, the introduced calendar signals either (i) do not align strongly with demand variation in this winter/early-spring period, or (ii) add noise/collinearity relative to the dominant temporal pattern already captured by hour, day-of-week, and lag structure.\n\nIn Q2 2025, the results are even more decisive: the original baseline MAE is 0.698, and the quadratic-weather + weekly-lag model improves only marginally to 0.694. Adding holidays and the university calendar produces essentially no change (MAE remains 0.694; ΔMAE ≈ +0.000; +0.002%). In other words, once we account for temporal persistence and flexible weather effects, the holiday/calendar variables provide almost no additional predictive power for Q2 in this setup. Practically, this suggests that the largest remaining errors in Q2 are likely driven by factors not encoded by these features—such as special events, station capacity constraints, operational rebalancing actions themselves, or localized micro-weather and land-use patterns—rather than broad academic/holiday schedule shifts.\n\nPart 3 demonstrates that the big gains come from core time dynamics (lags, weekly repetition) and nonlinear weather, while the added calendar indicators have weak incremental value under MAE. This is still a useful outcome: it tells us that improving prediction further likely requires more spatially-specific or operational features (e.g., proximity to venues/parks, station capacity, nearby employment density, or event calendars), rather than additional broad “calendar context” variables.\n\n## Deployment and Operational Considerations\n\nFrom an operations standpoint, the value of our forecasts is not in perfectly predicting trip counts, but in anticipating when stations are likely to drift toward stockouts (no bikes) or dockouts (no docks) during high-stakes windows. Our results suggest that the “best” model (Model 2 with temporal lags) is reasonably stable across seasons, but errors are largest during rush-hour periods—exactly when rebalancing decisions matter most. That implies a practical deployment rule: the model should be used as a screening tool to prioritize stations for truck routes before commute peaks, rather than as a fully automated decision-maker. In other words, even if the average MAE is modest, the operational risk concentrates in the times and places where a few missed calls can lead to many lost trips.\n\nIf Indego were to deploy this system, we would recommend it be part of a larger system that aims to flag or capture potentially vulnerable stations that other robust systems can examine and further provide isnight/recommendations on it. The seasonal comparison also showed that Q2 is harder to predict overall (higher MAEs across models), Indego should treat summer deployment as more uncertain and add safeguards—like conservative thresholds that prioritize avoiding stockouts in the busiest areas even at the expense of occasional unnecessary rebalancing.\n\n------------------------------------------------------------------------\n\n# Technical Appendix\n\nThe technical appendix provides the supporting details behind our modeling workflow and results, documenting the full data pipeline and analytical choices used to generate the figures and performance metrics in the main report. It includes the steps for cleaning and aggregating Indego trip data into a station-by-hour panel, merging station-level census context and hourly weather measures, constructing temporal lag features, and implementing the quarter-specific temporal train/test splits. We also report model specifications, evaluation procedures (including MAE computation), and additional diagnostics and feature-engineering extensions (e.g., quadratic weather terms and holiday/university calendar indicators) so that the analysis is transparent, reproducible, and easy to audit or extend.\n\n## Reproducing In-Class Q1 Results\n\nThis section reproduces the analytical approach for Q1 analysis conducted in class.\n\n### 0.0 \\| Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(tigris)\nlibrary(tidycensus)\nlibrary(broom)\nlibrary(here)\nlibrary(riem)  # For Philadelphia weather from ASOS stations\n\n# Visualization\nlibrary(viridis)\nlibrary(gridExtra)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(gganimate)\n\noptions(scipen = 999)\n\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", size = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n:::\n\n\n\n\n### 0.1 \\| Load and Process Indego Trip Data\n\n**Importing Data**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summon indego data from Q1 & Q2\n\nindego <- read_csv(\"data/indego-trips-2025-q1.csv\")\nindego_q2 <- read_csv(\"data/indego-trips-2025-q2.csv\")\n\n# Helper function to create time bins – aggregate trips into hourly intervals for panel data structure\n\nindego <- indego %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n**Daily Trip Counts**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaily_trips <- indego %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q1 2025\",\n    subtitle = \"Winter demand patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/trips_over_time-1.png){width=672}\n:::\n:::\n\n\nThere is certainlly month-specific demands that look both seasonal and event-driven.\n\n**Hourly Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Average trips by hour and day type\nhourly_patterns <- indego %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date)) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(hourly_patterns, aes(x = hour, y = avg_trips, color = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Average Hourly Ridership Patterns - Q1 2025\",\n    subtitle = \"Clear commute patterns on weekdays\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Day Type\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/hourly_patterns-1.png){width=672}\n:::\n:::\n\n\nClear spikes during the weekday at specific AM and PM rush hours.\n\n**Top Stations**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Most popular origin stations\ntop_stations <- indego %>%\n  count(start_station, start_lat, start_lon, name = \"trips\") %>%\n  arrange(desc(trips)) %>%\n  head(20)\n\nkable(top_stations, \n      caption = \"Top 20 Indego Stations by Trip Origins - Q1 2025\",\n      format.args = list(big.mark = \",\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Top 20 Indego Stations by Trip Origins - Q1 2025</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> start_station </th>\n   <th style=\"text-align:right;\"> start_lat </th>\n   <th style=\"text-align:right;\"> start_lon </th>\n   <th style=\"text-align:right;\"> trips </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 3,010 </td>\n   <td style=\"text-align:right;\"> 39.94711 </td>\n   <td style=\"text-align:right;\"> -75.16618 </td>\n   <td style=\"text-align:right;\"> 3,999 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,032 </td>\n   <td style=\"text-align:right;\"> 39.94527 </td>\n   <td style=\"text-align:right;\"> -75.17971 </td>\n   <td style=\"text-align:right;\"> 2,842 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,359 </td>\n   <td style=\"text-align:right;\"> 39.94888 </td>\n   <td style=\"text-align:right;\"> -75.16978 </td>\n   <td style=\"text-align:right;\"> 2,699 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,020 </td>\n   <td style=\"text-align:right;\"> 39.94855 </td>\n   <td style=\"text-align:right;\"> -75.19007 </td>\n   <td style=\"text-align:right;\"> 2,673 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,208 </td>\n   <td style=\"text-align:right;\"> 39.95048 </td>\n   <td style=\"text-align:right;\"> -75.19324 </td>\n   <td style=\"text-align:right;\"> 2,503 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,244 </td>\n   <td style=\"text-align:right;\"> 39.93865 </td>\n   <td style=\"text-align:right;\"> -75.16674 </td>\n   <td style=\"text-align:right;\"> 2,486 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,066 </td>\n   <td style=\"text-align:right;\"> 39.94561 </td>\n   <td style=\"text-align:right;\"> -75.17348 </td>\n   <td style=\"text-align:right;\"> 2,396 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,362 </td>\n   <td style=\"text-align:right;\"> 39.94816 </td>\n   <td style=\"text-align:right;\"> -75.16226 </td>\n   <td style=\"text-align:right;\"> 2,387 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,012 </td>\n   <td style=\"text-align:right;\"> 39.94218 </td>\n   <td style=\"text-align:right;\"> -75.17747 </td>\n   <td style=\"text-align:right;\"> 2,361 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,028 </td>\n   <td style=\"text-align:right;\"> 39.94061 </td>\n   <td style=\"text-align:right;\"> -75.14958 </td>\n   <td style=\"text-align:right;\"> 2,348 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,161 </td>\n   <td style=\"text-align:right;\"> 39.95486 </td>\n   <td style=\"text-align:right;\"> -75.18091 </td>\n   <td style=\"text-align:right;\"> 2,278 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,101 </td>\n   <td style=\"text-align:right;\"> 39.94295 </td>\n   <td style=\"text-align:right;\"> -75.15955 </td>\n   <td style=\"text-align:right;\"> 2,274 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,295 </td>\n   <td style=\"text-align:right;\"> 39.95028 </td>\n   <td style=\"text-align:right;\"> -75.16027 </td>\n   <td style=\"text-align:right;\"> 2,160 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,054 </td>\n   <td style=\"text-align:right;\"> 39.96250 </td>\n   <td style=\"text-align:right;\"> -75.17420 </td>\n   <td style=\"text-align:right;\"> 2,123 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,185 </td>\n   <td style=\"text-align:right;\"> 39.95169 </td>\n   <td style=\"text-align:right;\"> -75.15888 </td>\n   <td style=\"text-align:right;\"> 2,116 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,038 </td>\n   <td style=\"text-align:right;\"> 39.94781 </td>\n   <td style=\"text-align:right;\"> -75.19409 </td>\n   <td style=\"text-align:right;\"> 2,111 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,203 </td>\n   <td style=\"text-align:right;\"> 39.94077 </td>\n   <td style=\"text-align:right;\"> -75.17227 </td>\n   <td style=\"text-align:right;\"> 2,106 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,059 </td>\n   <td style=\"text-align:right;\"> 39.96244 </td>\n   <td style=\"text-align:right;\"> -75.16121 </td>\n   <td style=\"text-align:right;\"> 2,027 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,022 </td>\n   <td style=\"text-align:right;\"> 39.95472 </td>\n   <td style=\"text-align:right;\"> -75.18323 </td>\n   <td style=\"text-align:right;\"> 2,014 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,063 </td>\n   <td style=\"text-align:right;\"> 39.94633 </td>\n   <td style=\"text-align:right;\"> -75.16980 </td>\n   <td style=\"text-align:right;\"> 2,014 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThere is some clustering on which stations are most used and they appeared to be located in both center city - old city as well as university city.\n\n### 0.2 \\| Load Philadelphia Census Data\n\n\n::: {.cell progress='false'}\n\n```{.r .cell-code}\n# Get Philadelphia census tracts\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    \"B01003_001\",  # Total population\n    \"B19013_001\",  # Median household income\n    \"B08301_001\",  # Total commuters\n    \"B08301_010\",  # Commute by transit\n    \"B02001_002\",  # White alone\n    \"B25077_001\"   # Median home value\n  ),\n  state = \"PA\",\n  county = \"Philadelphia\",\n  year = 2022,\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  rename(\n    Total_Pop = B01003_001E,\n    Med_Inc = B19013_001E,\n    Total_Commuters = B08301_001E,\n    Transit_Commuters = B08301_010E,\n    White_Pop = B02001_002E,\n    Med_Home_Value = B25077_001E\n  ) %>%\n  mutate(\n    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,\n    Percent_White = (White_Pop / Total_Pop) * 100\n  ) %>%\n  st_transform(crs = 4326)  # WGS84 for lat/lon matching\n```\n:::\n\n\n**Map Philadelphia Context**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Map median income\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = NA) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Context for understanding bike share demand patterns\"\n  ) +\n  # Stations \n  geom_point(\n    data = indego,\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 0.4, alpha = 0.6\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/map-philly-1.png){width=672}\n:::\n:::\n\n\nWe note, once again, that the majority of the indego stations are clustered around center city and university city servicing a largely urban and younger population.\n\n**Join Census Data to Stations**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create sf object for stations\nstations_sf <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\n# Spatial join to get census tract for each station\nstations_census <- st_join(stations_sf, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n```\n:::\n\n\n**Left-Join Census Data to Q1 Indego Data**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Flag stations in non-residential census tracts\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Add back to trip data\nindego_census <- indego %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n# Prepare data for visualization\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Create the map showing problem stations\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = \"white\", size = 0.1) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar,\n    na.value = \"grey90\"\n  ) +\n  # Stations with census data (small grey dots)\n  geom_point(\n    data = stations_for_map %>% filter(has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"grey30\", size = 1, alpha = 0.6\n  ) +\n  # Stations WITHOUT census data (red X marks the spot)\n  geom_point(\n    data = stations_for_map %>% filter(!has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 1, shape = 4, stroke = 1.5\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Indego stations shown (RED = no census data match)\",\n    caption = \"Red X marks indicate stations that didn't join to census tracts\"\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nGiven the abundance of stations that cannot be tied to residential census datapoints, we opt to drop those stations from our analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Identify which stations to keep\nvalid_stations <- stations_census %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\n# Filter trip data to valid stations only\nindego_census <- indego %>%\n  filter(start_station %in% valid_stations) %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n```\n:::\n\n\n### 0.3 \\| Get Weather Data\n\n**Weather Data for Q1 2025**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get weather from Philadelphia International Airport (KPHL)\n# This covers Q1 2025: January 1 - March 31\nweather_data <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2025-01-01\",\n  date_end = \"2025-03-31\"\n)\n\n# Process weather data\nweather_processed <- weather_data %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  # updated in-class code to only keep the first row for each hour\n  distinct(interval60, .keep_all = TRUE) \n\n# Check for missing hours and interpolate if needed\nweather_complete <- weather_processed %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n```\n:::\n\n\n**Visualize Weather Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q1 2025\",\n    subtitle = \"Winter to Early Spring Transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nClear relationship showcasing increase in demand dependent on weather patterns.\n\n### 0.4 \\| Aggregate Trips to Station-Hour Level\n\n**Q1 2025**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count trips by station-hour\ntrips_panel <- indego_census %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n```\n:::\n\n\n**Create Complete Panel Structure**\n\nNot every station has trips every hour. We need a **complete panel** where every station-hour combination exists (even if Trip_Count = 0).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate expected panel size\nn_stations <- length(unique(trips_panel$start_station))\nn_hours <- length(unique(trips_panel$interval60))\nexpected_rows <- n_stations * n_hours\n\n# Create complete panel\nstudy_panel <- expand.grid(\n  interval60 = unique(trips_panel$interval60),\n  start_station = unique(trips_panel$start_station)\n) %>%\n  # Join trip counts\n  left_join(trips_panel, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Fill in station attributes (they're the same for all hours)\nstation_attributes <- trips_panel %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_panel <- study_panel %>%\n  left_join(station_attributes, by = \"start_station\")\n```\n:::\n\n\nWe find 410,032 missing datapoints, or rather hour-station datapoints. After completing the panel we achieve a pnael row of 526,750.\n\n**Add Time Features**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n**Join Weather Data**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  left_join(weather_complete, by = \"interval60\")\n```\n:::\n\n\n### 0.5 \\| Create Temporal Lags\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sort by station and time\nstudy_panel <- study_panel %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_panel <- study_panel %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_panel_complete <- study_panel %>%\n  filter(!is.na(lag1day))\n```\n:::\n\n\n**Visualize Lag Correlations**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sample one station to visualize\nexample_station <- study_panel_complete %>%\n  filter(start_station == first(start_station)) %>%\n  head(168)  # One week\n\n# Plot actual vs lagged demand\nggplot(example_station, aes(x = interval60)) +\n  geom_line(aes(y = Trip_Count, color = \"Current\"), linewidth = 1) +\n  geom_line(aes(y = lag1Hour, color = \"1 Hour Ago\"), linewidth = 1, alpha = 0.7) +\n  geom_line(aes(y = lag1day, color = \"24 Hours Ago\"), linewidth = 1, alpha = 0.7) +\n  scale_color_manual(values = c(\n    \"Current\" = \"#08519c\",\n    \"1 Hour Ago\" = \"#3182bd\",\n    \"24 Hours Ago\" = \"#6baed6\"\n  )) +\n  labs(\n    title = \"Temporal Lag Patterns at One Station\",\n    subtitle = \"Past demand predicts future demand\",\n    x = \"Date-Time\",\n    y = \"Trip Count\",\n    color = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nOne might argue that 24 hour ago appears to have the most relationship across pattenrs of demand at individual stations.\n\n### 0.6 \\| Temporal Train/Test Split\n\nApproach: Train on Past Data and Test on Future Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Train on weeks 1-9 (Jan 1 - early March)\n# Test on weeks 10-13 (rest of March)\n\n# Which stations have trips in BOTH early and late periods?\nearly_stations <- study_panel_complete %>%\n  filter(week < 10) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations <- study_panel_complete %>%\n  filter(week >= 10) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\n# Keep only stations that appear in BOTH periods\ncommon_stations <- intersect(early_stations, late_stations)\n\n\n# Filter panel to only common stations\nstudy_panel_complete <- study_panel_complete %>%\n  filter(start_station %in% common_stations)\n\n# NOW create train/test split\ntrain <- study_panel_complete %>%\n  filter(week < 10)\n\ntest <- study_panel_complete %>%\n  filter(week >= 10)\n```\n:::\n\n\n**Model 1: Baseline (Time + Weather)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntrain <- train %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\nmodel1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train\n)\n```\n:::\n\n\n**Model 2: Add Temporal Lags**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation + \n    lag1Hour + lag3Hours + lag1day, # temporal lags\n  data = train\n)\n```\n:::\n\n\n**Model 3: Add Demographics**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y, # demographics\n  data = train\n)\n```\n:::\n\n\n**Model 4: Add Station Fixed Effects**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel4 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station), # station fixed effects\n  data = train\n)\n```\n:::\n\n\n**Model 5: Add Rush Hour Interaction**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel5 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station) +\n    rush_hour * weekend,  # Rush hour effects different on weekends\n  data = train\n)\n```\n:::\n\n\n**R-squared Fit For Each Model**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrsq_tbl <- tibble::tibble(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  R2 = c(\n    summary(model1)$r.squared,\n    summary(model2)$r.squared,\n    summary(model3)$r.squared,\n    summary(model4)$r.squared,\n    summary(model5)$r.squared\n  ),\n  Adj_R2 = c(\n    summary(model1)$adj.r.squared,\n    summary(model2)$adj.r.squared,\n    summary(model3)$adj.r.squared,\n    summary(model4)$adj.r.squared,\n    summary(model5)$adj.r.squared\n  )\n) %>%\n  mutate(\n    R2 = round(R2, 3),\n    Adj_R2 = round(Adj_R2, 3)\n  )\n\nkable(\n  rsq_tbl,\n  caption = \"Model Fit (Training Set): R-squared and Adjusted R-squared\",\n  col.names = c(\"Model\", \"R\\u00B2\", \"Adj. R\\u00B2\")\n) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Model Fit (Training Set): R-squared and Adjusted R-squared</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> R² </th>\n   <th style=\"text-align:right;\"> Adj. R² </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.079 </td>\n   <td style=\"text-align:right;\"> 0.079 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.229 </td>\n   <td style=\"text-align:right;\"> 0.229 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. + Demographics </td>\n   <td style=\"text-align:right;\"> 0.155 </td>\n   <td style=\"text-align:right;\"> 0.154 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4. + Station FE </td>\n   <td style=\"text-align:right;\"> 0.179 </td>\n   <td style=\"text-align:right;\"> 0.176 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.184 </td>\n   <td style=\"text-align:right;\"> 0.181 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### 0.7 \\| Predictions on Test Set and MAE\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntest <- test %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n\ntest <- test %>%\n  mutate(\n    pred1 = predict(model1, newdata = test),\n    pred2 = predict(model2, newdata = test),\n    pred3 = predict(model3, newdata = test),\n    pred4 = predict(model4, newdata = test),\n    pred5 = predict(model5, newdata = test)\n  )\n\n# Calculate MAE for each model\nmae_results <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred1), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred3), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred4), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred5), na.rm = TRUE)\n  )\n)\n\nkable(mae_results, \n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Mean Absolute Error by Model (Test Set)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> MAE (trips) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.62 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.54 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. + Demographics </td>\n   <td style=\"text-align:right;\"> 0.77 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4. + Station FE </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.75 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Visualize Model Comparison**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mae_results, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +\n  labs(\n    title = \"Model Performance Comparison\",\n    subtitle = \"Lower MAE = Better Predictions\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n### 0.8 \\| Observed vs Predicted\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- test %>%\n  mutate(\n    error = Trip_Count - pred2,\n    abs_error = abs(error),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      hour > 18 ~ \"Evening\"\n    )\n  )\n\n# Scatter plot by time and day type\nggplot(test, aes(x = Trip_Count, y = pred2)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Bike Trips\",\n    subtitle = \"Model 2 performance by time period\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\",\n    caption = \"Red line = perfect predictions; Green line = actual model fit\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/obs-vs-pred-1.png){width=672}\n:::\n:::\n\n\n**Spatial Error Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate MAE by Station\nstation_errors <- test %>%\n  filter(!is.na(pred2)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\nbase_map <- ggplot() +\n  geom_sf(data = philly_census,\n          fill = \"grey95\", color = \"white\", linewidth = 0.2) +\n  mapTheme\n\n# Map 1: Prediction Errors (MAE)\np_err <- base_map +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size = 0.6,\n    alpha = 0.85\n  ) +\n  scale_color_viridis_c(\n    option   = \"plasma\",\n    direction = -1,\n    name     = \"MAE (trips)\"\n  ) +\n  labs(\n    title    = \"Prediction Errors\",\n    subtitle = \"MAE per station\"\n  ) +\n  theme(\n    legend.title = element_text(size = 10),\n    legend.text  = element_text(size = 8)\n  )\n\n# Map 2: Average Trip Demand\np_demand <- base_map +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 0.6,\n    alpha = 0.85\n  ) +\n  scale_color_viridis_c(\n    option   = \"viridis\",\n    direction = 1,\n    name     = \"Avg demand\\n(trips/hr)\"\n  ) +\n  labs(\n    title    = \"Average Demand\",\n    subtitle = \"Trips per station-hour\"\n  ) +\n  theme(\n    legend.title = element_text(size = 10),\n    legend.text  = element_text(size = 8)\n  )\n\ngrid.arrange(p_err, p_demand, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/spatial-errors-1.png){width=672}\n:::\n:::\n\n\n**Temporal Error Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MAE by time of day and day type\ntemporal_errors <- test %>%\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time Period\",\n    subtitle = \"When is the model struggling most?\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/temporal-errors-1.png){width=672}\n:::\n:::\n\n\n**Demographic Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join demographic data to station errors\nstation_errors_demo <- station_errors %>%\n  left_join(\n    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\n# Create plots\np1 <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Errors vs. Median Income\", x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\np2 <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Transit Usage\", x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\np3 <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Race\", x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(p1, p2, p3, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/demographic-errors-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Assessing Q2 2025 Indego Bikeshare Patterns\n\n### 1.0 \\| Data Cleaning/Wrangling for Q2 2025\n\n**Create Time Bins**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindego_q2 <- indego_q2 %>%\n  mutate(\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins and extract time features\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n**Daily Trip Counts**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaily_trips <- indego_q2 %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q2 2025\",\n    subtitle = \"Spring demand patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nA differing pattern from Q1, rather there is no sudden spikes, rather the pattern fluctuates within arguably similar margins throughout the quartile.\n\n**Filter out Non-Residential Bike Share Stations**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter trip data to valid stations only\nindego_q2_census <- indego_q2 %>%\n  filter(start_station %in% valid_stations) %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n```\n:::\n\n\n### 1.1 \\| Space-Time Panel\n\n**Aggregate Trips to Station-Hour Level**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrips_q2_panel <- indego_q2_census %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n```\n:::\n\n\n**Create Complete Panel**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_q2_panel <- expand.grid(\n  interval60 = unique(trips_q2_panel$interval60),\n  start_station = unique(trips_q2_panel$start_station)\n) %>%\n  # Join trip counts\n  left_join(trips_q2_panel, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Fill in station attributes (they're the same for all hours)\nstation_q2_attributes <- trips_q2_panel %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_q2_panel <- study_q2_panel %>%\n  left_join(station_q2_attributes, by = \"start_station\")\n```\n:::\n\n\n**Add Time Features**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_q2_panel <- study_q2_panel %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n**Join Weather Data**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_q2 <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2025-04-01\",\n  date_end = \"2025-06-30\"\n)\n\n# Process weather data\nweather_q2 <- weather_q2 %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  # updated in-class code to only keep the first row for each hour\n  distinct(interval60, .keep_all = TRUE) \n\n# Check for missing hours and interpolate if needed\nweather_q2_complete <- weather_q2 %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\nstudy_q2_panel <- study_q2_panel %>%\n  left_join(weather_q2, by = \"interval60\")\n#summary(study_q2_panel %>% select(Trip_Count, Temperature, Precipitation))\n\nggplot(weather_q2_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q2 2025\",\n    subtitle = \"Spring to Summer Transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n### 1.2 \\| Create Temporal Lag Variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_q2 <- study_q2_panel %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_q2 <- study_q2 %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_q2_complete <- study_q2 %>%\n  filter(!is.na(lag1day))\n```\n:::\n\n\n### 1.3 \\| Build 5 Predictive Models\n\n**Temporal Train/Test Split**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Train on Weeks 14-22\n# Test on Weeks 23-26\nearly_q2_stations <- study_q2_complete %>%\n  filter(week < 23) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_q2_stations <- study_q2_complete %>%\n  filter(week >= 23) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\ncommon_q2_stations <- intersect(early_q2_stations, \n                                late_q2_stations)\n\n# Filter panel to only common stations\nstudy_q2_complete <- study_q2_complete %>%\n  filter(start_station %in% common_q2_stations)\n\n# create train/test split\ntrain_q2 <- study_q2_complete %>%\n  filter(week < 23)\n\ntest_q2 <- study_q2_complete %>%\n  filter(week >= 23)\n```\n:::\n\n\n**Model 1: Baseline (Time + Weather)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_q2 <- train_q2 %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ncontrasts(train_q2$dotw_simple) <- contr.treatment(7)\n\nmodel1_q2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train_q2\n)\n```\n:::\n\n\n**Model 2: Add Temporal Lags**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2_q2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation + \n    lag1Hour + lag3Hours + lag1day,\n  data = train_q2\n)\n```\n:::\n\n\n**Model 3: Add Demographics**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3_q2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y,\n  data = train_q2\n)\n```\n:::\n\n\n**Model 4: Add Station Fixed Effects**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel4_q2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station),\n  data = train_q2\n)\n```\n:::\n\n\n**Model 5: Add Rush Hour Interaction**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel5_q2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station) +\n    rush_hour * weekend,  # Rush hour effects different on weekends\n  data = train_q2\n)\n```\n:::\n\n\n**R-squared Fit For Each Model**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrsq_tbl2 <- tibble::tibble(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  R2 = c(\n    summary(model1_q2)$r.squared,\n    summary(model2_q2)$r.squared,\n    summary(model3_q2)$r.squared,\n    summary(model4_q2)$r.squared,\n    summary(model5_q2)$r.squared\n  ),\n  Adj_R2 = c(\n    summary(model1_q2)$adj.r.squared,\n    summary(model2_q2)$adj.r.squared,\n    summary(model3_q2)$adj.r.squared,\n    summary(model4_q2)$adj.r.squared,\n    summary(model5_q2)$adj.r.squared\n  )\n) %>%\n  mutate(\n    R2 = round(R2, 3),\n    Adj_R2 = round(Adj_R2, 3)\n  )\n\nkable(\n  rsq_tbl,\n  caption = \"Model Fit (Training Set): R-squared and Adjusted R-squared\",\n  col.names = c(\"Model\", \"R\\u00B2\", \"Adj. R\\u00B2\")\n) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), full_width = FALSE)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Model Fit (Training Set): R-squared and Adjusted R-squared</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> R² </th>\n   <th style=\"text-align:right;\"> Adj. R² </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.079 </td>\n   <td style=\"text-align:right;\"> 0.079 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.229 </td>\n   <td style=\"text-align:right;\"> 0.229 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. + Demographics </td>\n   <td style=\"text-align:right;\"> 0.155 </td>\n   <td style=\"text-align:right;\"> 0.154 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4. + Station FE </td>\n   <td style=\"text-align:right;\"> 0.179 </td>\n   <td style=\"text-align:right;\"> 0.176 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.184 </td>\n   <td style=\"text-align:right;\"> 0.181 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### 1.4 \\| Model Evaluation\n\n**Prediction on Test Set and MAE**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntest_q2 <- test_q2 %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ntest_q2 <- test_q2 %>%\n  mutate(\n    pred1 = predict(model1_q2, newdata = test_q2),\n    pred2 = predict(model2_q2, newdata = test_q2),\n    pred3 = predict(model3_q2, newdata = test_q2),\n    pred4 = predict(model4_q2, newdata = test_q2),\n    pred5 = predict(model5_q2, newdata = test_q2)\n  )\n\n# Calculate MAE for each model\nmae_results_q2 <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test_q2$Trip_Count - test_q2$pred1), na.rm = TRUE),\n    mean(abs(test_q2$Trip_Count - test_q2$pred2), na.rm = TRUE),\n    mean(abs(test_q2$Trip_Count - test_q2$pred3), na.rm = TRUE),\n    mean(abs(test_q2$Trip_Count - test_q2$pred4), na.rm = TRUE),\n    mean(abs(test_q2$Trip_Count - test_q2$pred5), na.rm = TRUE)\n  )\n)\n\nkable(mae_results_q2, \n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Test Set) - Q2 2025\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Mean Absolute Error by Model (Test Set) - Q2 2025</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> MAE (trips) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.84 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.70 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. + Demographics </td>\n   <td style=\"text-align:right;\"> 0.94 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4. + Station FE </td>\n   <td style=\"text-align:right;\"> 0.92 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.96 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Visualize Model Comparison**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mae_results_q2, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +\n  labs(\n    title = \"Model Performance Comparison - Q2 2025\",\n    subtitle = \"Lower MAE = Better Predictions\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n### 1.5 \\| Space-Time Error Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_q2 <- test_q2 %>%\n  mutate(\n    error = Trip_Count - pred2,\n    abs_error = abs(error),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      hour > 18 ~ \"Evening\"\n    )\n  )\n\n# Scatter plot by time and day type\nggplot(test_q2, aes(x = Trip_Count, y = pred2)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Bike Trips - Q2 2025\",\n    subtitle = \"Model 2 performance by time period\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\",\n    caption = \"Red line = perfect predictions; Green line = actual model fit\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n**Spatial Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate MAE by Station\nstation_errors_q2 <- test_q2 %>%\n  filter(!is.na(pred2)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n# Base Map\nbase_map <- ggplot() +\n  geom_sf(data = philly_census,\n          fill = \"grey95\", color = \"white\", linewidth = 0.2) +\n  mapTheme\n\n# Map 1: Prediction Errors (MAE)\np_err_q2 <- base_map +\n  geom_point(\n    data = station_errors_q2,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size = 0.6, alpha = 0.85\n  ) +\n  scale_color_viridis_c(option = \"plasma\", direction = -1, name = \"MAE (trips)\") +\n  labs(\n    title    = \"Prediction Errors\",\n    subtitle = \"MAE per station\"\n  ) +\n  theme(\n    legend.title = element_text(size = 10),\n    legend.text  = element_text(size = 8)\n  )\n\n# Map 2: Average Trip Demand\np_demand_q2 <- base_map +\n  geom_point(\n    data = station_errors_q2,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 0.6, alpha = 0.85\n  ) +\n  scale_color_viridis_c(option = \"viridis\",\n    direction = 1, name = \"Avg demand\\n(trips/hr)\"\n  ) +\n  labs(\n    title    = \"Average Demand\",\n    subtitle = \"Trips per station-hour\"\n  ) +\n  theme(\n    legend.title = element_text(size = 10),\n    legend.text  = element_text(size = 8)\n  )\n\ngrid.arrange(p_err_q2, p_demand_q2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n**Temporal Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MAE by time of y and day type\ntemporal_errors_q2 <- test_q2 %>%\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors_q2, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time Period - Q2 2025\",\n    subtitle = \"When is the model struggling most?\",\n    x = \"Time of Day\",\n    y = \"MAE (trips)\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n**Demographic Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join demographic data to station errors\nstation_errors_demo_q2 <- station_errors_q2 %>%\n  left_join(\n    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\n# Create plots\np1_q2 <- ggplot(station_errors_demo_q2, aes(x = Med_Inc, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Errors vs. Median Income\", x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\np2_q2 <- ggplot(station_errors_demo_q2, aes(x = Percent_Taking_Transit, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Transit Usage\", x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\np3_q2 <- ggplot(station_errors_demo_q2, aes(x = Percent_White, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Race\", x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(p1_q2, p2_q2, p3_q2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n## Error Analysis for Q2 2025 vs Q1 2025\n\n### 2.0 \\| Compare MAE Across Quarters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmae_all <- bind_rows(\n  mae_results    %>% mutate(Quarter = \"Q1 2025\"),\n  mae_results_q2 %>% mutate(Quarter = \"Q2 2025\")\n)\nmae_wide <- mae_all %>%\n  pivot_wider(names_from = Quarter, values_from = MAE)\n\nkable(\n  mae_wide,\n  digits  = 2,\n  caption = \"Mean Absolute Error by Model: Q1 vs Q2 2025\",\n  col.names = c(\"Model\", \"Q1 2025 MAE (trips)\", \"Q2 2025 MAE (trips)\")\n) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Mean Absolute Error by Model: Q1 vs Q2 2025</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> Q1 2025 MAE (trips) </th>\n   <th style=\"text-align:right;\"> Q2 2025 MAE (trips) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.62 </td>\n   <td style=\"text-align:right;\"> 0.84 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.54 </td>\n   <td style=\"text-align:right;\"> 0.70 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. + Demographics </td>\n   <td style=\"text-align:right;\"> 0.77 </td>\n   <td style=\"text-align:right;\"> 0.94 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4. + Station FE </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n   <td style=\"text-align:right;\"> 0.92 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.75 </td>\n   <td style=\"text-align:right;\"> 0.96 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\nggplot(mae_all, aes(x = Model, y = MAE, fill = Quarter)) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  labs(\n    title = \"Model Performance by Quarter\",\n    y = \"MAE (trips)\",\n    x = NULL\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n### 2.1 \\| Temporal Error Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 2. Temporal error patterns (time-of-day, by quarter\ntemporal_all <- bind_rows(\n  temporal_errors    %>% mutate(Quarter = \"Q1 2025\"),\n  temporal_errors_q2 %>% mutate(Quarter = \"Q2 2025\")\n) %>%\n  # Optional: enforce an ordering of time-of-day buckets if you have them\n  mutate(\n    time_of_day = factor(time_of_day,\n                         levels = unique(time_of_day))  # or your own ordered vector\n  )\n\nggplot(temporal_all,\n       aes(x = time_of_day, y = MAE, fill = Quarter)) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ day_type) +\n  labs(\n    title = \"Prediction Errors by Time of Day\",\n    subtitle = \"Q1 vs Q2 2025\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Quarter\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\n### 2.2 \\| Spatial Error Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstations_all <- bind_rows(\n  station_errors    %>% mutate(Quarter = \"Q1 2025\"),\n  station_errors_q2 %>% mutate(Quarter = \"Q2 2025\")\n)\n\nggplot() +\n  geom_sf(data = philly_census,\n          fill = \"grey95\", color = \"white\", linewidth = 0.2) +\n  geom_point(\n    data = stations_all,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size  = 1.3,\n    alpha = 0.85\n  ) +\n  facet_wrap(~ Quarter) +\n  scale_color_viridis_c(name = \"MAE (trips)\") +\n  labs(\n    title = \"Spatial Distribution of Prediction Errors\",\n    subtitle = \"Station-level MAE by quarter\",\n    x = NULL, y = NULL\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\n### 2.3 \\| Features That Matter Most\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# NOTE: this is a simple coefficient comparison; ideally predictors are standardized.\n\nimp_q1 <- tidy(model2) %>%\n  filter(term != \"(Intercept)\") %>%\n  mutate(Quarter = \"Q1 2025\")\n\nimp_q2 <- tidy(model2_q2) %>%\n  filter(term != \"(Intercept)\") %>%\n  mutate(Quarter = \"Q2 2025\")\n\nimp_all <- bind_rows(imp_q1, imp_q2) %>%\n  mutate(abs_est = abs(estimate)) %>%\n  group_by(Quarter) %>%\n  slice_max(order_by = abs_est, n = 10) %>%\n  ungroup()\n\nggplot(imp_all,\n       aes(x = reorder(term, abs_est), y = abs_est, fill = Quarter)) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  labs(\n    title = \"Most Influential Features (Model 2)\",\n    x = \"Predictor (top 10 per quarter)\",\n    y = \"|Coefficient|\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Feature Engineering & model improvement\n\nOur baseline comparisons show that Model 2 (Time + Weather + Temporal Lags) is consistently the strongest performer in both quarters, but the Q2 error diagnostics reveal where that baseline still breaks down. In Q2 2025, prediction errors rise sharply during high-variance travel windows—especially the PM rush hour—and cluster spatially in the highest-demand parts of the network (Center City and University City). These are precisely the hours and locations where Indego operations face the greatest risk of stockouts and dockouts, meaning that even modest average error can translate into meaningful service failures when demand shifts rapidly. This pattern suggests that while short-run persistence (recent lags) captures routine momentum well, the model is still missing structured drivers that create recurring surges and dips beyond “hour + day-of-week + current weather.”\n\nWe therefore introduce new features with a targeted goal: to convert some of the remaining “unexplained volatility” into predictable structure. First, we expand temporal memory by adding a weekly lag (same station, same hour, one week prior) to better capture repeating weekly rhythms that often govern commuting and scheduled travel. Second, we allow weather to influence riding nonlinearly by adding quadratic temperature and precipitation terms, reflecting the reality that biking responds to thresholds (pleasant vs. unpleasant conditions) rather than changing in a purely linear way. Third, because Q2 includes calendar-driven disruptions (holidays, long weekends, and university schedule effects) that can shift demand patterns in the urban core, we add holiday timing indicators (holiday, day-before, day-after) and university in-session/no-classes flags. Together, these additions are designed to improve performance in the same “stress test” settings highlighted by the error analysis—peak periods and core stations—without changing the overall modeling pipeline or evaluation approach, so any improvement in MAE can be attributed directly to the new feature information rather than to a different training or testing design.\n\n### 3.0 \\| Declaring Helper Functions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmake_in_range <- function(dates, ranges_df) {\n  out <- rep(FALSE, length(dates))\n  for (i in seq_len(nrow(ranges_df))) {\n    out <- out | (dates >= ranges_df$start[i] & dates <= ranges_df$end[i])\n  }\n  as.integer(out)\n}\n\nadd_holiday_flags_2025 <- function(df) {\n  holidays_2025 <- tibble::tribble(\n    ~holiday_name,     ~holiday_date,\n    \"NewYearsDay\",     as.Date(\"2025-01-01\"),\n    \"MLKDay\",          as.Date(\"2025-01-20\"),\n    \"PresidentsDay\",   as.Date(\"2025-02-17\"),\n    \"MemorialDay\",     as.Date(\"2025-05-26\"),\n    \"Juneteenth\",      as.Date(\"2025-06-19\")\n  )\n\n  df %>%\n    mutate(date = as.Date(interval60)) %>%\n    left_join(holidays_2025 %>% transmute(date = holiday_date, holiday = 1L), by = \"date\") %>%\n    mutate(\n      holiday = replace_na(holiday, 0L),\n      day_before_holiday = as.integer(date %in% (holidays_2025$holiday_date - 1)),\n      day_after_holiday  = as.integer(date %in% (holidays_2025$holiday_date + 1))\n    )\n}\n\nadd_univ_calendar_flags <- function(df, penn_class_ranges, penn_no_class_ranges,\n                                    drexel_class_ranges, drexel_no_class_ranges,\n                                    temple_class_ranges, temple_no_class_ranges) {\n\n  df %>%\n    mutate(date = as.Date(interval60)) %>%\n    mutate(\n      penn_in_session   = make_in_range(date, penn_class_ranges),\n      penn_no_classes   = make_in_range(date, penn_no_class_ranges),\n\n      drexel_in_session = make_in_range(date, drexel_class_ranges),\n      drexel_no_classes = make_in_range(date, drexel_no_class_ranges),\n\n      temple_in_session = make_in_range(date, temple_class_ranges),\n      temple_no_classes = make_in_range(date, temple_no_class_ranges),\n\n      any_univ_in_session = as.integer((penn_in_session + drexel_in_session + temple_in_session) > 0),\n      any_univ_no_classes = as.integer((penn_no_classes + drexel_no_classes + temple_no_classes) > 0)\n    )\n}\n\nadd_model2_lags <- function(df) {\n  df %>%\n    arrange(start_station, interval60) %>%\n    group_by(start_station) %>%\n    mutate(\n      lag1Hour  = lag(Trip_Count, 1),\n      lag3Hours = lag(Trip_Count, 3),\n      lag1day   = lag(Trip_Count, 24),\n      lag1week  = lag(Trip_Count, 168)\n    ) %>%\n    ungroup() %>%\n    filter(!is.na(lag1week))\n}\n```\n:::\n\n\n### 3.1 \\| University Calander\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# PENN\npenn_class_ranges <- tibble::tribble(\n  ~start,              ~end,\n  as.Date(\"2025-08-26\"), as.Date(\"2025-12-08\"),  # fall classes window (first day -> last day)\n  as.Date(\"2026-01-14\"), as.Date(\"2026-04-29\"),  # spring classes window\n  as.Date(\"2026-05-26\"), as.Date(\"2026-08-07\")   # summer classes (11-week + sessions)\n)\n\npenn_no_class_ranges <- tibble::tribble(\n  ~start,              ~end,\n  as.Date(\"2025-09-01\"), as.Date(\"2025-09-01\"),  # Labor Day no classes\n  as.Date(\"2025-10-09\"), as.Date(\"2025-10-12\"),  # Fall Term Break\n  as.Date(\"2025-11-27\"), as.Date(\"2025-11-30\"),  # Thanksgiving Break\n  as.Date(\"2026-01-19\"), as.Date(\"2026-01-19\"),  # MLK no classes\n  as.Date(\"2026-03-07\"), as.Date(\"2026-03-15\"),  # Spring Break\n  as.Date(\"2026-05-25\"), as.Date(\"2026-05-25\"),  # Memorial Day observed\n  as.Date(\"2026-06-19\"), as.Date(\"2026-06-19\"),  # Juneteenth\n  as.Date(\"2026-07-03\"), as.Date(\"2026-07-03\")   # Independence Day observed\n)\n\n# DREXEL (approximate \"in session\" using Full Term windows you provided)\ndrexel_class_ranges <- tibble::tribble(\n  ~start,              ~end,\n  as.Date(\"2026-01-05\"), as.Date(\"2026-03-14\"),\n  as.Date(\"2026-03-30\"), as.Date(\"2026-06-06\"),\n  as.Date(\"2026-06-22\"), as.Date(\"2026-08-29\")\n)\n\ndrexel_no_class_ranges <- tibble::tribble(\n  ~start,              ~end,\n  as.Date(\"2026-01-19\"), as.Date(\"2026-01-19\"),  # MLK holiday\n  as.Date(\"2026-05-25\"), as.Date(\"2026-05-25\"),  # Memorial Day\n  as.Date(\"2026-06-19\"), as.Date(\"2026-06-19\"),  # Juneteenth\n  as.Date(\"2026-07-03\"), as.Date(\"2026-07-03\"),  # Independence Day observing\n  as.Date(\"2026-09-07\"), as.Date(\"2026-09-07\")   # Labor Day 2026\n)\n\n# TEMPLE\ntemple_class_ranges <- tibble::tribble(\n  ~start,              ~end,\n  as.Date(\"2025-08-25\"), as.Date(\"2025-12-08\"),  # fall (full-term end date)\n  as.Date(\"2026-01-12\"), as.Date(\"2026-04-27\"),  # spring\n  as.Date(\"2026-05-13\"), as.Date(\"2026-08-07\")   # summer blocks (covers multiple sessions)\n)\n\ntemple_no_class_ranges <- tibble::tribble(\n  ~start,              ~end,\n  as.Date(\"2025-09-01\"), as.Date(\"2025-09-01\"),  # Labor Day\n  as.Date(\"2025-10-17\"), as.Date(\"2025-10-17\"),  # Wellness Day\n  as.Date(\"2025-11-24\"), as.Date(\"2025-11-26\"),  # Fall Break\n  as.Date(\"2025-11-27\"), as.Date(\"2025-11-30\"),  # Thanksgiving holiday\n  as.Date(\"2026-01-19\"), as.Date(\"2026-01-19\"),  # MLK Day\n  as.Date(\"2026-03-02\"), as.Date(\"2026-03-08\"),  # Spring Break\n  as.Date(\"2026-05-25\"), as.Date(\"2026-05-25\"),  # Memorial Day\n  as.Date(\"2026-06-19\"), as.Date(\"2026-06-19\"),  # Juneteenth\n  as.Date(\"2026-07-03\"), as.Date(\"2026-07-03\")   # Independence Day observed\n)\n```\n:::\n\n\n### 3.2 \\| Model Evaluation Function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_eval_model2 <- function(df, quarter_label, split_week) {\n\n  early <- df %>% filter(week < split_week, Trip_Count > 0) %>% distinct(start_station) %>% pull()\n  late  <- df %>% filter(week >= split_week, Trip_Count > 0) %>% distinct(start_station) %>% pull()\n  common <- intersect(early, late)\n\n  df <- df %>% filter(start_station %in% common)\n\n  train <- df %>% filter(week < split_week) %>%\n    mutate(dotw_simple = factor(dotw, levels = c(\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\")))\n  test  <- df %>% filter(week >= split_week) %>%\n    mutate(dotw_simple = factor(dotw, levels = c(\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\")))\n\n  contrasts(train$dotw_simple) <- contr.treatment(7)\n\n  m2_baseline <- lm(\n    Trip_Count ~ as.factor(hour) + dotw_simple +\n      Temperature + I(Temperature^2) +\n      Precipitation + I(Precipitation^2) +\n      lag1Hour + lag3Hours + lag1day + lag1week,\n    data = train\n  )\n\n  m2_calendar <- lm(\n    Trip_Count ~ as.factor(hour) + dotw_simple +\n      Temperature + I(Temperature^2) +\n      Precipitation + I(Precipitation^2) +\n      lag1Hour + lag3Hours + lag1day + lag1week +\n      holiday + day_before_holiday + day_after_holiday +\n      any_univ_in_session + any_univ_no_classes +\n      holiday:weekend,\n    data = train\n  )\n\n  test <- test %>%\n    mutate(\n      pred_baseline = predict(m2_baseline, newdata = test),\n      pred_calendar = predict(m2_calendar, newdata = test)\n    )\n\n  tibble(\n    Quarter = quarter_label,\n    Model = c(\"Model 2 (Temporal Lags, Quad Weather)\",\n              \"Model 2 + Holidays + Univ Calendar (Quad Weather)\"),\n    MAE   = c(mean(abs(test$Trip_Count - test$pred_baseline), na.rm = TRUE),\n              mean(abs(test$Trip_Count - test$pred_calendar), na.rm = TRUE)),\n    n_train = nrow(train),\n    n_test  = nrow(test)\n  )\n}\n```\n:::\n\n\n### 3.3 \\| Build Q1/Q2 Feature-Enhanced Panels\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Q1 panel (already has weather_complete joined earlier)\npanel_q1_part11 <- study_panel %>%\n  mutate(dotw = as.character(dotw),\n         date = as.Date(interval60)) %>%\n  add_holiday_flags_2025() %>%\n  add_univ_calendar_flags(\n    penn_class_ranges, penn_no_class_ranges,\n    drexel_class_ranges, drexel_no_class_ranges,\n    temple_class_ranges, temple_no_class_ranges\n  ) %>%\n  add_model2_lags()\n\n# Q2 panel (study_q2_panel already exists; just ensure it has the COMPLETE weather)\npanel_q2_part11 <- study_q2_panel %>%\n  select(-Temperature, -Precipitation, -Wind_Speed) %>%   # avoid .x/.y mess\n  left_join(weather_q2_complete, by = \"interval60\") %>%\n  mutate(\n    Precipitation = replace_na(Precipitation, 0),\n    dotw = as.character(dotw),\n    date = as.Date(interval60)\n  ) %>%\n  add_holiday_flags_2025() %>%\n  add_univ_calendar_flags(\n    penn_class_ranges, penn_no_class_ranges,\n    drexel_class_ranges, drexel_no_class_ranges,\n    temple_class_ranges, temple_no_class_ranges\n  ) %>%\n  add_model2_lags()\n\n# Evaluate MAE (same splits you used elsewhere)\nmae_q1 <- fit_eval_model2(panel_q1_part11, \"Q1 2025\", split_week = 10)\nmae_q2 <- fit_eval_model2(panel_q2_part11, \"Q2 2025\", split_week = 23)\n\nmae_all <- bind_rows(mae_q1, mae_q2)\n\nmae_wide <- mae_all %>%\n  select(Quarter, Model, MAE) %>%\n  pivot_wider(names_from = Model, values_from = MAE) %>%\n  mutate(\n    delta_MAE = `Model 2 + Holidays + Univ Calendar (Quad Weather)` -\n                `Model 2 (Temporal Lags, Quad Weather)`,\n    pct_change = 100 * delta_MAE / `Model 2 (Temporal Lags, Quad Weather)`\n  )\n\nbaseline_m2_prev <- bind_rows(\n  mae_results %>%\n    filter(Model == \"2. + Temporal Lags\") %>%\n    transmute(Quarter = \"Q1 2025\",\n              `Original Baseline Model 2 (Linear Weather + Lags)` = MAE),\n\n  mae_results_q2 %>%\n    filter(Model == \"2. + Temporal Lags\") %>%\n    transmute(Quarter = \"Q2 2025\",\n              `Original Baseline Model 2 (Linear Weather + Lags)` = MAE)\n)\n\nmae_wide <- mae_wide %>%\n  left_join(baseline_m2_prev, by = \"Quarter\") %>%\n  relocate(`Original Baseline Model 2 (Linear Weather + Lags)`, .after = Quarter)\n\nkable(mae_wide, digits = 3, caption = \"MAE Comparison + Delta (Calendar - Baseline)\") %>%\n  kable_styling(bootstrap_options = c(\"striped\",\"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>MAE Comparison + Delta (Calendar - Baseline)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Quarter </th>\n   <th style=\"text-align:right;\"> Original Baseline Model 2 (Linear Weather + Lags) </th>\n   <th style=\"text-align:right;\"> Model 2 (Temporal Lags, Quad Weather) </th>\n   <th style=\"text-align:right;\"> Model 2 + Holidays + Univ Calendar (Quad Weather) </th>\n   <th style=\"text-align:right;\"> delta_MAE </th>\n   <th style=\"text-align:right;\"> pct_change </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Q1 2025 </td>\n   <td style=\"text-align:right;\"> 0.535 </td>\n   <td style=\"text-align:right;\"> 0.528 </td>\n   <td style=\"text-align:right;\"> 0.531 </td>\n   <td style=\"text-align:right;\"> 0.003 </td>\n   <td style=\"text-align:right;\"> 0.584 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Q2 2025 </td>\n   <td style=\"text-align:right;\"> 0.698 </td>\n   <td style=\"text-align:right;\"> 0.694 </td>\n   <td style=\"text-align:right;\"> 0.694 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\nggplot(mae_all, aes(x = Quarter, y = MAE, fill = Model)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Q1 vs Q2: Model 2 Baseline vs Model 2 + Calendar/Holiday Features\",\n    subtitle = \"Within-quarter retraining; MAE on held-out weeks\",\n    x = NULL, y = \"MAE (trips)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-42-1.png){width=672}\n:::\n:::\n\n\n### 3.4 \\| Spatial Error Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# helper to fit best baseline + return test with predictions\nfit_best_baseline_and_test <- function(df, split_week) {\n\n  early <- df %>% filter(week < split_week, Trip_Count > 0) %>% distinct(start_station) %>% pull()\n  late  <- df %>% filter(week >= split_week, Trip_Count > 0) %>% distinct(start_station) %>% pull()\n  common <- intersect(early, late)\n\n  df <- df %>% filter(start_station %in% common)\n\n  train <- df %>% filter(week < split_week) %>%\n    mutate(dotw_simple = factor(dotw, levels = c(\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\")))\n  test  <- df %>% filter(week >= split_week) %>%\n    mutate(dotw_simple = factor(dotw, levels = c(\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\")))\n\n  contrasts(train$dotw_simple) <- contr.treatment(7)\n\n  m_best <- lm(\n    Trip_Count ~ as.factor(hour) + dotw_simple +\n      Temperature + I(Temperature^2) +\n      Precipitation + I(Precipitation^2) +\n      lag1Hour + lag3Hours + lag1day + lag1week,\n    data = train\n  )\n\n  test %>%\n    mutate(\n      pred_best = predict(m_best, newdata = test),\n      error = Trip_Count - pred_best,\n      abs_error = abs(error),\n      time_of_day = case_when(\n        hour < 7 ~ \"Overnight\",\n        hour >= 7 & hour < 10 ~ \"AM Rush\",\n        hour >= 10 & hour < 15 ~ \"Mid-Day\",\n        hour >= 15 & hour <= 18 ~ \"PM Rush\",\n        hour > 18 ~ \"Evening\"\n      ),\n      day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\")\n    )\n}\n\ntest_q1_best <- fit_best_baseline_and_test(panel_q1_part11, split_week = 10)\ntest_q2_best <- fit_best_baseline_and_test(panel_q2_part11, split_week = 23)\n\ntemporal_errors_best_q1 <- test_q1_best %>%\n  group_by(time_of_day, day_type) %>%\n  summarize(MAE = mean(abs_error, na.rm = TRUE), .groups = \"drop\")\n\ntemporal_errors_best_q2 <- test_q2_best %>%\n  group_by(time_of_day, day_type) %>%\n  summarize(MAE = mean(abs_error, na.rm = TRUE), .groups = \"drop\")\n\ntemporal_all_best <- bind_rows(\n  temporal_errors_best_q1 %>% mutate(Quarter = \"Q1 2025\"),\n  temporal_errors_best_q2 %>% mutate(Quarter = \"Q2 2025\")\n) %>%\n  mutate(time_of_day = factor(time_of_day, levels = unique(time_of_day)))\n\nggplot(temporal_all_best, aes(x = time_of_day, y = MAE, fill = Quarter)) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ day_type) +\n  labs(\n    title = \"Prediction Errors by Time of Day (Best Baseline Model)\",\n    subtitle = \"Quad weather + lags incl. 1-week lag (no calendar), Q1 vs Q2 2025\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Quarter\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\nThe temporal error plot shows a really consistent story across as past models, the model is struggling when demand is high and volatile. The biggest breakdown is the PM rush period, especially on weekdays, which is exactly when station activity is most directional and fast-changing (commute surges, short intense bursts around 5–6pm, and rapid station stock shifts). Even with quadratic weather and a one-week lag, the model still can’t fully anticipate the sharp within-day swings that happen during peak travel periods. However, comparing the quartiles internally, Q2 is consistently worse than Q1 almost everywhere. That gap suggests that Q2 demand is harder to predict even when the model is retrained within-quarter using the same pipeline. In practice, spring/early-summer riding has more “extra” variation layered on top of routine commuter patterns—more discretionary trips, more event-driven spikes, and more weather-sensitive riding—so hour/day-of-week plus persistence lags don’t stabilize predictions as much as they do in winter. The fact that the Q2 bars are higher in nearly every block implies the issue isn’t a single bad time window; it’s broader seasonal volatility that shows up throughout the day, and it gets amplified during peaks.\n\n### 3.5 \\| Spatial Error Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstation_errors_best_q1 <- test_q1_best %>%\n  filter(!is.na(pred_best)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred_best), na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\nstation_errors_best_q2 <- test_q2_best %>%\n  filter(!is.na(pred_best)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred_best), na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\nstations_all_best <- bind_rows(\n  station_errors_best_q1 %>% mutate(Quarter = \"Q1 2025\"),\n  station_errors_best_q2 %>% mutate(Quarter = \"Q2 2025\")\n)\n\nggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", linewidth = 0.2) +\n  geom_point(\n    data = stations_all_best,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size  = 1.3,\n    alpha = 0.85\n  ) +\n  facet_wrap(~ Quarter) +\n  scale_color_viridis_c(name = \"MAE (trips)\") +\n  labs(\n    title = \"Spatial Distribution of Prediction Errors (Best Baseline Model)\",\n    subtitle = \"Quad weather + lags incl. 1-week lag (no calendar)\",\n    x = NULL, y = NULL\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n:::\n\n\nThe spatial error maps line up with the temporal story. In both quarters, the largest station-level MAEs cluster in and around the urban core, namely Center City and University City, while many stations farther from the center show lower error. This issue is similar to that of the preceeding models and is an issue that systematically affects both Q1 and Q2. However, Q2 appears to suffer or experience a disproportional effect currently the model performs best in quitier or more early/late time period commuters, but seems to struggle the msot in areas of potential high demand or tourist areas within Philadelphia. Additionally, unlike Q1 the weather is much more forgiving and students are likely more interesting in exploring the city as well as the influx of new potential students in these dominant areas likely causes constraints and hightened unpredictable demand that is saptially clustered around those areas.\n\n### 3.6 \\| Poisson Model for Q1 and Q2\n\n\n::: {.cell}\n\n```{.r .cell-code}\neval_poisson_models <- function(df, quarter_label, split_week) {\n\n  # keep only stations that have positive trips in both early+late periods\n  early <- df %>%\n    dplyr::filter(week < split_week, Trip_Count > 0) %>%\n    dplyr::distinct(start_station) %>%\n    dplyr::pull(start_station)\n\n  late <- df %>%\n    dplyr::filter(week >= split_week, Trip_Count > 0) %>%\n    dplyr::distinct(start_station) %>%\n    dplyr::pull(start_station)\n\n  common <- intersect(early, late)\n\n  df <- df %>%\n    dplyr::filter(start_station %in% common)\n\n  train <- df %>%\n    dplyr::filter(week < split_week) %>%\n    dplyr::mutate(\n      dotw_simple = factor(\n        as.character(dotw),\n        levels = c(\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\")\n      )\n    )\n\n  test <- df %>%\n    dplyr::filter(week >= split_week) %>%\n    dplyr::mutate(\n      dotw_simple = factor(\n        as.character(dotw),\n        levels = c(\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\")\n      )\n    )\n\n  contrasts(train$dotw_simple) <- contr.treatment(7)\n\n  ## (A) Poisson version of ORIGINAL Model 2 (linear weather + lags)\n  m2_pois_linear <- glm(\n    Trip_Count ~ as.factor(hour) + dotw_simple +\n      Temperature + Precipitation +\n      lag1Hour + lag3Hours + lag1day,\n    data   = train,\n    family = poisson(link = \"log\")\n  )\n\n  ## (B) Poisson version of quad-weather + lags + 1-week lag\n  m2_pois_quad_week <- glm(\n    Trip_Count ~ as.factor(hour) + dotw_simple +\n      Temperature + I(Temperature^2) +\n      Precipitation + I(Precipitation^2) +\n      lag1Hour + lag3Hours + lag1day + lag1week,\n    data   = train,\n    family = poisson(link = \"log\")\n  )\n\n  # Predictions on the mean scale (expected counts)\n  test <- test %>%\n    mutate(\n      pred_pois_linear = pmax(0, predict(m2_pois_linear,\n                                         newdata = test,\n                                         type   = \"response\")),\n      pred_pois_quad   = pmax(0, predict(m2_pois_quad_week,\n                                         newdata = test,\n                                         type   = \"response\"))\n    )\n\n  # MAE on test\n  mae_linear <- mean(abs(test$Trip_Count - test$pred_pois_linear), na.rm = TRUE)\n  mae_quad   <- mean(abs(test$Trip_Count - test$pred_pois_quad),   na.rm = TRUE)\n\n  # Overdispersion (Pearson)\n  disp_linear <- sum(residuals(m2_pois_linear, type = \"pearson\")^2, na.rm = TRUE) /\n                 m2_pois_linear$df.residual\n\n  disp_quad   <- sum(residuals(m2_pois_quad_week, type = \"pearson\")^2, na.rm = TRUE) /\n                 m2_pois_quad_week$df.residual\n\n  tibble::tibble(\n    Quarter    = quarter_label,\n    Model      = c(\"Poisson Model 2 (Linear Weather + Lags)\",\n                   \"Poisson Model 2 (Quad Weather + Lags + 1-Week Lag)\"),\n    MAE        = c(mae_linear, mae_quad),\n    Dispersion = c(disp_linear, disp_quad),\n    n_train    = nrow(train),\n    n_test     = nrow(test)\n  )\n}\n\n# Q1: start from study_panel (already has Temperature/Precipitation etc.)\npanel_q1_pois <- study_panel %>%\n  mutate(dotw = as.character(dotw)) %>%\n  add_model2_lags()     # creates lag1Hour/lag3Hours/lag1day/lag1week and drops early NA rows\n\n# Q2: ensure weather is joined consistently, then add lags including lag1week\npanel_q2_pois <- study_q2_panel %>%\n  left_join(weather_q2_complete, by = \"interval60\") %>%\n  mutate(\n    Temperature   = dplyr::coalesce(Temperature.y, Temperature.x),\n    Precipitation = dplyr::coalesce(Precipitation.y, Precipitation.x),\n    Precipitation = ifelse(is.na(Precipitation), 0, Precipitation),\n    dotw          = as.character(dotw)\n  ) %>%\n  add_model2_lags()\n\n### Run Poisson evaluation for Q1 and Q2\n\npois_q1 <- eval_poisson_models(panel_q1_pois, \"Q1 2025\", split_week = 10)\npois_q2 <- eval_poisson_models(panel_q2_pois, \"Q2 2025\", split_week = 23)\n\npois_all <- dplyr::bind_rows(pois_q1, pois_q2)\n\n# Table: MAE + dispersion\npois_wide <- pois_all %>%\n  dplyr::select(Quarter, Model, MAE, Dispersion) %>%\n  tidyr::pivot_wider(names_from = Model, values_from = c(MAE, Dispersion))\n\nkable(pois_wide, digits = 3,\n      caption = \"Poisson Models: MAE + Overdispersion (Pearson) — Q1 vs Q2\") %>%\n  kable_styling(bootstrap_options = c(\"striped\",\"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Poisson Models: MAE + Overdispersion (Pearson) — Q1 vs Q2</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Quarter </th>\n   <th style=\"text-align:right;\"> MAE_Poisson Model 2 (Linear Weather + Lags) </th>\n   <th style=\"text-align:right;\"> MAE_Poisson Model 2 (Quad Weather + Lags + 1-Week Lag) </th>\n   <th style=\"text-align:right;\"> Dispersion_Poisson Model 2 (Linear Weather + Lags) </th>\n   <th style=\"text-align:right;\"> Dispersion_Poisson Model 2 (Quad Weather + Lags + 1-Week Lag) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Q1 2025 </td>\n   <td style=\"text-align:right;\"> 0.572 </td>\n   <td style=\"text-align:right;\"> 0.588 </td>\n   <td style=\"text-align:right;\"> 1.357 </td>\n   <td style=\"text-align:right;\"> 1.323 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Q2 2025 </td>\n   <td style=\"text-align:right;\"> 0.730 </td>\n   <td style=\"text-align:right;\"> 0.724 </td>\n   <td style=\"text-align:right;\"> 1.511 </td>\n   <td style=\"text-align:right;\"> 1.453 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\n# Plot MAE for visual comparison\nggplot(pois_all, aes(x = Quarter, y = MAE, fill = Model)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title    = \"Poisson Model Performance (MAE)\",\n    subtitle = \"Original Model 2 vs Quad Weather + 1-Week Lag\",\n    x        = NULL,\n    y        = \"MAE (trips)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_MA_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n:::\n\n\nThe Poisson versions of Model 2 perform worse than our original OLS specifications when judged by out-of-sample MAE, so they are not preferable for our forecasting objective. In Q1 2025, the Poisson MAE is higher than the OLS baseline (Poisson ≈ 0.572–0.588 vs. OLS ≈ 0.535–0.528), and the same pattern holds in Q2 2025 (Poisson ≈ 0.724–0.730 vs. OLS ≈ 0.698–0.694). Even though Poisson is a natural choice for count outcomes, it is optimized for likelihood rather than absolute-error accuracy; since our evaluation metric is MAE, the original OLS models—especially Model 2 and the quadratic-weather extension—clearly outperform the Poisson alternatives and remain the better operational forecasting baseline.\n\n------------------------------------------------------------------------\n\n## Conclusion: Critical Reflection\n\n1.  **Operational implications:** Operationally, our best-performing approach remains the original **OLS Model 2** (time-of-day + day-of-week + weather + temporal lags), with MAE around **0.53 in Q1** and **0.69 in Q2**; the quadratic-weather + 1-week lag tweak helps only marginally, and neither calendar features nor Poisson improves MAE. That level of error is “good enough” only in a decision-support sense: it’s useful for **ranking and flagging stations** that are likely to be problematic, not for exact trip counts. The temporal diagnostics make clear that errors spike during **high-stakes windows**—especially the **PM rush** (and other peak periods), when demand changes quickly and rebalancing lead time is short—so that’s exactly when prediction misses can translate into stockouts/dockouts and service failures. We would recommend deploying the system under conditions that acknowledge this: (i) as a **screening tool** that prioritizes stations for human review and truck routing, (ii) with **conservative thresholds** in Q2 (since overall error is higher), and (iii) paired with operations rules like “act earlier for commute peaks” and “treat high-variance periods as higher risk even if point forecasts look moderate.”\n\n2.  **Equity considerations:** On equity, the spatial error maps suggest the largest absolute errors cluster in the **core network (Center City / University City)** where volume and variance are high—this is not inherently evidence of inequity, but it does matter because operational resources tend to be concentrated where the model is already most uncertain. If Indego uses the model strictly to optimize efficiency, it could unintentionally **pull attention away from lower-demand neighborhoods**, worsening existing disparities in bike availability and reliability. The safeguard is to make equity explicit in deployment: enforce **minimum service/rebalancing floors** by neighborhood, monitor **stockout/dockout rates** and forecast errors geographically over time, and use a two-tier strategy where the model ranks risk within operational zones but decisions are constrained by **coverage targets** (so lower-demand areas are not systematically deprioritized).\n\n3.  **Model limitations:** Finally, the limitations are pretty clear from what didn’t help: the model is missing **event-driven spikes**, operational feedback (rebalancing itself changes counts), station constraints (capacity, dock availability), and localized context (parks, venues, connectivity, campus-specific effects at the station level). With more time/data, we’d improve by adding **station capacity and availability states**, **special event calendars**, and simple spatial features (distance to Center City/universities/parks), and we’d consider a model designed for peak volatility (e.g., regime/peak indicators, or a hierarchical model with station-level random effects) while still evaluating on the metric that matches Indego’s operational goal (MAE or, even better, directly predicting **stockout/dockout risk**).\n\n------------------------------------------------------------------------\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}