{
  "hash": "18cbe089e69bd643ba46a2b126cca1c3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Assignment 5: Space-Time Prediction of Indego Bike Share Demand\"\nauthor: \"Jed Chew and Muhammad Al Abbas\"\ndate: 12/1/2025\nformat:\n  html:\n    code-fold: show\n    code-tools: true\n    toc: true\n    toc-depth: 3\n    toc-location: left\n    theme: cosmo\n    embed-resources: true\neditor: visual\nexecute:\n  warning: false\n  message: false\n---\n\n# The Rebalancing Challenge in Philadelphia\n\nPhiladelphia's Indego bike share system faces the same operational challenge as every bike share system: **rebalancing bikes to meet anticipated demand**.\n\nImagine you're an Indego operations manager at 6:00 AM on a Monday morning. You have 200 stations across Philadelphia, limited trucks and staff for moving bikes, and 2-3 hours before morning rush hour demand peaks. **Which stations will run out of bikes by 8:30 AM?**\n\nThis lab will teach you to build predictive models that forecast bike share demand across **space** (different stations) and **time** (different hours) to help solve this operational problem.\n\n## Learning Objectives\n\nBy the end of this assignment, you will be able to:\n\n1.  **Understand panel data structure** for space-time analysis\n2.  **Create temporal lag variables** to capture demand persistence\n3.  **Build multiple predictive models** with increasing complexity\n4.  **Validate models temporally** (train on past, test on future)\n5.  **Analyze prediction errors** in both space and time\n6.  **Engineer new features** based on error patterns\n7.  **Critically evaluate** when prediction errors matter most\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(tigris)\nlibrary(tidycensus)\nlibrary(broom)\nlibrary(here)\nlibrary(riem)  # For Philadelphia weather from ASOS stations\n\n# Visualization\nlibrary(viridis)\nlibrary(gridExtra)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(gganimate)\n\noptions(scipen = 999)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", size = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n:::\n\n\n\n\n## Part 1: Data Import & Preparation\n\n### 1.1 \\| Load Indego Trip Data\n\n**Data Dictionary**\n\n-   **trip_id:** Locally unique integer that identifies the trip\n-   **duration:** Length of trip in minutes\n-   **start_time & end_time**\n-   **start_station; start_lat; start_lon**\n-   **end_station; end_lat; end_lon**\n-   **bike_id:** Locally unique integer that identifies the bike\n-   **plan_duration:** The number of days that the plan the passholder is using entitles them to ride; 0 is used for a single ride plan (Walk-up)\n-   **trip_route_category:** “Round Trip” for trips starting and ending at the same station or “One Way” for all other trips\n-   **passholder_type:** The name of the passholder’s plan\n-   **bike_type:** The kind of bike used on the trip, including standard pedal-powered bikes or electric assist bikes\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindego <- read_csv(\"data/indego-trips-2025-q1.csv\")\nindego_q2 <- read_csv(\"data/indego-trips-2025-q2.csv\")\nindego_q3 <- read_csv(\"data/indego-trips-2025-q3.csv\")\n```\n:::\n\n\n\n\n### 1.2 \\| Create Time Bins\n\n-   Helper function to create time bins – aggregate trips into hourly intervals for panel data structure\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindego <- indego %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n### 1.3 \\| Exploratory Data Analysis\n\n**Daily Trip Counts**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaily_trips <- indego %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q1 2025\",\n    subtitle = \"Winter demand patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/trips_over_time-1.png){width=672}\n:::\n:::\n\n\n**Hourly Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Average trips by hour and day type\nhourly_patterns <- indego %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date)) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(hourly_patterns, aes(x = hour, y = avg_trips, color = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Average Hourly Ridership Patterns - Q1 2025\",\n    subtitle = \"Clear commute patterns on weekdays\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Day Type\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/hourly_patterns-1.png){width=672}\n:::\n:::\n\n\n**Top Stations**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Most popular origin stations\ntop_stations <- indego %>%\n  count(start_station, start_lat, start_lon, name = \"trips\") %>%\n  arrange(desc(trips)) %>%\n  head(20)\n\nkable(top_stations, \n      caption = \"Top 20 Indego Stations by Trip Origins - Q1 2025\",\n      format.args = list(big.mark = \",\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Top 20 Indego Stations by Trip Origins - Q1 2025</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> start_station </th>\n   <th style=\"text-align:right;\"> start_lat </th>\n   <th style=\"text-align:right;\"> start_lon </th>\n   <th style=\"text-align:right;\"> trips </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 3,010 </td>\n   <td style=\"text-align:right;\"> 39.94711 </td>\n   <td style=\"text-align:right;\"> -75.16618 </td>\n   <td style=\"text-align:right;\"> 3,999 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,032 </td>\n   <td style=\"text-align:right;\"> 39.94527 </td>\n   <td style=\"text-align:right;\"> -75.17971 </td>\n   <td style=\"text-align:right;\"> 2,842 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,359 </td>\n   <td style=\"text-align:right;\"> 39.94888 </td>\n   <td style=\"text-align:right;\"> -75.16978 </td>\n   <td style=\"text-align:right;\"> 2,699 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,020 </td>\n   <td style=\"text-align:right;\"> 39.94855 </td>\n   <td style=\"text-align:right;\"> -75.19007 </td>\n   <td style=\"text-align:right;\"> 2,673 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,208 </td>\n   <td style=\"text-align:right;\"> 39.95048 </td>\n   <td style=\"text-align:right;\"> -75.19324 </td>\n   <td style=\"text-align:right;\"> 2,503 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,244 </td>\n   <td style=\"text-align:right;\"> 39.93865 </td>\n   <td style=\"text-align:right;\"> -75.16674 </td>\n   <td style=\"text-align:right;\"> 2,486 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,066 </td>\n   <td style=\"text-align:right;\"> 39.94561 </td>\n   <td style=\"text-align:right;\"> -75.17348 </td>\n   <td style=\"text-align:right;\"> 2,396 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,362 </td>\n   <td style=\"text-align:right;\"> 39.94816 </td>\n   <td style=\"text-align:right;\"> -75.16226 </td>\n   <td style=\"text-align:right;\"> 2,387 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,012 </td>\n   <td style=\"text-align:right;\"> 39.94218 </td>\n   <td style=\"text-align:right;\"> -75.17747 </td>\n   <td style=\"text-align:right;\"> 2,361 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,028 </td>\n   <td style=\"text-align:right;\"> 39.94061 </td>\n   <td style=\"text-align:right;\"> -75.14958 </td>\n   <td style=\"text-align:right;\"> 2,348 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,161 </td>\n   <td style=\"text-align:right;\"> 39.95486 </td>\n   <td style=\"text-align:right;\"> -75.18091 </td>\n   <td style=\"text-align:right;\"> 2,278 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,101 </td>\n   <td style=\"text-align:right;\"> 39.94295 </td>\n   <td style=\"text-align:right;\"> -75.15955 </td>\n   <td style=\"text-align:right;\"> 2,274 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,295 </td>\n   <td style=\"text-align:right;\"> 39.95028 </td>\n   <td style=\"text-align:right;\"> -75.16027 </td>\n   <td style=\"text-align:right;\"> 2,160 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,054 </td>\n   <td style=\"text-align:right;\"> 39.96250 </td>\n   <td style=\"text-align:right;\"> -75.17420 </td>\n   <td style=\"text-align:right;\"> 2,123 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,185 </td>\n   <td style=\"text-align:right;\"> 39.95169 </td>\n   <td style=\"text-align:right;\"> -75.15888 </td>\n   <td style=\"text-align:right;\"> 2,116 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,038 </td>\n   <td style=\"text-align:right;\"> 39.94781 </td>\n   <td style=\"text-align:right;\"> -75.19409 </td>\n   <td style=\"text-align:right;\"> 2,111 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,203 </td>\n   <td style=\"text-align:right;\"> 39.94077 </td>\n   <td style=\"text-align:right;\"> -75.17227 </td>\n   <td style=\"text-align:right;\"> 2,106 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,059 </td>\n   <td style=\"text-align:right;\"> 39.96244 </td>\n   <td style=\"text-align:right;\"> -75.16121 </td>\n   <td style=\"text-align:right;\"> 2,027 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,022 </td>\n   <td style=\"text-align:right;\"> 39.95472 </td>\n   <td style=\"text-align:right;\"> -75.18323 </td>\n   <td style=\"text-align:right;\"> 2,014 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,063 </td>\n   <td style=\"text-align:right;\"> 39.94633 </td>\n   <td style=\"text-align:right;\"> -75.16980 </td>\n   <td style=\"text-align:right;\"> 2,014 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n::: callout-note\n## Observed Patterns for Q1 2025\n\n-   **Seasonal Demand:** generally, ridership demand increases from January to March as the weather in Philadelphia gets warmer. However, there is significant fluctuation in daily ridership for Q1 2025.\n-   **Hourly Ridership:** on weekdays, there is a clear morning and evening rush hour. On weekend, there appears to be a gentle crest in activity around midday to evening (around 10am to 7pm)\n:::\n\n------------------------------------------------------------------------\n\n## Part 2: Philadelphia Census Data\n\n### 2.1 \\| Load Philadelphia Census Data\n\n\n::: {.cell progress='false'}\n\n```{.r .cell-code}\n# Get Philadelphia census tracts\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    \"B01003_001\",  # Total population\n    \"B19013_001\",  # Median household income\n    \"B08301_001\",  # Total commuters\n    \"B08301_010\",  # Commute by transit\n    \"B02001_002\",  # White alone\n    \"B25077_001\"   # Median home value\n  ),\n  state = \"PA\",\n  county = \"Philadelphia\",\n  year = 2022,\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  rename(\n    Total_Pop = B01003_001E,\n    Med_Inc = B19013_001E,\n    Total_Commuters = B08301_001E,\n    Transit_Commuters = B08301_010E,\n    White_Pop = B02001_002E,\n    Med_Home_Value = B25077_001E\n  ) %>%\n  mutate(\n    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,\n    Percent_White = (White_Pop / Total_Pop) * 100\n  ) %>%\n  st_transform(crs = 4326)  # WGS84 for lat/lon matching\n```\n:::\n\n\n### 2.2 \\| Map Philadelphia Context\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Map median income\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = NA) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Context for understanding bike share demand patterns\"\n  ) +\n  # Stations \n  geom_point(\n    data = indego,\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 0.4, alpha = 0.6\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/map-philly-1.png){width=672}\n:::\n:::\n\n\n### 2.3 \\| Join Census Data to Stations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create sf object for stations\nstations_sf <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\n# Spatial join to get census tract for each station\nstations_census <- st_join(stations_sf, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n```\n:::\n\n\n**Left-Join Census Data to Q1 Indego Data**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Flag stations in non-residential census tracts\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Add back to trip data\nindego_census <- indego %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n# Prepare data for visualization\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\ncount(stations_for_map, has_census)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  has_census     n\n  <lgl>      <int>\n1 FALSE         19\n2 TRUE         245\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create the map showing problem stations\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = \"white\", size = 0.1) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar,\n    na.value = \"grey90\"\n  ) +\n  # Stations with census data (small grey dots)\n  geom_point(\n    data = stations_for_map %>% filter(has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"grey30\", size = 1, alpha = 0.6\n  ) +\n  # Stations WITHOUT census data (red X marks the spot)\n  geom_point(\n    data = stations_for_map %>% filter(!has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 1, shape = 4, stroke = 1.5\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Indego stations shown (RED = no census data match)\",\n    caption = \"Red X marks indicate stations that didn't join to census tracts\"\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n### 2.4 \\| Dealing with Missing Data\n\nWe need to decide what to do with the non-residential bike share stations. For this example, we are going to remove them.\n\nThis is not necessarily the right way to do things always, but for the sake of simplicity, we are narrowing our scope to only stations in residential neighborhoods. We might opt to create a separate model for non-residential stations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Identify which stations to keep\nvalid_stations <- stations_census %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\n# Filter trip data to valid stations only\nindego_census <- indego %>%\n  filter(start_station %in% valid_stations) %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 3: Get Weather Data\n\n### 3.1 \\| Weather Data for Q1 2025\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get weather from Philadelphia International Airport (KPHL)\n# This covers Q1 2025: January 1 - March 31\nweather_data <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2025-01-01\",\n  date_end = \"2025-03-31\"\n)\n\n# Process weather data\nweather_processed <- weather_data %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  # updated in-class code to only keep the first row for each hour\n  distinct(interval60, .keep_all = TRUE) \n\n# Check for missing hours and interpolate if needed\nweather_complete <- weather_processed %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Look at the weather\nsummary(weather_complete %>% select(Temperature, Precipitation, Wind_Speed))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Temperature    Precipitation        Wind_Speed    \n Min.   :10.00   Min.   :0.000000   Min.   : 0.000  \n 1st Qu.:30.00   1st Qu.:0.000000   1st Qu.: 6.000  \n Median :37.00   Median :0.000000   Median : 8.000  \n Mean   :38.36   Mean   :0.001327   Mean   : 9.308  \n 3rd Qu.:46.00   3rd Qu.:0.000000   3rd Qu.:13.000  \n Max.   :78.00   Max.   :0.280000   Max.   :30.000  \n```\n\n\n:::\n:::\n\n\n### 3.2 \\| Weather Data for Q2 2025\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_q2 <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2025-04-01\",\n  date_end = \"2025-06-30\"\n)\n\n# Process weather data\nweather_q2 <- weather_q2 %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  # updated in-class code to only keep the first row for each hour\n  distinct(interval60, .keep_all = TRUE) \n\n# Check for missing hours and interpolate if needed\nweather_q2_complete <- weather_q2 %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Look at the weather\nsummary(weather_q2_complete %>% select(Temperature, Precipitation, Wind_Speed))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Temperature     Precipitation        Wind_Speed    \n Min.   : 33.00   Min.   :0.000000   Min.   : 0.000  \n 1st Qu.: 57.00   1st Qu.:0.000000   1st Qu.: 5.000  \n Median : 66.00   Median :0.000000   Median : 8.000  \n Mean   : 65.62   Mean   :0.002024   Mean   : 8.125  \n 3rd Qu.: 73.00   3rd Qu.:0.000000   3rd Qu.:11.000  \n Max.   :100.00   Max.   :0.590000   Max.   :27.000  \n```\n\n\n:::\n:::\n\n\n### 3.3 \\| Weather Data for Q3 2025\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_q3 <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2025-07-01\",\n  date_end = \"2025-09-30\"\n)\n\n# Process weather data\nweather_q3 <- weather_q3 %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  # updated in-class code to only keep the first row for each hour\n  distinct(interval60, .keep_all = TRUE) \n\n# Check for missing hours and interpolate if needed\nweather_q3_complete <- weather_q3 %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Look at the weather\nsummary(weather_q3_complete %>% select(Temperature, Precipitation, Wind_Speed))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Temperature    Precipitation         Wind_Speed    \n Min.   :57.00   Min.   :0.0000000   Min.   : 0.000  \n 1st Qu.:70.00   1st Qu.:0.0000000   1st Qu.: 4.000  \n Median :76.00   Median :0.0000000   Median : 6.000  \n Mean   :75.94   Mean   :0.0008342   Mean   : 6.218  \n 3rd Qu.:81.00   3rd Qu.:0.0000000   3rd Qu.: 8.000  \n Max.   :98.00   Max.   :0.1000000   Max.   :25.000  \n```\n\n\n:::\n:::\n\n\n### 3.4 \\| Visualize Weather Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q1 2025\",\n    subtitle = \"Winter to Early Spring Transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_q2_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q2 2025\",\n    subtitle = \"Spring to Summer Transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_q3_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q3 2025\",\n    subtitle = \"Summer to Fall Transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_complete, aes(x = interval60, y = Precipitation)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  labs(\n    title = \"Philadelphia Precipitation - Q1 2025\",\n    subtitle = \"Winter to Early Spring Transition\",\n    x = \"Date\",\n    y = \"Hourly Precipitation (inches)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_q2_complete, aes(x = interval60, y = Precipitation)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  labs(\n    title = \"Philadelphia Precipitation - Q2 2025\",\n    subtitle = \"Spring to Summer Transition\",\n    x = \"Date\",\n    y = \"Hourly Precipitation (inches)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_q3_complete, aes(x = interval60, y = Precipitation)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  labs(\n    title = \"Philadelphia Precipitation - Q3 2025\",\n    subtitle = \"Summer to Fall Transition\",\n    x = \"Date\",\n    y = \"Hourly Precipitation (inches)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Combined 3x3 Panel Visualization of Weather Data by Quarter\nweather_long <- bind_rows(\n  weather_complete    %>% mutate(Quarter = \"Q1 2025\"),\n  weather_q2_complete %>% mutate(Quarter = \"Q2 2025\"),\n  weather_q3_complete %>% mutate(Quarter = \"Q3 2025\")\n) %>%\n  pivot_longer(\n    cols = c(Precipitation, Temperature, Wind_Speed),\n    names_to = \"Measure\",\n    values_to = \"Value\"\n  ) %>%\n  mutate(\n    Measure = factor(Measure, levels = c(\"Precipitation\", \"Temperature\", \"Wind_Speed\")),\n    Quarter = factor(Quarter, levels = c(\"Q1 2025\", \"Q2 2025\", \"Q3 2025\"))\n  )\n\nggplot(weather_long, aes(x = interval60, y = Value)) +\n  geom_line(alpha = 0.7) +\n  facet_grid(Measure ~ Quarter, scales = \"free\") +\n  scale_x_datetime(date_breaks = \"1 month\", date_labels = \"%b\") +\n  labs(\n    title = \"Philadelphia Weather by Quarter - 2025\",\n    x = \"Date / Time\",\n    y = NULL\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 4: Create Space-Time Panel\n\n### 4.1 \\| Aggregate Trips to Station-Hour Level\n\n**Q1 2025**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count trips by station-hour\ntrips_panel <- indego_census %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n\n# How many station-hour observations?\nnrow(trips_panel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 116718\n```\n\n\n:::\n\n```{.r .cell-code}\n# How many unique stations?\nlength(unique(trips_panel$start_station))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 245\n```\n\n\n:::\n\n```{.r .cell-code}\n# How many unique hours?\nlength(unique(trips_panel$interval60))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2150\n```\n\n\n:::\n:::\n\n\n### 4.2 \\| Create Complete Panel Structure\n\nNot every station has trips every hour. We need a **complete panel** where every station-hour combination exists (even if Trip_Count = 0).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate expected panel size\nn_stations <- length(unique(trips_panel$start_station))\nn_hours <- length(unique(trips_panel$interval60))\nexpected_rows <- n_stations * n_hours\n\ncat(\"Expected panel rows:\", format(expected_rows, big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nExpected panel rows: 526,750 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Current rows:\", format(nrow(trips_panel), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCurrent rows: 116,718 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Missing rows:\", format(expected_rows - nrow(trips_panel), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMissing rows: 410,032 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Create complete panel\nstudy_panel <- expand.grid(\n  interval60 = unique(trips_panel$interval60),\n  start_station = unique(trips_panel$start_station)\n) %>%\n  # Join trip counts\n  left_join(trips_panel, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Fill in station attributes (they're the same for all hours)\nstation_attributes <- trips_panel %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_panel <- study_panel %>%\n  left_join(station_attributes, by = \"start_station\")\n\n# Verify we have complete panel\ncat(\"Complete panel rows:\", format(nrow(study_panel), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nComplete panel rows: 526,750 \n```\n\n\n:::\n:::\n\n\n**Add Time Features**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n**Join Weather Data**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  left_join(weather_complete, by = \"interval60\")\nsummary(study_panel %>% select(Trip_Count, Temperature, Precipitation))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Trip_Count       Temperature    Precipitation   \n Min.   : 0.0000   Min.   :10.00   Min.   :0.0000  \n 1st Qu.: 0.0000   1st Qu.:30.00   1st Qu.:0.0000  \n Median : 0.0000   Median :37.00   Median :0.0000  \n Mean   : 0.3585   Mean   :38.39   Mean   :0.0013  \n 3rd Qu.: 0.0000   3rd Qu.:46.00   3rd Qu.:0.0000  \n Max.   :26.0000   Max.   :78.00   Max.   :0.2800  \n                   NA's   :5880    NA's   :5880    \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 5: Create Temporal Lag Variables\n\nTemporal Persistence: past demand predicts future demand\n\n### 5.1 \\| Create Temporal Lags\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sort by station and time\nstudy_panel <- study_panel %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_panel <- study_panel %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_panel_complete <- study_panel %>%\n  filter(!is.na(lag1day))\n\ncat(\"Rows after removing NA lags:\", format(nrow(study_panel_complete), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows after removing NA lags: 520,870 \n```\n\n\n:::\n:::\n\n\n### 5.2 \\| Visualize Lag Correlations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sample one station to visualize\nexample_station <- study_panel_complete %>%\n  filter(start_station == first(start_station)) %>%\n  head(168)  # One week\n\n# Plot actual vs lagged demand\nggplot(example_station, aes(x = interval60)) +\n  geom_line(aes(y = Trip_Count, color = \"Current\"), linewidth = 1) +\n  geom_line(aes(y = lag1Hour, color = \"1 Hour Ago\"), linewidth = 1, alpha = 0.7) +\n  geom_line(aes(y = lag1day, color = \"24 Hours Ago\"), linewidth = 1, alpha = 0.7) +\n  scale_color_manual(values = c(\n    \"Current\" = \"#08519c\",\n    \"1 Hour Ago\" = \"#3182bd\",\n    \"24 Hours Ago\" = \"#6baed6\"\n  )) +\n  labs(\n    title = \"Temporal Lag Patterns at One Station\",\n    subtitle = \"Past demand predicts future demand\",\n    x = \"Date-Time\",\n    y = \"Trip Count\",\n    color = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 6: Build 5 Predictive Models of Increasing Complexity\n\n### Temporal Train/Test Split\n\nApproach: Train on Past Data and Test on Future Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Train on weeks 1-9 (Jan 1 - early March)\n# Test on weeks 10-13 (rest of March)\n\n# Which stations have trips in BOTH early and late periods?\nearly_stations <- study_panel_complete %>%\n  filter(week < 10) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations <- study_panel_complete %>%\n  filter(week >= 10) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\n# Keep only stations that appear in BOTH periods\ncommon_stations <- intersect(early_stations, late_stations)\n\n\n# Filter panel to only common stations\nstudy_panel_complete <- study_panel_complete %>%\n  filter(start_station %in% common_stations)\n\n# NOW create train/test split\ntrain <- study_panel_complete %>%\n  filter(week < 10)\n\ntest <- study_panel_complete %>%\n  filter(week >= 10)\n\ncat(\"Training observations:\", format(nrow(train), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining observations: 352,240 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing observations:\", format(nrow(test), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting observations: 153,748 \n```\n\n\n:::\n:::\n\n\n### Model 1: Baseline (Time + Weather)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntrain <- train %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\nmodel1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train\n)\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.9505 -0.4005 -0.1795  0.0221 18.5359 \n\nCoefficients:\n                    Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)       -0.1865881  0.0087166 -21.406 < 0.0000000000000002 ***\nas.factor(hour)1  -0.0254861  0.0087583  -2.910              0.00362 ** \nas.factor(hour)2  -0.0363902  0.0088009  -4.135  0.00003553166352764 ***\nas.factor(hour)3  -0.0525056  0.0087645  -5.991  0.00000000209104740 ***\nas.factor(hour)4  -0.0364554  0.0087381  -4.172  0.00003019750974031 ***\nas.factor(hour)5   0.0230901  0.0087069   2.652              0.00800 ** \nas.factor(hour)6   0.1744174  0.0087150  20.014 < 0.0000000000000002 ***\nas.factor(hour)7   0.3241655  0.0087182  37.183 < 0.0000000000000002 ***\nas.factor(hour)8   0.5499211  0.0087229  63.044 < 0.0000000000000002 ***\nas.factor(hour)9   0.3904427  0.0087209  44.771 < 0.0000000000000002 ***\nas.factor(hour)10  0.2810826  0.0087269  32.209 < 0.0000000000000002 ***\nas.factor(hour)11  0.2964398  0.0087321  33.948 < 0.0000000000000002 ***\nas.factor(hour)12  0.3676829  0.0087199  42.166 < 0.0000000000000002 ***\nas.factor(hour)13  0.3494810  0.0086973  40.183 < 0.0000000000000002 ***\nas.factor(hour)14  0.3519969  0.0086887  40.512 < 0.0000000000000002 ***\nas.factor(hour)15  0.4082093  0.0086904  46.972 < 0.0000000000000002 ***\nas.factor(hour)16  0.4901333  0.0086951  56.369 < 0.0000000000000002 ***\nas.factor(hour)17  0.6148350  0.0087059  70.623 < 0.0000000000000002 ***\nas.factor(hour)18  0.4245184  0.0087149  48.712 < 0.0000000000000002 ***\nas.factor(hour)19  0.2709915  0.0087215  31.072 < 0.0000000000000002 ***\nas.factor(hour)20  0.1498838  0.0087168  17.195 < 0.0000000000000002 ***\nas.factor(hour)21  0.0883229  0.0087071  10.144 < 0.0000000000000002 ***\nas.factor(hour)22  0.0688853  0.0086978   7.920  0.00000000000000239 ***\nas.factor(hour)23  0.0416985  0.0086883   4.799  0.00000159201720578 ***\ndotw_simple2       0.0534158  0.0046920  11.384 < 0.0000000000000002 ***\ndotw_simple3       0.0591069  0.0048452  12.199 < 0.0000000000000002 ***\ndotw_simple4       0.0329187  0.0046852   7.026  0.00000000000212695 ***\ndotw_simple5       0.0432028  0.0046773   9.237 < 0.0000000000000002 ***\ndotw_simple6      -0.0654894  0.0046757 -14.006 < 0.0000000000000002 ***\ndotw_simple7      -0.0629789  0.0047034 -13.390 < 0.0000000000000002 ***\nTemperature        0.0079845  0.0001544  51.702 < 0.0000000000000002 ***\nPrecipitation     -2.5026380  0.1914911 -13.069 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.746 on 352208 degrees of freedom\nMultiple R-squared:  0.07881,\tAdjusted R-squared:  0.07873 \nF-statistic:   972 on 31 and 352208 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\nThe model uses Monday as the baseline. Each coefficient represents the difference in expected trips per station-hour compared to Monday. For example, dow_simple2 = Tuesday.\n\n**Weekday Pattern (Tue-Fri):**\n\n-   All weekdays have positive coefficients (0.029 to 0.052)\n-   Tuesday has the highest weekday effect (+0.052)\n-   Weekdays likely benefit from concentrated commuting patterns\n\n**Weekend Pattern (Sat-Sun):**\n\n-   Both weekend days have negative coefficients (-0.061 and -0.065)\n-   This means fewer trips per station-hour than Monday\n\n### Model 2: Add Temporal Lags\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation + \n    lag1Hour + lag3Hours + lag1day, # temporal lags\n  data = train\n)\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.8168 -0.2847 -0.1032  0.0169 17.7976 \n\nCoefficients:\n                    Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)       -0.0981452  0.0079807 -12.298 < 0.0000000000000002 ***\nas.factor(hour)1  -0.0073089  0.0080114  -0.912              0.36161    \nas.factor(hour)2  -0.0056704  0.0080509  -0.704              0.48124    \nas.factor(hour)3  -0.0098486  0.0080187  -1.228              0.21937    \nas.factor(hour)4   0.0073214  0.0079952   0.916              0.35981    \nas.factor(hour)5   0.0541355  0.0079676   6.794  0.00000000001088671 ***\nas.factor(hour)6   0.1598589  0.0079803  20.032 < 0.0000000000000002 ***\nas.factor(hour)7   0.2402233  0.0079951  30.046 < 0.0000000000000002 ***\nas.factor(hour)8   0.3755384  0.0080279  46.779 < 0.0000000000000002 ***\nas.factor(hour)9   0.1807415  0.0080254  22.521 < 0.0000000000000002 ***\nas.factor(hour)10  0.1188012  0.0080068  14.838 < 0.0000000000000002 ***\nas.factor(hour)11  0.1347784  0.0080231  16.799 < 0.0000000000000002 ***\nas.factor(hour)12  0.2042401  0.0080027  25.521 < 0.0000000000000002 ***\nas.factor(hour)13  0.1863749  0.0079803  23.354 < 0.0000000000000002 ***\nas.factor(hour)14  0.1933502  0.0079711  24.256 < 0.0000000000000002 ***\nas.factor(hour)15  0.2303877  0.0079791  28.874 < 0.0000000000000002 ***\nas.factor(hour)16  0.2798055  0.0079958  34.994 < 0.0000000000000002 ***\nas.factor(hour)17  0.3592389  0.0080276  44.750 < 0.0000000000000002 ***\nas.factor(hour)18  0.1723963  0.0080312  21.466 < 0.0000000000000002 ***\nas.factor(hour)19  0.0896528  0.0080112  11.191 < 0.0000000000000002 ***\nas.factor(hour)20  0.0154708  0.0080102   1.931              0.05344 .  \nas.factor(hour)21  0.0133420  0.0079787   1.672              0.09449 .  \nas.factor(hour)22  0.0257497  0.0079603   3.235              0.00122 ** \nas.factor(hour)23  0.0204881  0.0079476   2.578              0.00994 ** \ndotw_simple2       0.0203302  0.0042937   4.735  0.00000219283951014 ***\ndotw_simple3       0.0107868  0.0044368   2.431              0.01505 *  \ndotw_simple4      -0.0016960  0.0042891  -0.395              0.69254    \ndotw_simple5       0.0111818  0.0042805   2.612              0.00900 ** \ndotw_simple6      -0.0723041  0.0042858 -16.871 < 0.0000000000000002 ***\ndotw_simple7      -0.0433412  0.0043053 -10.067 < 0.0000000000000002 ***\nTemperature        0.0036893  0.0001423  25.920 < 0.0000000000000002 ***\nPrecipitation     -1.3733842  0.1752334  -7.837  0.00000000000000461 ***\nlag1Hour           0.2285048  0.0016338 139.865 < 0.0000000000000002 ***\nlag3Hours          0.0974819  0.0016053  60.726 < 0.0000000000000002 ***\nlag1day            0.2350577  0.0016168 145.387 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6823 on 352205 degrees of freedom\nMultiple R-squared:  0.2293,\tAdjusted R-squared:  0.2292 \nF-statistic:  3082 on 34 and 352205 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n### Model 3: Add Demographics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y, # demographics\n  data = train\n)\ncat(\"Model 3 R-squared:\", summary(model3)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 3 R-squared: 0.1548858 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 3 Adj R-squared:\", summary(model3)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 3 Adj R-squared: 0.1544508 \n```\n\n\n:::\n:::\n\n\n### Model 4: Add Station Fixed Effects\n\nStation fixed effects capture baseline differences in demand across stations – some are just busier than others.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel4 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station), # station fixed effects\n  data = train\n)\n\ncat(\"Model 4 R-squared:\", summary(model4)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 R-squared: 0.1793657 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 4 Adj R-squared:\", summary(model4)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 Adj R-squared: 0.1762624 \n```\n\n\n:::\n:::\n\n\n### Model 5: Add Rush Hour Interaction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel5 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station) +\n    rush_hour * weekend,  # Rush hour effects different on weekends\n  data = train\n)\n\ncat(\"Model 5 R-squared:\", summary(model5)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 R-squared: 0.1841495 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 5 Adj R-squared:\", summary(model5)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 Adj R-squared: 0.18103 \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 7: Model Evaluation\n\n### 7.1 \\| Predictions on Test Set and MAE\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntest <- test %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n\ntest <- test %>%\n  mutate(\n    pred1 = predict(model1, newdata = test),\n    pred2 = predict(model2, newdata = test),\n    pred3 = predict(model3, newdata = test),\n    pred4 = predict(model4, newdata = test),\n    pred5 = predict(model5, newdata = test)\n  )\n\n# Calculate MAE for each model\nmae_results <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred1), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred3), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred4), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred5), na.rm = TRUE)\n  )\n)\n\nkable(mae_results, \n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Mean Absolute Error by Model (Test Set)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> MAE (trips) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.62 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.54 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. + Demographics </td>\n   <td style=\"text-align:right;\"> 0.77 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4. + Station FE </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.75 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### 7.2 \\| Visualize Model Comparison\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mae_results, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +\n  labs(\n    title = \"Model Performance Comparison\",\n    subtitle = \"Lower MAE = Better Predictions\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 8: Space-Time Error Analysis using Best Model\n\nWe conduct space-time error analysis using **Model 2 (Time + Weather + Temporal Lags)** which has the lowest MAE for Q1 2025 test data.\n\n### 8.1 \\| Observed vs Predicted\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- test %>%\n  mutate(\n    error = Trip_Count - pred2,\n    abs_error = abs(error),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      hour > 18 ~ \"Evening\"\n    )\n  )\n\n# Scatter plot by time and day type\nggplot(test, aes(x = Trip_Count, y = pred2)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Bike Trips\",\n    subtitle = \"Model 2 performance by time period\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\",\n    caption = \"Red line = perfect predictions; Green line = actual model fit\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/obs-vs-pred-1.png){width=672}\n:::\n:::\n\n\n### 8.2 \\| Spatial Error Patterns\n\n-   Create error maps\n-   Identify neighborhoods with high errors\n-   Hypothesize why (missing features? different demand patterns?)\n\n**Calculate MAE by Station**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate MAE by Station\nstation_errors <- test %>%\n  filter(!is.na(pred2)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n```\n:::\n\n\n**Visualize**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Base Map\nbase_map <- ggplot() +\n  geom_sf(data = philly_census,\n          fill = \"grey95\", color = \"white\", linewidth = 0.2) +\n  mapTheme\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Map 1: Prediction Errors (MAE)\np_err <- base_map +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size = 0.6,\n    alpha = 0.85\n  ) +\n  scale_color_viridis_c(\n    option   = \"plasma\",\n    direction = -1,\n    name     = \"MAE (trips)\"\n  ) +\n  labs(\n    title    = \"Prediction Errors\",\n    subtitle = \"MAE per station\"\n  ) +\n  theme(\n    legend.title = element_text(size = 10),\n    legend.text  = element_text(size = 8)\n  )\n\n# Map 2: Average Trip Demand\np_demand <- base_map +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 0.6,\n    alpha = 0.85\n  ) +\n  scale_color_viridis_c(\n    option   = \"viridis\",\n    direction = 1,\n    name     = \"Avg demand\\n(trips/hr)\"\n  ) +\n  labs(\n    title    = \"Average Demand\",\n    subtitle = \"Trips per station-hour\"\n  ) +\n  theme(\n    legend.title = element_text(size = 10),\n    legend.text  = element_text(size = 8)\n  )\n\ngrid.arrange(p_err, p_demand, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n### 8.3 \\| Temporal Error Patterns\n\n-   When are errors highest?\n-   Do certain hours/days have systematic under/over-prediction?\n-   Are there seasonal patterns?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MAE by time of day and day type\ntemporal_errors <- test %>%\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time Period\",\n    subtitle = \"When is the model struggling most?\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/temporal-errors-1.png){width=672}\n:::\n:::\n\n\n### 8.4 \\| Demographic Patterns\n\n-   Relate errors to census characteristics\n-   Are certain communities systematically harder to predict?\n-   What are the equity implications?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join demographic data to station errors\nstation_errors_demo <- station_errors %>%\n  left_join(\n    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\n# Create plots\np1 <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Errors vs. Median Income\", x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\np2 <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Transit Usage\", x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\np3 <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Race\", x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(p1, p2, p3, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/demographic-errors-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 9: Replicate with Q2 2025\n\n1.  **Download data** from: <https://www.rideindego.com/about/data/>\n2.  **Adapt this code** to work with your quarter:\n    -   Update date ranges for weather data\n    -   Check for any data structure changes\n    -   Create the same 5 models\n    -   Calculate MAE for each model\n3.  **Compare results** to Q1 2025:\n    -   How do MAE values compare? Why might they differ?\n    -   Are temporal patterns different (e.g., summer vs. winter)?\n    -   Which features are most important in your quarter?\n\n### 9.1 \\| Data Cleaning/Wrangling for Q2 2025\n\n**Create Time Bins**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindego_q2 <- indego_q2 %>%\n  mutate(\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins and extract time features\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n**Daily Trip Counts**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaily_trips <- indego_q2 %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q2 2025\",\n    subtitle = \"Spring demand patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n**Filter out Non-Residential Bike Share Stations**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter trip data to valid stations only\nindego_q2_census <- indego_q2 %>%\n  filter(start_station %in% valid_stations) %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n```\n:::\n\n\n### 9.2 \\| Space-Time Panel\n\n**Aggregate Trips to Station-Hour Level**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrips_q2_panel <- indego_q2_census %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n```\n:::\n\n\n**Create Complete Panel**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_q2_panel <- expand.grid(\n  interval60 = unique(trips_q2_panel$interval60),\n  start_station = unique(trips_q2_panel$start_station)\n) %>%\n  # Join trip counts\n  left_join(trips_q2_panel, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Fill in station attributes (they're the same for all hours)\nstation_q2_attributes <- trips_q2_panel %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_q2_panel <- study_q2_panel %>%\n  left_join(station_q2_attributes, by = \"start_station\")\n```\n:::\n\n\n**Add Time Features**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_q2_panel <- study_q2_panel %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n**Join Weather Data**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_q2_panel <- study_q2_panel %>%\n  left_join(weather_q2, by = \"interval60\")\nsummary(study_q2_panel %>% select(Trip_Count, Temperature, Precipitation))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Trip_Count       Temperature     Precipitation  \n Min.   : 0.0000   Min.   : 33.00   Min.   :0.000  \n 1st Qu.: 0.0000   1st Qu.: 57.00   1st Qu.:0.000  \n Median : 0.0000   Median : 66.00   Median :0.000  \n Mean   : 0.6418   Mean   : 65.64   Mean   :0.002  \n 3rd Qu.: 1.0000   3rd Qu.: 74.00   3rd Qu.:0.000  \n Max.   :27.0000   Max.   :100.00   Max.   :0.590  \n                   NA's   :6075     NA's   :6075   \n```\n\n\n:::\n:::\n\n\n### 9.3 \\| Create Temporal Lag Variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_q2 <- study_q2_panel %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_q2 <- study_q2 %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_q2_complete <- study_q2 %>%\n  filter(!is.na(lag1day))\n```\n:::\n\n\n### 9.4 \\| Build 5 Predictive Models\n\n**Temporal Train/Test Split**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncount(study_q2_complete, week)\nstudy_q2_complete\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Train on Weeks 14-22\n# Test on Weeks 23-26\nearly_q2_stations <- study_q2_complete %>%\n  filter(week < 23) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_q2_stations <- study_q2_complete %>%\n  filter(week >= 23) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\ncommon_q2_stations <- intersect(early_q2_stations, \n                                late_q2_stations)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter panel to only common stations\nstudy_q2_complete <- study_q2_complete %>%\n  filter(start_station %in% common_q2_stations)\n\n# create train/test split\ntrain_q2 <- study_q2_complete %>%\n  filter(week < 23)\n\ntest_q2 <- study_q2_complete %>%\n  filter(week >= 23)\n\ncat(\"Training observations:\", format(nrow(train_q2), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining observations: 364,210 \n```\n\n\n:::\n:::\n\n\n**Model 1: Baseline (Time + Weather)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_q2 <- train_q2 %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ncontrasts(train_q2$dotw_simple) <- contr.treatment(7)\n\nmodel1_q2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train_q2\n)\nsummary(model1_q2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation, data = train_q2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6824 -0.6754 -0.2075  0.1946 25.4742 \n\nCoefficients:\n                    Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)       -0.5696234  0.0166219 -34.269 < 0.0000000000000002 ***\nas.factor(hour)1  -0.0464595  0.0131866  -3.523             0.000426 ***\nas.factor(hour)2  -0.0583958  0.0131927  -4.426   0.0000095859103524 ***\nas.factor(hour)3  -0.1012772  0.0132039  -7.670   0.0000000000000172 ***\nas.factor(hour)4  -0.0810538  0.0132249  -6.129   0.0000000008858276 ***\nas.factor(hour)5   0.0164398  0.0132386   1.242             0.214307    \nas.factor(hour)6   0.2422479  0.0132002  18.352 < 0.0000000000000002 ***\nas.factor(hour)7   0.5042657  0.0132113  38.169 < 0.0000000000000002 ***\nas.factor(hour)8   0.8721289  0.0132212  65.965 < 0.0000000000000002 ***\nas.factor(hour)9   0.6538501  0.0132470  49.358 < 0.0000000000000002 ***\nas.factor(hour)10  0.5317584  0.0132172  40.232 < 0.0000000000000002 ***\nas.factor(hour)11  0.5720271  0.0131838  43.389 < 0.0000000000000002 ***\nas.factor(hour)12  0.6074526  0.0131523  46.186 < 0.0000000000000002 ***\nas.factor(hour)13  0.6307984  0.0131351  48.024 < 0.0000000000000002 ***\nas.factor(hour)14  0.6633381  0.0131283  50.527 < 0.0000000000000002 ***\nas.factor(hour)15  0.7442104  0.0131355  56.656 < 0.0000000000000002 ***\nas.factor(hour)16  0.9101606  0.0131464  69.233 < 0.0000000000000002 ***\nas.factor(hour)17  1.2191892  0.0132175  92.240 < 0.0000000000000002 ***\nas.factor(hour)18  0.9755571  0.0131802  74.017 < 0.0000000000000002 ***\nas.factor(hour)19  0.6826233  0.0131833  51.779 < 0.0000000000000002 ***\nas.factor(hour)20  0.4262897  0.0131818  32.339 < 0.0000000000000002 ***\nas.factor(hour)21  0.2728711  0.0131737  20.713 < 0.0000000000000002 ***\nas.factor(hour)22  0.1877722  0.0131524  14.277 < 0.0000000000000002 ***\nas.factor(hour)23  0.0810141  0.0131364   6.167   0.0000000006960077 ***\ndotw_simple2       0.0333828  0.0070879   4.710   0.0000024803544317 ***\ndotw_simple3      -0.0071563  0.0070882  -1.010             0.312685    \ndotw_simple4       0.0535764  0.0070406   7.610   0.0000000000000275 ***\ndotw_simple5      -0.0259107  0.0070527  -3.674             0.000239 ***\ndotw_simple6      -0.0457166  0.0070539  -6.481   0.0000000000912192 ***\ndotw_simple7      -0.0782260  0.0070345 -11.120 < 0.0000000000000002 ***\nTemperature        0.0123957  0.0002067  59.967 < 0.0000000000000002 ***\nPrecipitation     -0.8301985  0.0957072  -8.674 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.137 on 363936 degrees of freedom\n  (242 observations deleted due to missingness)\nMultiple R-squared:  0.1148,\tAdjusted R-squared:  0.1147 \nF-statistic:  1522 on 31 and 363936 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n**Model 2: Add Temporal Lags**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2_q2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation + \n    lag1Hour + lag3Hours + lag1day,\n  data = train_q2\n)\nsummary(model2_q2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day, data = train_q2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.6009  -0.4869  -0.1344   0.1315  20.6970 \n\nCoefficients:\n                    Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)       -0.2796263  0.0148076 -18.884 < 0.0000000000000002 ***\nas.factor(hour)1   0.0007749  0.0117249   0.066              0.94731    \nas.factor(hour)2   0.0187669  0.0117332   1.599              0.10972    \nas.factor(hour)3   0.0027743  0.0117472   0.236              0.81330    \nas.factor(hour)4   0.0353638  0.0117687   3.005              0.00266 ** \nas.factor(hour)5   0.1099521  0.0117828   9.332 < 0.0000000000000002 ***\nas.factor(hour)6   0.2605154  0.0117586  22.155 < 0.0000000000000002 ***\nas.factor(hour)7   0.4010269  0.0117892  34.016 < 0.0000000000000002 ***\nas.factor(hour)8   0.6060499  0.0118449  51.165 < 0.0000000000000002 ***\nas.factor(hour)9   0.3158042  0.0118585  26.631 < 0.0000000000000002 ***\nas.factor(hour)10  0.2556785  0.0117878  21.690 < 0.0000000000000002 ***\nas.factor(hour)11  0.2777351  0.0117649  23.607 < 0.0000000000000002 ***\nas.factor(hour)12  0.3258458  0.0117306  27.777 < 0.0000000000000002 ***\nas.factor(hour)13  0.3481209  0.0117208  29.701 < 0.0000000000000002 ***\nas.factor(hour)14  0.3608107  0.0117196  30.787 < 0.0000000000000002 ***\nas.factor(hour)15  0.4095141  0.0117361  34.894 < 0.0000000000000002 ***\nas.factor(hour)16  0.5110286  0.0117714  43.413 < 0.0000000000000002 ***\nas.factor(hour)17  0.6988166  0.0118974  58.737 < 0.0000000000000002 ***\nas.factor(hour)18  0.4222649  0.0118666  35.584 < 0.0000000000000002 ***\nas.factor(hour)19  0.2386819  0.0118094  20.211 < 0.0000000000000002 ***\nas.factor(hour)20  0.0796276  0.0117996   6.748      0.0000000000150 ***\nas.factor(hour)21  0.0520767  0.0117520   4.431      0.0000093693149 ***\nas.factor(hour)22  0.0548516  0.0117068   4.685      0.0000027946352 ***\nas.factor(hour)23  0.0200955  0.0116811   1.720              0.08537 .  \ndotw_simple2       0.0117607  0.0063020   1.866              0.06202 .  \ndotw_simple3      -0.0411918  0.0063055  -6.533      0.0000000000647 ***\ndotw_simple4       0.0265191  0.0062602   4.236      0.0000227443145 ***\ndotw_simple5      -0.0378583  0.0062723  -6.036      0.0000000015834 ***\ndotw_simple6      -0.0361729  0.0062724  -5.767      0.0000000080773 ***\ndotw_simple7      -0.0617899  0.0062559  -9.877 < 0.0000000000000002 ***\nTemperature        0.0047819  0.0001856  25.768 < 0.0000000000000002 ***\nPrecipitation     -0.3988956  0.0851207  -4.686      0.0000027838071 ***\nlag1Hour           0.2536160  0.0015983 158.681 < 0.0000000000000002 ***\nlag3Hours          0.1191525  0.0015653  76.121 < 0.0000000000000002 ***\nlag1day            0.2480216  0.0015661 158.368 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 363933 degrees of freedom\n  (242 observations deleted due to missingness)\nMultiple R-squared:  0.3003,\tAdjusted R-squared:  0.3002 \nF-statistic:  4594 on 34 and 363933 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n**Model 3: Add Demographics**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3_q2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y,\n  data = train_q2\n)\ncat(\"Model 3 R-squared:\", summary(model3_q2)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 3 R-squared: 0.2042621 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 3 Adj R-squared:\", summary(model3_q2)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 3 Adj R-squared: 0.2040146 \n```\n\n\n:::\n:::\n\n\n**Model 4: Add Station Fixed Effects**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel4_q2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station),\n  data = train_q2\n)\n\ncat(\"Model 4 R-squared:\", summary(model4_q2)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 R-squared: 0.2341957 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 4 Adj R-squared:\", summary(model4_q2)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 Adj R-squared: 0.2324218 \n```\n\n\n:::\n:::\n\n\n**Model 5: Add Rush Hour Interaction**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel5_q2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station) +\n    rush_hour * weekend,  # Rush hour effects different on weekends\n  data = train_q2\n)\n\ncat(\"Model 5 R-squared:\", summary(model5_q2)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 R-squared: 0.239317 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 5 Adj R-squared:\", summary(model5_q2)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 Adj R-squared: 0.2375357 \n```\n\n\n:::\n:::\n\n\n### 9.5 \\| Model Evaluation\n\n**Prediction on Test Set and MAE**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntest_q2 <- test_q2 %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\ntest_q2 <- test_q2 %>%\n  mutate(\n    pred1 = predict(model1_q2, newdata = test_q2),\n    pred2 = predict(model2_q2, newdata = test_q2),\n    pred3 = predict(model3_q2, newdata = test_q2),\n    pred4 = predict(model4_q2, newdata = test_q2),\n    pred5 = predict(model5_q2, newdata = test_q2)\n  )\n\n# Calculate MAE for each model\nmae_results_q2 <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test_q2$Trip_Count - test_q2$pred1), na.rm = TRUE),\n    mean(abs(test_q2$Trip_Count - test_q2$pred2), na.rm = TRUE),\n    mean(abs(test_q2$Trip_Count - test_q2$pred3), na.rm = TRUE),\n    mean(abs(test_q2$Trip_Count - test_q2$pred4), na.rm = TRUE),\n    mean(abs(test_q2$Trip_Count - test_q2$pred5), na.rm = TRUE)\n  )\n)\n\nkable(mae_results_q2, \n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Test Set) - Q2 2025\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Mean Absolute Error by Model (Test Set) - Q2 2025</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> MAE (trips) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.84 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.70 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. + Demographics </td>\n   <td style=\"text-align:right;\"> 0.94 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4. + Station FE </td>\n   <td style=\"text-align:right;\"> 0.92 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.96 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Visualize Model Comparison**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mae_results_q2, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +\n  labs(\n    title = \"Model Performance Comparison - Q2 2025\",\n    subtitle = \"Lower MAE = Better Predictions\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-42-1.png){width=672}\n:::\n:::\n\n\n### 9.6 \\| Space-Time Error Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_q2 <- test_q2 %>%\n  mutate(\n    error = Trip_Count - pred2,\n    abs_error = abs(error),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      hour > 18 ~ \"Evening\"\n    )\n  )\n\n# Scatter plot by time and day type\nggplot(test_q2, aes(x = Trip_Count, y = pred2)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Bike Trips - Q2 2025\",\n    subtitle = \"Model 2 performance by time period\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\",\n    caption = \"Red line = perfect predictions; Green line = actual model fit\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\n**Spatial Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate MAE by Station\nstation_errors_q2 <- test_q2 %>%\n  filter(!is.na(pred2)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n# Base Map\nbase_map <- ggplot() +\n  geom_sf(data = philly_census,\n          fill = \"grey95\", color = \"white\", linewidth = 0.2) +\n  mapTheme\n\n# Map 1: Prediction Errors (MAE)\np_err_q2 <- base_map +\n  geom_point(\n    data = station_errors_q2,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size = 0.6, alpha = 0.85\n  ) +\n  scale_color_viridis_c(option = \"plasma\", direction = -1, name = \"MAE (trips)\") +\n  labs(\n    title    = \"Prediction Errors\",\n    subtitle = \"MAE per station\"\n  ) +\n  theme(\n    legend.title = element_text(size = 10),\n    legend.text  = element_text(size = 8)\n  )\n\n# Map 2: Average Trip Demand\np_demand_q2 <- base_map +\n  geom_point(\n    data = station_errors_q2,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 0.6, alpha = 0.85\n  ) +\n  scale_color_viridis_c(option = \"viridis\",\n    direction = 1, name = \"Avg demand\\n(trips/hr)\"\n  ) +\n  labs(\n    title    = \"Average Demand\",\n    subtitle = \"Trips per station-hour\"\n  ) +\n  theme(\n    legend.title = element_text(size = 10),\n    legend.text  = element_text(size = 8)\n  )\n\ngrid.arrange(p_err_q2, p_demand_q2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n:::\n\n\n**Temporal Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MAE by time of y and day type\ntemporal_errors_q2 <- test_q2 %>%\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors_q2, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time Period - Q2 2025\",\n    subtitle = \"When is the model struggling most?\",\n    x = \"Time of Day\",\n    y = \"MAE (trips)\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n:::\n\n\n**Demographic Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join demographic data to station errors\nstation_errors_demo_q2 <- station_errors_q2 %>%\n  left_join(\n    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\n# Create plots\np1_q2 <- ggplot(station_errors_demo_q2, aes(x = Med_Inc, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Errors vs. Median Income\", x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\np2_q2 <- ggplot(station_errors_demo_q2, aes(x = Percent_Taking_Transit, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Transit Usage\", x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\np3_q2 <- ggplot(station_errors_demo_q2, aes(x = Percent_White, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Race\", x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(p1_q2, p2_q2, p3_q2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-46-1.png){width=672}\n:::\n:::\n\n\n## Part 10: Error Analysis for Q2 2025 vs Q1 2025\n\n**Compare MAE Across Quarters**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmae_all <- bind_rows(\n  mae_results    %>% mutate(Quarter = \"Q1 2025\"),\n  mae_results_q2 %>% mutate(Quarter = \"Q2 2025\")\n)\nmae_wide <- mae_all %>%\n  pivot_wider(names_from = Quarter, values_from = MAE)\n\nkable(\n  mae_wide,\n  digits  = 2,\n  caption = \"Mean Absolute Error by Model: Q1 vs Q2 2025\",\n  col.names = c(\"Model\", \"Q1 2025 MAE (trips)\", \"Q2 2025 MAE (trips)\")\n) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Mean Absolute Error by Model: Q1 vs Q2 2025</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> Q1 2025 MAE (trips) </th>\n   <th style=\"text-align:right;\"> Q2 2025 MAE (trips) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.62 </td>\n   <td style=\"text-align:right;\"> 0.84 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.54 </td>\n   <td style=\"text-align:right;\"> 0.70 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. + Demographics </td>\n   <td style=\"text-align:right;\"> 0.77 </td>\n   <td style=\"text-align:right;\"> 0.94 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4. + Station FE </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n   <td style=\"text-align:right;\"> 0.92 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.75 </td>\n   <td style=\"text-align:right;\"> 0.96 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n\n```{.r .cell-code}\nggplot(mae_all, aes(x = Model, y = MAE, fill = Quarter)) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  labs(\n    title = \"Model Performance by Quarter\",\n    y = \"MAE (trips)\",\n    x = NULL\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-47-1.png){width=672}\n:::\n:::\n\n\n**Temporal Error Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## 2. Temporal error patterns (time-of-day, by quarter\ntemporal_all <- bind_rows(\n  temporal_errors    %>% mutate(Quarter = \"Q1 2025\"),\n  temporal_errors_q2 %>% mutate(Quarter = \"Q2 2025\")\n) %>%\n  # Optional: enforce an ordering of time-of-day buckets if you have them\n  mutate(\n    time_of_day = factor(time_of_day,\n                         levels = unique(time_of_day))  # or your own ordered vector\n  )\n\nggplot(temporal_all,\n       aes(x = time_of_day, y = MAE, fill = Quarter)) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ day_type) +\n  labs(\n    title = \"Prediction Errors by Time of Day\",\n    subtitle = \"Q1 vs Q2 2025\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Quarter\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-48-1.png){width=672}\n:::\n:::\n\n\n**Spatial Error Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstations_all <- bind_rows(\n  station_errors    %>% mutate(Quarter = \"Q1 2025\"),\n  station_errors_q2 %>% mutate(Quarter = \"Q2 2025\")\n)\n\nggplot() +\n  geom_sf(data = philly_census,\n          fill = \"grey95\", color = \"white\", linewidth = 0.2) +\n  geom_point(\n    data = stations_all,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size  = 1.3,\n    alpha = 0.85\n  ) +\n  facet_wrap(~ Quarter) +\n  scale_color_viridis_c(name = \"MAE (trips)\") +\n  labs(\n    title = \"Spatial Distribution of Prediction Errors\",\n    subtitle = \"Station-level MAE by quarter\",\n    x = NULL, y = NULL\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-49-1.png){width=672}\n:::\n:::\n\n\n**Which Features Matter Most?**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# NOTE: this is a simple coefficient comparison; ideally predictors are standardized.\n\nimp_q1 <- tidy(model2) %>%\n  filter(term != \"(Intercept)\") %>%\n  mutate(Quarter = \"Q1 2025\")\n\nimp_q2 <- tidy(model2_q2) %>%\n  filter(term != \"(Intercept)\") %>%\n  mutate(Quarter = \"Q2 2025\")\n\nimp_all <- bind_rows(imp_q1, imp_q2) %>%\n  mutate(abs_est = abs(estimate)) %>%\n  group_by(Quarter) %>%\n  slice_max(order_by = abs_est, n = 10) %>%\n  ungroup()\n\nggplot(imp_all,\n       aes(x = reorder(term, abs_est), y = abs_est, fill = Quarter)) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  labs(\n    title = \"Most Influential Features (Model 2)\",\n    x = \"Predictor (top 10 per quarter)\",\n    y = \"|Coefficient|\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-50-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 11: Feature Engineering & model improvement\n\nBased on your error analysis, add 2-3 NEW features to improve the model:\n\n**Potential features to consider:**\n\n*Temporal features:*\n\n-   Holiday indicators (Memorial Day, July 4th, Labor Day)\n-   School calendar (Penn, Drexel, Temple in session?)\n-   Special events (concerts, sports games, conventions)\n-   Day of month (payday effects?)\n\n*Weather features:*\n\n-   Feels-like temperature (wind chill/heat index)\n-   \"Perfect biking weather\" indicator (60-75°F, no rain)\n-   Precipitation forecast (not just current)\n-   Weekend + nice weather interaction\n\n*Spatial features:*\n\n-   Distance to Center City\n-   Distance to nearest university\n-   Distance to nearest park\n-   Points of interest nearby (restaurants, offices, bars)\n-   Station capacity\n-   Bike lane connectivity\n\n*Trip history features:*\n\n-   Rolling 7-day average demand\n-   Same hour last week\n-   Station \"type\" clustering (residential, commercial, tourist)\n\n**Implementation:**\n\n-   Add your features to the best model\n-   Compare MAE before and after\n-   Explain *why* you chose these features\n-   Did they improve predictions? Where?\n\n**Try a poisson model for count data**\n\n-   Does this improve model fit?\n\n### Refined Rush Hour (Code Shell)\n\n\n::: {.cell}\n\n```{.r .cell-code}\npanel_df <- panel_df %>%\n  mutate(\n    # Weekday flag (commute concept)\n    is_weekday = dotw %in% c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"),\n\n    # Classic commute rush hour, but ONLY on weekdays\n    rush_hour = ifelse(is_weekday & hour %in% c(7, 8, 9, 16, 17, 18), 1L, 0L),\n\n    # Separate AM / PM peaks (handy for interactions)\n    am_peak = ifelse(is_weekday & hour %in% c(7, 8, 9), 1L, 0L),\n    pm_peak = ifelse(is_weekday & hour %in% c(16, 17, 18), 1L, 0L),\n\n    # Weekend “leisure peak” – people ride mid-day instead of commute times\n    weekend_midday_peak = ifelse(!is_weekday & hour %in% 11:17, 1L, 0L)\n  )\n```\n:::\n\n\n### Weather-Based Features (Code Shell)\n\n-   can try interactions like rush_hour \\* perfect_bike_weather\n\n\n::: {.cell}\n\n```{.r .cell-code}\npanel_df <- panel_df %>%\n  mutate(\n    perfect_bike_weather = ifelse(\n      !is.na(feel) &\n        feel >= 55 & feel <= 80 &        # comfy feels-like temp\n        Precipitation == 0 &             # no rain\n        Wind_Speed <= 15,                # not too windy\n      1L, 0L\n    ),\n\n    bad_weather = ifelse(\n      !is.na(feel) &\n        (feel < 40 | feel > 90 |         # too cold/hot by feels-like\n         Precipitation > 0.01 |\n         Wind_Speed > 20),\n      1L, 0L\n    )\n  )\n```\n:::\n\n\n### Poisson Model (Code Shell)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Poisson model\nmodel_poisson <- glm(\n  countBurglaries ~ Abandoned_Cars + Abandoned_Cars.nn + abandoned.isSig.dist,\n  data = fishnet,\n  family = poisson(link = \"log\")\n)\n\n# Exponentiate coefficients for interpretation\nsummary(model_poisson)\nexp(coef(model_poisson))\n\n# Example output:\n#                        exp(coef)\n# (Intercept)            0.234\n# Abandoned_Cars         1.151\n# Abandoned_Cars.nn      0.998\n# abandoned.isSig.dist   0.999\n\n# Interpretation:\n# - Each additional abandoned car → 15.1% increase in expected burglaries\n# - Each meter from nearest abandoned car → 0.2% decrease in expected burglaries\n```\n:::\n\n\n**Poisson: Check for Overdispersion**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#  Calculate dispersion parameter\ndispersion <- sum(residuals(model_pois, type = \"pearson\")^2) / \n               model_pois$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 3), \"\\n\")\n\n# Rule of thumb:\n# < 1.5: Poisson OK\n# 1.5 - 3: Mild overdispersion, NegBin recommended (negative binomial)\n# > 3: Serious overdispersion, NegBin essential\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Conclusion: Critical Reflection\n\nWrite 1-2 paragraphs addressing:\n\n1.  **Operational implications:**\n    -   Is your final MAE \"good enough\" for Indego to use?\n    -   When do prediction errors cause problems for rebalancing?\n    -   Would you recommend deploying this system? Under what conditions?\n2.  **Equity considerations:**\n    -   Do prediction errors disproportionately affect certain neighborhoods?\n    -   Could this system worsen existing disparities in bike access?\n    -   What safeguards would you recommend?\n3.  **Model limitations:**\n    -   What patterns is your model missing?\n    -   What assumptions might not hold in real deployment?\n    -   How would you improve this with more time/data?\n\n------------------------------------------------------------------------\n\n### Brief report summarizing (with supporting data & visualization):\n\n-   Your quarter and why you chose it\n-   Model comparison results\n-   Error analysis insights\n-   New features you added and why\n-   Critical reflection on deployment\n\n------------------------------------------------------------------------\n\n### Fun Animations\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrideshare_animation <-\n  ggplot() +\n    geom_sf(data = ride.animation.data, aes(fill = Trips)) +\n    scale_fill_manual(values = palette5) +\n    labs(title = \"Rideshare pickups for one day in November 2018\",\n         subtitle = \"15 minute intervals: {current_frame}\") +\n    transition_manual(interval15) + # new map generated for each 15-min interval\n    mapTheme()\n\n# create 20-sec gif    \nanimate(rideshare_animation, duration=20, renderer = gifski_renderer())\n```\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}