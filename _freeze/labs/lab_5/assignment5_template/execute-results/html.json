{
  "hash": "13fa963659a6038077a52dd39f463a4d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Assignment 5: Space-Time Prediction of Indego Bike Share Demand\"\nauthor: \"Jed Chew and Muhammad Al Abbas\"\ndate: 12/1/2025\nformat:\n  html:\n    code-fold: show\n    code-tools: true\n    toc: true\n    toc-depth: 3\n    toc-location: left\n    theme: cosmo\n    embed-resources: true\neditor: visual\nexecute:\n  warning: false\n  message: false\n---\n\n# The Rebalancing Challenge in Philadelphia\n\nPhiladelphia's Indego bike share system faces the same operational challenge as every bike share system: **rebalancing bikes to meet anticipated demand**.\n\nImagine you're an Indego operations manager at 6:00 AM on a Monday morning. You have: - 200 stations across Philadelphia - Limited trucks and staff for moving bikes - 2-3 hours before morning rush hour demand peaks - **The question:** Which stations will run out of bikes by 8:30 AM?\n\nThis lab will teach you to build predictive models that forecast bike share demand across **space** (different stations) and **time** (different hours) to help solve this operational problem.\n\n## Learning Objectives\n\nBy the end of this assignment, you will be able to:\n\n1.  **Understand panel data structure** for space-time analysis\n2.  **Create temporal lag variables** to capture demand persistence\n3.  **Build multiple predictive models** with increasing complexity\n4.  **Validate models temporally** (train on past, test on future)\n5.  **Analyze prediction errors** in both space and time\n6.  **Engineer new features** based on error patterns\n7.  **Critically evaluate** when prediction errors matter most\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(tigris)\nlibrary(tidycensus)\nlibrary(here)\nlibrary(riem)  # For Philadelphia weather from ASOS stations\n\n# Visualization\nlibrary(viridis)\nlibrary(gridExtra)\nlibrary(knitr)\nlibrary(kableExtra)\n\noptions(scipen = 999)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),\n  axis.text.y = element_text(size = 10),\n  axis.title = element_text(size = 11, face = \"bold\"),\n  panel.background = element_blank(),\n  panel.grid.major = element_line(colour = \"#D0D0D0\", size = 0.2),\n  panel.grid.minor = element_blank(),\n  axis.ticks = element_blank(),\n  legend.position = \"right\"\n)\n\nmapTheme <- theme(\n  plot.title = element_text(size = 14, face = \"bold\"),\n  plot.subtitle = element_text(size = 10),\n  plot.caption = element_text(size = 8),\n  axis.line = element_blank(),\n  axis.text = element_blank(),\n  axis.ticks = element_blank(),\n  axis.title = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_line(colour = 'transparent'),\n  panel.grid.minor = element_blank(),\n  legend.position = \"right\",\n  plot.margin = margin(1, 1, 1, 1, 'cm'),\n  legend.key.height = unit(1, \"cm\"),\n  legend.key.width = unit(0.2, \"cm\")\n)\n\npalette5 <- c(\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#3182bd\", \"#08519c\")\n```\n:::\n\n\n\n\n## Part 1:  Data Import & Preparation\n\n### 1.1 \\| Load Indego Trip Data\n\n**Data Dictionary**\n\n-   **trip_id:** Locally unique integer that identifies the trip\n-   **duration:** Length of trip in minutes\n-   **start_time & end_time**\n-   **start_station; start_lat; start_lon**\n-   **end_station; end_lat; end_lon**\n-   **bike_id:** Locally unique integer that identifies the bike\n-   **plan_duration:** The number of days that the plan the passholder is using entitles them to ride; 0 is used for a single ride plan (Walk-up)\n-   **trip_route_category:** “Round Trip” for trips starting and ending at the same station or “One Way” for all other trips\n-   **passholder_type:** The name of the passholder’s plan\n-   **bike_type:** The kind of bike used on the trip, including standard pedal-powered bikes or electric assist bikes\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindego <- read_csv(\"data/indego-trips-2025-q1.csv\")\nindego_q2 <- read_csv(\"data/indego-trips-2025-q2.csv\")\nindego_q3 <- read_csv(\"data/indego-trips-2025-q3.csv\")\n```\n:::\n\n\n\n\n### 1.2 \\| Create Time Bins\n\n-   Helper function to create time bins – aggregate trips into hourly intervals for panel data structure\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindego <- indego %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n\n# Look at temporal features\nhead(indego %>% select(start_datetime, interval60, week, dotw, hour, weekend))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n  start_datetime      interval60           week dotw   hour weekend\n  <dttm>              <dttm>              <dbl> <ord> <int>   <dbl>\n1 2025-01-01 00:00:00 2025-01-01 00:00:00     1 Wed       0       0\n2 2025-01-01 00:04:00 2025-01-01 00:00:00     1 Wed       0       0\n3 2025-01-01 00:05:00 2025-01-01 00:00:00     1 Wed       0       0\n4 2025-01-01 00:05:00 2025-01-01 00:00:00     1 Wed       0       0\n5 2025-01-01 00:08:00 2025-01-01 00:00:00     1 Wed       0       0\n6 2025-01-01 00:14:00 2025-01-01 00:00:00     1 Wed       0       0\n```\n\n\n:::\n:::\n\n\n### 1.3 \\| Exploratory Data Analysis\n\n**Daily Trip Counts**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaily_trips <- indego %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q1 2025\",\n    subtitle = \"Winter demand patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/trips_over_time-1.png){width=672}\n:::\n:::\n\n\n**Hourly Patterns**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Average trips by hour and day type\nhourly_patterns <- indego %>%\n  group_by(hour, weekend) %>%\n  summarize(avg_trips = n() / n_distinct(date)) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(hourly_patterns, aes(x = hour, y = avg_trips, color = day_type)) +\n  geom_line(linewidth = 1.2) +\n  scale_color_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Average Hourly Ridership Patterns - Q1 2025\",\n    subtitle = \"Clear commute patterns on weekdays\",\n    x = \"Hour of Day\",\n    y = \"Average Trips per Hour\",\n    color = \"Day Type\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/hourly_patterns-1.png){width=672}\n:::\n:::\n\n\n**Top Stations**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Most popular origin stations\ntop_stations <- indego %>%\n  count(start_station, start_lat, start_lon, name = \"trips\") %>%\n  arrange(desc(trips)) %>%\n  head(20)\n\nkable(top_stations, \n      caption = \"**Top 20 Indego Stations by Trip Origins - Q1 2025**\",\n      format.args = list(big.mark = \",\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>**Top 20 Indego Stations by Trip Origins - Q1 2025**</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> start_station </th>\n   <th style=\"text-align:right;\"> start_lat </th>\n   <th style=\"text-align:right;\"> start_lon </th>\n   <th style=\"text-align:right;\"> trips </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 3,010 </td>\n   <td style=\"text-align:right;\"> 39.94711 </td>\n   <td style=\"text-align:right;\"> -75.16618 </td>\n   <td style=\"text-align:right;\"> 3,999 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,032 </td>\n   <td style=\"text-align:right;\"> 39.94527 </td>\n   <td style=\"text-align:right;\"> -75.17971 </td>\n   <td style=\"text-align:right;\"> 2,842 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,359 </td>\n   <td style=\"text-align:right;\"> 39.94888 </td>\n   <td style=\"text-align:right;\"> -75.16978 </td>\n   <td style=\"text-align:right;\"> 2,699 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,020 </td>\n   <td style=\"text-align:right;\"> 39.94855 </td>\n   <td style=\"text-align:right;\"> -75.19007 </td>\n   <td style=\"text-align:right;\"> 2,673 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,208 </td>\n   <td style=\"text-align:right;\"> 39.95048 </td>\n   <td style=\"text-align:right;\"> -75.19324 </td>\n   <td style=\"text-align:right;\"> 2,503 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,244 </td>\n   <td style=\"text-align:right;\"> 39.93865 </td>\n   <td style=\"text-align:right;\"> -75.16674 </td>\n   <td style=\"text-align:right;\"> 2,486 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,066 </td>\n   <td style=\"text-align:right;\"> 39.94561 </td>\n   <td style=\"text-align:right;\"> -75.17348 </td>\n   <td style=\"text-align:right;\"> 2,396 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,362 </td>\n   <td style=\"text-align:right;\"> 39.94816 </td>\n   <td style=\"text-align:right;\"> -75.16226 </td>\n   <td style=\"text-align:right;\"> 2,387 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,012 </td>\n   <td style=\"text-align:right;\"> 39.94218 </td>\n   <td style=\"text-align:right;\"> -75.17747 </td>\n   <td style=\"text-align:right;\"> 2,361 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,028 </td>\n   <td style=\"text-align:right;\"> 39.94061 </td>\n   <td style=\"text-align:right;\"> -75.14958 </td>\n   <td style=\"text-align:right;\"> 2,348 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,161 </td>\n   <td style=\"text-align:right;\"> 39.95486 </td>\n   <td style=\"text-align:right;\"> -75.18091 </td>\n   <td style=\"text-align:right;\"> 2,278 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,101 </td>\n   <td style=\"text-align:right;\"> 39.94295 </td>\n   <td style=\"text-align:right;\"> -75.15955 </td>\n   <td style=\"text-align:right;\"> 2,274 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,295 </td>\n   <td style=\"text-align:right;\"> 39.95028 </td>\n   <td style=\"text-align:right;\"> -75.16027 </td>\n   <td style=\"text-align:right;\"> 2,160 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,054 </td>\n   <td style=\"text-align:right;\"> 39.96250 </td>\n   <td style=\"text-align:right;\"> -75.17420 </td>\n   <td style=\"text-align:right;\"> 2,123 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,185 </td>\n   <td style=\"text-align:right;\"> 39.95169 </td>\n   <td style=\"text-align:right;\"> -75.15888 </td>\n   <td style=\"text-align:right;\"> 2,116 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,038 </td>\n   <td style=\"text-align:right;\"> 39.94781 </td>\n   <td style=\"text-align:right;\"> -75.19409 </td>\n   <td style=\"text-align:right;\"> 2,111 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,203 </td>\n   <td style=\"text-align:right;\"> 39.94077 </td>\n   <td style=\"text-align:right;\"> -75.17227 </td>\n   <td style=\"text-align:right;\"> 2,106 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,059 </td>\n   <td style=\"text-align:right;\"> 39.96244 </td>\n   <td style=\"text-align:right;\"> -75.16121 </td>\n   <td style=\"text-align:right;\"> 2,027 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,022 </td>\n   <td style=\"text-align:right;\"> 39.95472 </td>\n   <td style=\"text-align:right;\"> -75.18323 </td>\n   <td style=\"text-align:right;\"> 2,014 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3,063 </td>\n   <td style=\"text-align:right;\"> 39.94633 </td>\n   <td style=\"text-align:right;\"> -75.16980 </td>\n   <td style=\"text-align:right;\"> 2,014 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n::: callout-note\n## Observed Patterns for Q1 2025\n\n-   Lorem Ipsum\n:::\n\n------------------------------------------------------------------------\n\n## Part 2: Philadelphia Census Data\n\n### 2.1 \\| Load Philadelphia Census Data\n\n\n::: {.cell progress='false'}\n\n```{.r .cell-code}\n# Get Philadelphia census tracts\nphilly_census <- get_acs(\n  geography = \"tract\",\n  variables = c(\n    \"B01003_001\",  # Total population\n    \"B19013_001\",  # Median household income\n    \"B08301_001\",  # Total commuters\n    \"B08301_010\",  # Commute by transit\n    \"B02001_002\",  # White alone\n    \"B25077_001\"   # Median home value\n  ),\n  state = \"PA\",\n  county = \"Philadelphia\",\n  year = 2022,\n  geometry = TRUE,\n  output = \"wide\"\n) %>%\n  rename(\n    Total_Pop = B01003_001E,\n    Med_Inc = B19013_001E,\n    Total_Commuters = B08301_001E,\n    Transit_Commuters = B08301_010E,\n    White_Pop = B02001_002E,\n    Med_Home_Value = B25077_001E\n  ) %>%\n  mutate(\n    Percent_Taking_Transit = (Transit_Commuters / Total_Commuters) * 100,\n    Percent_White = (White_Pop / Total_Pop) * 100\n  ) %>%\n  st_transform(crs = 4326)  # WGS84 for lat/lon matching\n```\n:::\n\n\n### 2.2 \\| Map Philadelphia Context\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Map median income\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = NA) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Context for understanding bike share demand patterns\"\n  ) +\n  # Stations \n  geom_point(\n    data = indego,\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 0.25, alpha = 0.6\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/map-philly-1.png){width=672}\n:::\n:::\n\n\n### 2.3 \\| Join Census Data to Stations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create sf object for stations\nstations_sf <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  st_as_sf(coords = c(\"start_lon\", \"start_lat\"), crs = 4326)\n\n# Spatial join to get census tract for each station\nstations_census <- st_join(stations_sf, philly_census, left = TRUE) %>%\n  st_drop_geometry()\n```\n:::\n\n\n**Left-Join Census Data to Q1 Indego Data**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Look at the result - investigate whether all of the stations joined to census data -- according to the map above there are stations in non-residential tracts.\n\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Add back to trip data\nindego_census <- indego %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n\n# Prepare data for visualization\nstations_for_map <- indego %>%\n  distinct(start_station, start_lat, start_lon) %>%\n  filter(!is.na(start_lat), !is.na(start_lon)) %>%\n  left_join(\n    stations_census %>% select(start_station, Med_Inc),\n    by = \"start_station\"\n  ) %>%\n  mutate(has_census = !is.na(Med_Inc))\n\n# Create the map showing problem stations\nggplot() +\n  geom_sf(data = philly_census, aes(fill = Med_Inc), color = \"white\", size = 0.1) +\n  scale_fill_viridis(\n    option = \"viridis\",\n    name = \"Median\\nIncome\",\n    labels = scales::dollar,\n    na.value = \"grey90\"\n  ) +\n  # Stations with census data (small grey dots)\n  geom_point(\n    data = stations_for_map %>% filter(has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"grey30\", size = 1, alpha = 0.6\n  ) +\n  # Stations WITHOUT census data (red X marks the spot)\n  geom_point(\n    data = stations_for_map %>% filter(!has_census),\n    aes(x = start_lon, y = start_lat),\n    color = \"red\", size = 1, shape = 4, stroke = 1.5\n  ) +\n  labs(\n    title = \"Philadelphia Median Household Income by Census Tract\",\n    subtitle = \"Indego stations shown (RED = no census data match)\",\n    caption = \"Red X marks indicate stations that didn't join to census tracts\"\n  ) +\n  mapTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n::: callout-note\n## Observed Patterns\n\n-   Lorem Ipsum\n:::\n\n### 2.4 \\| Dealing with Missing Data\n\nWe need to decide what to do with the non-residential bike share stations. For this example, we are going to remove them.\n\nThis is not necessarily the right way to do things always, but for the sake of simplicity, we are narrowing our scope to only stations in residential neighborhoods. We might opt to create a separate model for non-residential stations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Identify which stations to keep\nvalid_stations <- stations_census %>%\n  filter(!is.na(Med_Inc)) %>%\n  pull(start_station)\n\n# Filter trip data to valid stations only\nindego_census <- indego %>%\n  filter(start_station %in% valid_stations) %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 3: Get Weather Data\n\n### 3.1 \\| Weather Data for Q1 2025\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get weather from Philadelphia International Airport (KPHL)\n# This covers Q1 2025: January 1 - March 31\nweather_data <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2025-01-01\",\n  date_end = \"2025-03-31\"\n)\n\n# Process weather data\nweather_processed <- weather_data %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  # updated in-class code to only keep the first row for each hour\n  distinct(interval60, .keep_all = TRUE) \n\n# Check for missing hours and interpolate if needed\nweather_complete <- weather_processed %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Look at the weather\nsummary(weather_complete %>% select(Temperature, Precipitation, Wind_Speed))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Temperature    Precipitation        Wind_Speed    \n Min.   :10.00   Min.   :0.000000   Min.   : 0.000  \n 1st Qu.:30.00   1st Qu.:0.000000   1st Qu.: 6.000  \n Median :37.00   Median :0.000000   Median : 8.000  \n Mean   :38.36   Mean   :0.001327   Mean   : 9.308  \n 3rd Qu.:46.00   3rd Qu.:0.000000   3rd Qu.:13.000  \n Max.   :78.00   Max.   :0.280000   Max.   :30.000  \n```\n\n\n:::\n:::\n\n\n### 3.2 \\| Weather Data for Q2 2025\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_q2 <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2025-04-01\",\n  date_end = \"2025-06-30\"\n)\n\n# Process weather data\nweather_q2 <- weather_q2 %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  # updated in-class code to only keep the first row for each hour\n  distinct(interval60, .keep_all = TRUE) \n\n# Check for missing hours and interpolate if needed\nweather_q2_complete <- weather_q2 %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Look at the weather\nsummary(weather_q2_complete %>% select(Temperature, Precipitation, Wind_Speed))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Temperature     Precipitation        Wind_Speed    \n Min.   : 33.00   Min.   :0.000000   Min.   : 0.000  \n 1st Qu.: 57.00   1st Qu.:0.000000   1st Qu.: 5.000  \n Median : 66.00   Median :0.000000   Median : 8.000  \n Mean   : 65.62   Mean   :0.002024   Mean   : 8.125  \n 3rd Qu.: 73.00   3rd Qu.:0.000000   3rd Qu.:11.000  \n Max.   :100.00   Max.   :0.590000   Max.   :27.000  \n```\n\n\n:::\n:::\n\n\n### 3.3 \\| Weather Data for Q3 2025\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_q3 <- riem_measures(\n  station = \"PHL\",  # Philadelphia International Airport\n  date_start = \"2025-07-01\",\n  date_end = \"2025-09-30\"\n)\n\n# Process weather data\nweather_q3 <- weather_q3 %>%\n  mutate(\n    interval60 = floor_date(valid, unit = \"hour\"),\n    Temperature = tmpf,  # Temperature in Fahrenheit\n    Precipitation = ifelse(is.na(p01i), 0, p01i),  # Hourly precip in inches\n    Wind_Speed = sknt  # Wind speed in knots\n  ) %>%\n  select(interval60, Temperature, Precipitation, Wind_Speed) %>%\n  # updated in-class code to only keep the first row for each hour\n  distinct(interval60, .keep_all = TRUE) \n\n# Check for missing hours and interpolate if needed\nweather_q3_complete <- weather_q3 %>%\n  complete(interval60 = seq(min(interval60), max(interval60), by = \"hour\")) %>%\n  fill(Temperature, Precipitation, Wind_Speed, .direction = \"down\")\n\n# Look at the weather\nsummary(weather_q3_complete %>% select(Temperature, Precipitation, Wind_Speed))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Temperature    Precipitation         Wind_Speed    \n Min.   :57.00   Min.   :0.0000000   Min.   : 0.000  \n 1st Qu.:70.00   1st Qu.:0.0000000   1st Qu.: 4.000  \n Median :76.00   Median :0.0000000   Median : 6.000  \n Mean   :75.94   Mean   :0.0008342   Mean   : 6.218  \n 3rd Qu.:81.00   3rd Qu.:0.0000000   3rd Qu.: 8.000  \n Max.   :98.00   Max.   :0.1000000   Max.   :25.000  \n```\n\n\n:::\n:::\n\n\n### 3.4 \\| Visualize Weather Patterns\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q1 2025\",\n    subtitle = \"Winter to Early Spring Transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_q2_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q2 2025\",\n    subtitle = \"Spring to Summer Transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_q3_complete, aes(x = interval60, y = Temperature)) +\n  geom_line(color = \"#3182bd\", alpha = 0.7) +\n  geom_smooth(se = FALSE, color = \"red\") +\n  labs(\n    title = \"Philadelphia Temperature - Q3 2025\",\n    subtitle = \"Summer to Fall Transition\",\n    x = \"Date\",\n    y = \"Temperature (°F)\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 4: Create Space-Time Panel\n\n### 4.1 \\| Aggregate Trips to Station-Hour Level\n\n**Q1 2025**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count trips by station-hour\ntrips_panel <- indego_census %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n\n# How many station-hour observations?\nnrow(trips_panel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 116718\n```\n\n\n:::\n\n```{.r .cell-code}\n# How many unique stations?\nlength(unique(trips_panel$start_station))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 245\n```\n\n\n:::\n\n```{.r .cell-code}\n# How many unique hours?\nlength(unique(trips_panel$interval60))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2150\n```\n\n\n:::\n:::\n\n\n### 4.2 \\| Create Complete Panel Structure\n\nNot every station has trips every hour. We need a **complete panel** where every station-hour combination exists (even if Trip_Count = 0).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate expected panel size\nn_stations <- length(unique(trips_panel$start_station))\nn_hours <- length(unique(trips_panel$interval60))\nexpected_rows <- n_stations * n_hours\n\ncat(\"Expected panel rows:\", format(expected_rows, big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nExpected panel rows: 526,750 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Current rows:\", format(nrow(trips_panel), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCurrent rows: 116,718 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Missing rows:\", format(expected_rows - nrow(trips_panel), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMissing rows: 410,032 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Create complete panel\nstudy_panel <- expand.grid(\n  interval60 = unique(trips_panel$interval60),\n  start_station = unique(trips_panel$start_station)\n) %>%\n  # Join trip counts\n  left_join(trips_panel, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Fill in station attributes (they're the same for all hours)\nstation_attributes <- trips_panel %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_panel <- study_panel %>%\n  left_join(station_attributes, by = \"start_station\")\n\n# Verify we have complete panel\ncat(\"Complete panel rows:\", format(nrow(study_panel), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nComplete panel rows: 526,750 \n```\n\n\n:::\n:::\n\n\n**Add Time Features**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n**Join Weather Data**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_panel <- study_panel %>%\n  left_join(weather_complete, by = \"interval60\")\n\n# Check for missing values\nsummary(study_panel %>% select(Trip_Count, Temperature, Precipitation))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Trip_Count       Temperature    Precipitation   \n Min.   : 0.0000   Min.   :10.00   Min.   :0.0000  \n 1st Qu.: 0.0000   1st Qu.:30.00   1st Qu.:0.0000  \n Median : 0.0000   Median :37.00   Median :0.0000  \n Mean   : 0.3585   Mean   :38.39   Mean   :0.0013  \n 3rd Qu.: 0.0000   3rd Qu.:46.00   3rd Qu.:0.0000  \n Max.   :26.0000   Max.   :78.00   Max.   :0.2800  \n                   NA's   :5880    NA's   :5880    \n```\n\n\n:::\n\n```{.r .cell-code}\nhead(study_panel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           interval60 start_station start_lat.x start_lon.x Med_Inc.x\n1 2025-01-01 00:00:00          3005    39.94733   -75.14403    144922\n2 2025-01-01 01:00:00          3005    39.94733   -75.14403    144922\n3 2025-01-01 02:00:00          3005          NA          NA        NA\n4 2025-01-01 03:00:00          3005    39.94733   -75.14403    144922\n5 2025-01-01 04:00:00          3005          NA          NA        NA\n6 2025-01-01 05:00:00          3005          NA          NA        NA\n  Percent_Taking_Transit.x Percent_White.x Total_Pop.x Trip_Count start_lat.y\n1                 11.74283         86.2964        3583          6    39.94733\n2                 11.74283         86.2964        3583          1    39.94733\n3                       NA              NA          NA          0    39.94733\n4                 11.74283         86.2964        3583          1    39.94733\n5                       NA              NA          NA          0    39.94733\n6                       NA              NA          NA          0    39.94733\n  start_lon.y Med_Inc.y Percent_Taking_Transit.y Percent_White.y Total_Pop.y\n1   -75.14403    144922                 11.74283         86.2964        3583\n2   -75.14403    144922                 11.74283         86.2964        3583\n3   -75.14403    144922                 11.74283         86.2964        3583\n4   -75.14403    144922                 11.74283         86.2964        3583\n5   -75.14403    144922                 11.74283         86.2964        3583\n6   -75.14403    144922                 11.74283         86.2964        3583\n  week month dotw hour       date weekend rush_hour Temperature Precipitation\n1    1   Jan  Wed    0 2025-01-01       0         0          50        0.0600\n2    1   Jan  Wed    1 2025-01-01       0         0          49        0.0001\n3    1   Jan  Wed    2 2025-01-01       0         0          52        0.0001\n4    1   Jan  Wed    3 2025-01-01       0         0          48        0.0001\n5    1   Jan  Wed    4 2025-01-01       0         0          48        0.0000\n6    1   Jan  Wed    5 2025-01-01       0         0          45        0.0000\n  Wind_Speed\n1          9\n2         10\n3          6\n4          8\n5          8\n6          9\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 5: Create Temporal Lag Variables\n\nTemporal Persistence: past demand predicts future demand\n\n### 5.1 \\| Create Temporal Lags\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sort by station and time\nstudy_panel <- study_panel %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_panel <- study_panel %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_panel_complete <- study_panel %>%\n  filter(!is.na(lag1day))\n\ncat(\"Rows after removing NA lags:\", format(nrow(study_panel_complete), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows after removing NA lags: 520,870 \n```\n\n\n:::\n:::\n\n\n### 5.2 \\| Visualize Lag Correlations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sample one station to visualize\nexample_station <- study_panel_complete %>%\n  filter(start_station == first(start_station)) %>%\n  head(168)  # One week\n\n# Plot actual vs lagged demand\nggplot(example_station, aes(x = interval60)) +\n  geom_line(aes(y = Trip_Count, color = \"Current\"), linewidth = 1) +\n  geom_line(aes(y = lag1Hour, color = \"1 Hour Ago\"), linewidth = 1, alpha = 0.7) +\n  geom_line(aes(y = lag1day, color = \"24 Hours Ago\"), linewidth = 1, alpha = 0.7) +\n  scale_color_manual(values = c(\n    \"Current\" = \"#08519c\",\n    \"1 Hour Ago\" = \"#3182bd\",\n    \"24 Hours Ago\" = \"#6baed6\"\n  )) +\n  labs(\n    title = \"Temporal Lag Patterns at One Station\",\n    subtitle = \"Past demand predicts future demand\",\n    x = \"Date-Time\",\n    y = \"Trip Count\",\n    color = \"Time Period\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 6: Temporal Train/Test Split\n\nApproach: Train on Past Data and Test on Future Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Split by week\n# Q1 has weeks 1-13 (Jan-Mar)\n# Train on weeks 1-9 (Jan 1 - early March)\n# Test on weeks 10-13 (rest of March)\n\n# Which stations have trips in BOTH early and late periods?\nearly_stations <- study_panel_complete %>%\n  filter(week < 10) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\nlate_stations <- study_panel_complete %>%\n  filter(week >= 10) %>%\n  filter(Trip_Count > 0) %>%\n  distinct(start_station) %>%\n  pull(start_station)\n\n# Keep only stations that appear in BOTH periods\ncommon_stations <- intersect(early_stations, late_stations)\n\n\n# Filter panel to only common stations\nstudy_panel_complete <- study_panel_complete %>%\n  filter(start_station %in% common_stations)\n\n# NOW create train/test split\ntrain <- study_panel_complete %>%\n  filter(week < 10)\n\ntest <- study_panel_complete %>%\n  filter(week >= 10)\n\ncat(\"Training observations:\", format(nrow(train), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining observations: 352,240 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing observations:\", format(nrow(test), big.mark = \",\"), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting observations: 153,748 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Training date range:\", min(train$date), \"to\", max(train$date), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining date range: 20090 to 20151 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Testing date range:\", min(test$date), \"to\", max(test$date), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTesting date range: 20152 to 20178 \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 7: Build 5 Predictive Models\n\nWe'll build 5 models with increasing complexity to see what improves predictions.\n\n### Model 1: Baseline (Time + Weather)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntrain <- train %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(train$dotw_simple) <- contr.treatment(7)\n\nmodel1 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation,\n  data = train\n)\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.9505 -0.4005 -0.1795  0.0221 18.5359 \n\nCoefficients:\n                    Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)       -0.1865881  0.0087166 -21.406 < 0.0000000000000002 ***\nas.factor(hour)1  -0.0254861  0.0087583  -2.910              0.00362 ** \nas.factor(hour)2  -0.0363902  0.0088009  -4.135  0.00003553166352764 ***\nas.factor(hour)3  -0.0525056  0.0087645  -5.991  0.00000000209104740 ***\nas.factor(hour)4  -0.0364554  0.0087381  -4.172  0.00003019750974031 ***\nas.factor(hour)5   0.0230901  0.0087069   2.652              0.00800 ** \nas.factor(hour)6   0.1744174  0.0087150  20.014 < 0.0000000000000002 ***\nas.factor(hour)7   0.3241655  0.0087182  37.183 < 0.0000000000000002 ***\nas.factor(hour)8   0.5499211  0.0087229  63.044 < 0.0000000000000002 ***\nas.factor(hour)9   0.3904427  0.0087209  44.771 < 0.0000000000000002 ***\nas.factor(hour)10  0.2810826  0.0087269  32.209 < 0.0000000000000002 ***\nas.factor(hour)11  0.2964398  0.0087321  33.948 < 0.0000000000000002 ***\nas.factor(hour)12  0.3676829  0.0087199  42.166 < 0.0000000000000002 ***\nas.factor(hour)13  0.3494810  0.0086973  40.183 < 0.0000000000000002 ***\nas.factor(hour)14  0.3519969  0.0086887  40.512 < 0.0000000000000002 ***\nas.factor(hour)15  0.4082093  0.0086904  46.972 < 0.0000000000000002 ***\nas.factor(hour)16  0.4901333  0.0086951  56.369 < 0.0000000000000002 ***\nas.factor(hour)17  0.6148350  0.0087059  70.623 < 0.0000000000000002 ***\nas.factor(hour)18  0.4245184  0.0087149  48.712 < 0.0000000000000002 ***\nas.factor(hour)19  0.2709915  0.0087215  31.072 < 0.0000000000000002 ***\nas.factor(hour)20  0.1498838  0.0087168  17.195 < 0.0000000000000002 ***\nas.factor(hour)21  0.0883229  0.0087071  10.144 < 0.0000000000000002 ***\nas.factor(hour)22  0.0688853  0.0086978   7.920  0.00000000000000239 ***\nas.factor(hour)23  0.0416985  0.0086883   4.799  0.00000159201720578 ***\ndotw_simple2       0.0534158  0.0046920  11.384 < 0.0000000000000002 ***\ndotw_simple3       0.0591069  0.0048452  12.199 < 0.0000000000000002 ***\ndotw_simple4       0.0329187  0.0046852   7.026  0.00000000000212695 ***\ndotw_simple5       0.0432028  0.0046773   9.237 < 0.0000000000000002 ***\ndotw_simple6      -0.0654894  0.0046757 -14.006 < 0.0000000000000002 ***\ndotw_simple7      -0.0629789  0.0047034 -13.390 < 0.0000000000000002 ***\nTemperature        0.0079845  0.0001544  51.702 < 0.0000000000000002 ***\nPrecipitation     -2.5026380  0.1914911 -13.069 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.746 on 352208 degrees of freedom\nMultiple R-squared:  0.07881,\tAdjusted R-squared:  0.07873 \nF-statistic:   972 on 31 and 352208 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\nThe model uses Monday as the baseline. Each coefficient represents the difference in expected trips per station-hour compared to Monday. For example, dow_simple2 = Tuesday.\n\n**Weekday Pattern (Tue-Fri):**\n\n-   All weekdays have positive coefficients (0.029 to 0.052)\n-   Tuesday has the highest weekday effect (+0.052)\n-   Weekdays likely benefit from concentrated commuting patterns\n\n**Weekend Pattern (Sat-Sun):**\n\n-   Both weekend days have negative coefficients (-0.061 and -0.065)\n-   This means fewer trips per station-hour than Monday\n\n### Model 2: Add Temporal Lags\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation + \n    lag1Hour + lag3Hours + lag1day,\n  data = train\n)\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + \n    Precipitation + lag1Hour + lag3Hours + lag1day, data = train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.8168 -0.2847 -0.1032  0.0169 17.7976 \n\nCoefficients:\n                    Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)       -0.0981452  0.0079807 -12.298 < 0.0000000000000002 ***\nas.factor(hour)1  -0.0073089  0.0080114  -0.912              0.36161    \nas.factor(hour)2  -0.0056704  0.0080509  -0.704              0.48124    \nas.factor(hour)3  -0.0098486  0.0080187  -1.228              0.21937    \nas.factor(hour)4   0.0073214  0.0079952   0.916              0.35981    \nas.factor(hour)5   0.0541355  0.0079676   6.794  0.00000000001088671 ***\nas.factor(hour)6   0.1598589  0.0079803  20.032 < 0.0000000000000002 ***\nas.factor(hour)7   0.2402233  0.0079951  30.046 < 0.0000000000000002 ***\nas.factor(hour)8   0.3755384  0.0080279  46.779 < 0.0000000000000002 ***\nas.factor(hour)9   0.1807415  0.0080254  22.521 < 0.0000000000000002 ***\nas.factor(hour)10  0.1188012  0.0080068  14.838 < 0.0000000000000002 ***\nas.factor(hour)11  0.1347784  0.0080231  16.799 < 0.0000000000000002 ***\nas.factor(hour)12  0.2042401  0.0080027  25.521 < 0.0000000000000002 ***\nas.factor(hour)13  0.1863749  0.0079803  23.354 < 0.0000000000000002 ***\nas.factor(hour)14  0.1933502  0.0079711  24.256 < 0.0000000000000002 ***\nas.factor(hour)15  0.2303877  0.0079791  28.874 < 0.0000000000000002 ***\nas.factor(hour)16  0.2798055  0.0079958  34.994 < 0.0000000000000002 ***\nas.factor(hour)17  0.3592389  0.0080276  44.750 < 0.0000000000000002 ***\nas.factor(hour)18  0.1723963  0.0080312  21.466 < 0.0000000000000002 ***\nas.factor(hour)19  0.0896528  0.0080112  11.191 < 0.0000000000000002 ***\nas.factor(hour)20  0.0154708  0.0080102   1.931              0.05344 .  \nas.factor(hour)21  0.0133420  0.0079787   1.672              0.09449 .  \nas.factor(hour)22  0.0257497  0.0079603   3.235              0.00122 ** \nas.factor(hour)23  0.0204881  0.0079476   2.578              0.00994 ** \ndotw_simple2       0.0203302  0.0042937   4.735  0.00000219283951014 ***\ndotw_simple3       0.0107868  0.0044368   2.431              0.01505 *  \ndotw_simple4      -0.0016960  0.0042891  -0.395              0.69254    \ndotw_simple5       0.0111818  0.0042805   2.612              0.00900 ** \ndotw_simple6      -0.0723041  0.0042858 -16.871 < 0.0000000000000002 ***\ndotw_simple7      -0.0433412  0.0043053 -10.067 < 0.0000000000000002 ***\nTemperature        0.0036893  0.0001423  25.920 < 0.0000000000000002 ***\nPrecipitation     -1.3733842  0.1752334  -7.837  0.00000000000000461 ***\nlag1Hour           0.2285048  0.0016338 139.865 < 0.0000000000000002 ***\nlag3Hours          0.0974819  0.0016053  60.726 < 0.0000000000000002 ***\nlag1day            0.2350577  0.0016168 145.387 < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6823 on 352205 degrees of freedom\nMultiple R-squared:  0.2293,\tAdjusted R-squared:  0.2292 \nF-statistic:  3082 on 34 and 352205 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n:::\n\n\n### Model 3: Add Demographics\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y,\n  data = train\n)\ncat(\"Model 3 R-squared:\", summary(model3)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 3 R-squared: 0.1548858 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 3 Adj R-squared:\", summary(model3)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 3 Adj R-squared: 0.1544508 \n```\n\n\n:::\n:::\n\n\n### Model 4: Add Station Fixed Effects\n\nStation fixed effects capture Baseline differences in demand across stations – some are just busier than others.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel4 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station),\n  data = train\n)\n\ncat(\"Model 4 R-squared:\", summary(model4)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 R-squared: 0.1793657 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 4 Adj R-squared:\", summary(model4)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 4 Adj R-squared: 0.1762624 \n```\n\n\n:::\n:::\n\n\n### Model 5: Add Rush Hour Interaction\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel5 <- lm(\n  Trip_Count ~ as.factor(hour) + dotw_simple + Temperature + Precipitation +\n    lag1Hour + lag3Hours + lag1day + rush_hour + as.factor(month) +\n    Med_Inc.x + Percent_Taking_Transit.y + Percent_White.y +\n    as.factor(start_station) +\n    rush_hour * weekend,  # Rush hour effects different on weekends\n  data = train\n)\n\ncat(\"Model 5 R-squared:\", summary(model5)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 R-squared: 0.1841495 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model 5 Adj R-squared:\", summary(model5)$adj.r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel 5 Adj R-squared: 0.18103 \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 8: Model Evaluation\n\n### 8.1 \\| Predictions on Test Setand MAE\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create day of week factor with treatment (dummy) coding\ntest <- test %>%\n  mutate(dotw_simple = factor(dotw, levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")))\n\n# Set contrasts to treatment coding (dummy variables)\ncontrasts(test$dotw_simple) <- contr.treatment(7)\n\ntest <- test %>%\n  mutate(\n    pred1 = predict(model1, newdata = test),\n    pred2 = predict(model2, newdata = test),\n    pred3 = predict(model3, newdata = test),\n    pred4 = predict(model4, newdata = test),\n    pred5 = predict(model5, newdata = test)\n  )\n\n# Calculate MAE for each model\nmae_results <- data.frame(\n  Model = c(\n    \"1. Time + Weather\",\n    \"2. + Temporal Lags\",\n    \"3. + Demographics\",\n    \"4. + Station FE\",\n    \"5. + Rush Hour Interaction\"\n  ),\n  MAE = c(\n    mean(abs(test$Trip_Count - test$pred1), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred3), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred4), na.rm = TRUE),\n    mean(abs(test$Trip_Count - test$pred5), na.rm = TRUE)\n  )\n)\n\nkable(mae_results, \n      digits = 2,\n      caption = \"Mean Absolute Error by Model (Test Set)\",\n      col.names = c(\"Model\", \"MAE (trips)\")) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Mean Absolute Error by Model (Test Set)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Model </th>\n   <th style=\"text-align:right;\"> MAE (trips) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1. Time + Weather </td>\n   <td style=\"text-align:right;\"> 0.62 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2. + Temporal Lags </td>\n   <td style=\"text-align:right;\"> 0.54 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3. + Demographics </td>\n   <td style=\"text-align:right;\"> 0.77 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4. + Station FE </td>\n   <td style=\"text-align:right;\"> 0.76 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5. + Rush Hour Interaction </td>\n   <td style=\"text-align:right;\"> 0.75 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### 8.2 \\| Visualize Model Comparison\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mae_results, aes(x = reorder(Model, -MAE), y = MAE)) +\n  geom_col(fill = \"#3182bd\", alpha = 0.8) +\n  geom_text(aes(label = round(MAE, 2)), vjust = -0.5) +\n  labs(\n    title = \"Model Performance Comparison\",\n    subtitle = \"Lower MAE = Better Predictions\",\n    x = \"Model\",\n    y = \"Mean Absolute Error (trips)\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 9: Space-Time Error Analysis using Best Model\n\nWe conduct space-time error analysis using Model 2 which has the lowest MAE for Q1 2025 data.\n\n### 9.1 \\| Observed vs Predicted\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- test %>%\n  mutate(\n    error = Trip_Count - pred2,\n    abs_error = abs(error),\n    time_of_day = case_when(\n      hour < 7 ~ \"Overnight\",\n      hour >= 7 & hour < 10 ~ \"AM Rush\",\n      hour >= 10 & hour < 15 ~ \"Mid-Day\",\n      hour >= 15 & hour <= 18 ~ \"PM Rush\",\n      hour > 18 ~ \"Evening\"\n    )\n  )\n\n# Scatter plot by time and day type\nggplot(test, aes(x = Trip_Count, y = pred2)) +\n  geom_point(alpha = 0.2, color = \"#3182bd\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linewidth = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"darkgreen\") +\n  facet_grid(weekend ~ time_of_day) +\n  labs(\n    title = \"Observed vs. Predicted Bike Trips\",\n    subtitle = \"Model 2 performance by time period\",\n    x = \"Observed Trips\",\n    y = \"Predicted Trips\",\n    caption = \"Red line = perfect predictions; Green line = actual model fit\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/obs-vs-pred-1.png){width=672}\n:::\n:::\n\n\n### 9.2 \\| Spatial Error Patterns\n\n-   Create error maps\n-   Identify neighborhoods with high errors\n-   Hypothesize why (missing features? different demand patterns?)\n\n**Calculate MAE by Station**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate MAE by station\nstation_errors <- test %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n\n## Create Two Maps Side-by-Side with Proper Legends (sorry these maps are ugly)\n\n# Calculate station errors\nstation_errors <- test %>%\n  filter(!is.na(pred2)) %>%\n  group_by(start_station, start_lat.x, start_lon.y) %>%\n  summarize(\n    MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),\n    avg_demand = mean(Trip_Count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  filter(!is.na(start_lat.x), !is.na(start_lon.y))\n```\n:::\n\n\n**Visualize**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Map 1: Prediction Errors\np1 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = MAE),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"plasma\",\n    name = \"MAE\\n(trips)\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5),  # Fewer, cleaner breaks\n    labels = c(\"0.5\", \"1.0\", \"1.5\")\n  ) +\n  labs(title = \"Prediction Errors\",\n       subtitle = \"Higher in Center City\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 1.5,\n    barheight = 12,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Map 2: Average Demand\np2 <- ggplot() +\n  geom_sf(data = philly_census, fill = \"grey95\", color = \"white\", size = 0.2) +\n  geom_point(\n    data = station_errors,\n    aes(x = start_lon.y, y = start_lat.x, color = avg_demand),\n    size = 3.5,\n    alpha = 0.7\n  ) +\n  scale_color_viridis(\n    option = \"viridis\",\n    name = \"Avg\\nDemand\",\n    direction = -1,\n    breaks = c(0.5, 1.0, 1.5, 2.0, 2.5),  # Clear breaks\n    labels = c(\"0.5\", \"1.0\", \"1.5\", \"2.0\", \"2.5\")\n  ) +\n  labs(title = \"Average Demand\",\n       subtitle = \"Trips per station-hour\") +\n  mapTheme +\n  theme(\n    legend.position = \"right\",\n    legend.title = element_text(size = 10, face = \"bold\"),\n    legend.text = element_text(size = 9),\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 10)\n  ) +\n  guides(color = guide_colorbar(\n    barwidth = 1.5,\n    barheight = 12,\n    title.position = \"top\",\n    title.hjust = 0.5\n  ))\n\n# Combine\ngrid.arrange(\n  p1, p2,\n  ncol = 2\n  )\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\np1\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-18-2.png){width=672}\n:::\n:::\n\n\n### 9.3 \\| Temporal Error Patterns\n\n-   When are errors highest?\n-   Do certain hours/days have systematic under/over-prediction?\n-   Are there seasonal patterns?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MAE by time of day and day type\ntemporal_errors <- test %>%\n  group_by(time_of_day, weekend) %>%\n  summarize(\n    MAE = mean(abs_error, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %>%\n  mutate(day_type = ifelse(weekend == 1, \"Weekend\", \"Weekday\"))\n\nggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"Weekday\" = \"#08519c\", \"Weekend\" = \"#6baed6\")) +\n  labs(\n    title = \"Prediction Errors by Time Period\",\n    subtitle = \"When is the model struggling most?\",\n    x = \"Time of Day\",\n    y = \"Mean Absolute Error (trips)\",\n    fill = \"Day Type\"\n  ) +\n  plotTheme +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/temporal-errors-1.png){width=672}\n:::\n:::\n\n\n### 9.4 \\| Demographic Patterns\n\n-   Relate errors to census characteristics\n-   Are certain communities systematically harder to predict?\n-   What are the equity implications?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join demographic data to station errors\nstation_errors_demo <- station_errors %>%\n  left_join(\n    station_attributes %>% select(start_station, Med_Inc, Percent_Taking_Transit, Percent_White),\n    by = \"start_station\"\n  ) %>%\n  filter(!is.na(Med_Inc))\n\n# Create plots\np1 <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Errors vs. Median Income\", x = \"Median Income\", y = \"MAE\") +\n  plotTheme\n\np2 <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Transit Usage\", x = \"% Taking Transit\", y = \"MAE\") +\n  plotTheme\n\np3 <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +\n  geom_point(alpha = 0.5, color = \"#3182bd\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Errors vs. Race\", x = \"% White\", y = \"MAE\") +\n  plotTheme\n\ngrid.arrange(p1, p2, p3, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/demographic-errors-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 10: Replicate with Q2 2025\n\n1.  **Download data** from: <https://www.rideindego.com/about/data/>\n2.  **Adapt this code** to work with your quarter:\n    -   Update date ranges for weather data\n    -   Check for any data structure changes\n    -   Create the same 5 models\n    -   Calculate MAE for each model\n3.  **Compare results** to Q1 2025:\n    -   How do MAE values compare? Why might they differ?\n    -   Are temporal patterns different (e.g., summer vs. winter)?\n    -   Which features are most important in your quarter?\n\n### Data Cleaning/Wrangling for Q2 2025\n\n**Create Time Bins**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindego_q2 <- indego_q2 %>%\n  mutate(\n    # Parse datetime\n    start_datetime = mdy_hm(start_time),\n    end_datetime = mdy_hm(end_time),\n    \n    # Create hourly bins\n    interval60 = floor_date(start_datetime, unit = \"hour\"),\n    \n    # Extract time features\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    \n    # Create useful indicators\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n**Daily Trip Counts**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaily_trips <- indego_q2 %>%\n  group_by(date) %>%\n  summarize(trips = n())\n\nggplot(daily_trips, aes(x = date, y = trips)) +\n  geom_line(color = \"#3182bd\", linewidth = 1) +\n  geom_smooth(se = FALSE, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Indego Daily Ridership - Q2 2025\",\n    subtitle = \"Spring demand patterns in Philadelphia\",\n    x = \"Date\",\n    y = \"Daily Trips\",\n    caption = \"Source: Indego bike share\"\n  ) +\n  plotTheme\n```\n\n::: {.cell-output-display}\n![](assignment5_template_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n**Filter out Non-Residential Bike Share Stations**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter trip data to valid stations only\nindego_q2_census <- indego_q2 %>%\n  filter(start_station %in% valid_stations) %>%\n  left_join(\n    stations_census %>% \n      select(start_station, Med_Inc, Percent_Taking_Transit, \n             Percent_White, Total_Pop),\n    by = \"start_station\"\n  )\n```\n:::\n\n\n### Space-Time Panel\n\n**Aggregate Trips to Station-Hour Level**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrips_q2_panel <- indego_q2_census %>%\n  group_by(interval60, start_station, start_lat, start_lon,\n           Med_Inc, Percent_Taking_Transit, Percent_White, Total_Pop) %>%\n  summarize(Trip_Count = n()) %>%\n  ungroup()\n```\n:::\n\n\n**Create Complete Panel**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_q2_panel <- expand.grid(\n  interval60 = unique(trips_q2_panel$interval60),\n  start_station = unique(trips_q2_panel$start_station)\n) %>%\n  # Join trip counts\n  left_join(trips_q2_panel, by = c(\"interval60\", \"start_station\")) %>%\n  # Replace NA trip counts with 0\n  mutate(Trip_Count = replace_na(Trip_Count, 0))\n\n# Fill in station attributes (they're the same for all hours)\nstation_q2_attributes <- trips_q2_panel %>%\n  group_by(start_station) %>%\n  summarize(\n    start_lat = first(start_lat),\n    start_lon = first(start_lon),\n    Med_Inc = first(Med_Inc),\n    Percent_Taking_Transit = first(Percent_Taking_Transit),\n    Percent_White = first(Percent_White),\n    Total_Pop = first(Total_Pop)\n  )\n\nstudy_q2_panel <- study_q2_panel %>%\n  left_join(station_q2_attributes, by = \"start_station\")\n```\n:::\n\n\n**Add Time Features**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_q2_panel <- study_q2_panel %>%\n  mutate(\n    week = week(interval60),\n    month = month(interval60, label = TRUE),\n    dotw = wday(interval60, label = TRUE),\n    hour = hour(interval60),\n    date = as.Date(interval60),\n    weekend = ifelse(dotw %in% c(\"Sat\", \"Sun\"), 1, 0),\n    rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0)\n  )\n```\n:::\n\n\n**Join Weather Data**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_q2_panel <- study_q2_panel %>%\n  left_join(weather_q2, by = \"interval60\")\nsummary(study_q2_panel %>% select(Trip_Count, Temperature, Precipitation))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Trip_Count       Temperature     Precipitation  \n Min.   : 0.0000   Min.   : 33.00   Min.   :0.000  \n 1st Qu.: 0.0000   1st Qu.: 57.00   1st Qu.:0.000  \n Median : 0.0000   Median : 66.00   Median :0.000  \n Mean   : 0.6418   Mean   : 65.64   Mean   :0.002  \n 3rd Qu.: 1.0000   3rd Qu.: 74.00   3rd Qu.:0.000  \n Max.   :27.0000   Max.   :100.00   Max.   :0.590  \n                   NA's   :6075     NA's   :6075   \n```\n\n\n:::\n:::\n\n\n### Create Temporal Lag Variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy_q2 <- study_q2_panel %>%\n  arrange(start_station, interval60)\n\n# Create lag variables WITHIN each station\nstudy_q2 <- study_q2 %>%\n  group_by(start_station) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),\n    lag2Hours = lag(Trip_Count, 2),\n    lag3Hours = lag(Trip_Count, 3),\n    lag12Hours = lag(Trip_Count, 12),\n    lag1day = lag(Trip_Count, 24)\n  ) %>%\n  ungroup()\n\n# Remove rows with NA lags (first 24 hours for each station)\nstudy_q2_complete <- study_q2 %>%\n  filter(!is.na(lag1day))\n```\n:::\n\n\n### Temporal Train/Test Split\n\n### Build 5 Predictive Models\n\n------------------------------------------------------------------------\n\n## Part 11: Error Analysis for Q2 2025 vs Q1 2025\n\n\n::: {.cell}\n\n:::\n\n\n------------------------------------------------------------------------\n\n## Part 12: Feature Engineering & model improvement\n\nBased on your error analysis, add 2-3 NEW features to improve the model:\n\n**Potential features to consider:**\n\n*Temporal features:*\n\n-   Holiday indicators (Memorial Day, July 4th, Labor Day)\n-   School calendar (Penn, Drexel, Temple in session?)\n-   Special events (concerts, sports games, conventions)\n-   Day of month (payday effects?)\n\n*Weather features:*\n\n-   Feels-like temperature (wind chill/heat index)\n-   \"Perfect biking weather\" indicator (60-75°F, no rain)\n-   Precipitation forecast (not just current)\n-   Weekend + nice weather interaction\n\n*Spatial features:*\n\n-   Distance to Center City\n-   Distance to nearest university\n-   Distance to nearest park\n-   Points of interest nearby (restaurants, offices, bars)\n-   Station capacity\n-   Bike lane connectivity\n\n*Trip history features:*\n\n-   Rolling 7-day average demand\n-   Same hour last week\n-   Station \"type\" clustering (residential, commercial, tourist)\n\n**Implementation:**\n\n-   Add your features to the best model\n-   Compare MAE before and after\n-   Explain *why* you chose these features\n-   Did they improve predictions? Where?\n\n**Try a poisson model for count data**\n\n-   Does this improve model fit?\n\n------------------------------------------------------------------------\n\n## Conclusion: Critical Reflection\n\nWrite 1-2 paragraphs addressing:\n\n1.  **Operational implications:**\n    -   Is your final MAE \"good enough\" for Indego to use?\n    -   When do prediction errors cause problems for rebalancing?\n    -   Would you recommend deploying this system? Under what conditions?\n2.  **Equity considerations:**\n    -   Do prediction errors disproportionately affect certain neighborhoods?\n    -   Could this system worsen existing disparities in bike access?\n    -   What safeguards would you recommend?\n3.  **Model limitations:**\n    -   What patterns is your model missing?\n    -   What assumptions might not hold in real deployment?\n    -   How would you improve this with more time/data?\n\n------------------------------------------------------------------------\n\n### Brief report summarizing (with supporting data & visualization):\n\n-   Your quarter and why you chose it\n-   Model comparison results\n-   Error analysis insights\n-   New features you added and why\n-   Critical reflection on deployment\n",
    "supporting": [
      "assignment5_template_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}