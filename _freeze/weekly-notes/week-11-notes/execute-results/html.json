{
  "hash": "918b94fb96f36a347044a1a925b2c7f1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 11 Notes - Space Time Prediction\"\ndate: \"2025-11-17\"\n---\n\n## Key Concepts Learned\n\n### Understanding Panel Data\n\n-   Panel structure lets us capture BOTH station differences AND time patterns. Each row = station-hour observation with features and outcome\n-   Station-specific baselines:\n    -   Station A (downtown): High demand during work hours\n\n    -   Station B (residential): High demand mornings/evenings\n\n    -   Station C (tourist area): High demand weekends Time-based patterns: Rush hour peaks Weekend vs. weekday differences Weather effects Holiday impacts\n\n![](images/clipboard-2036303385.png)\n\n### Temporal Validation\n\n![](images/clipboard-27451662.png)\n\n### Model Progression Strategy\n\n1.  Baseline: Time + Weather only\n2.  \\+ Temporal lags: Add lag1Hour, lag1day\n3.  \\+ Spatial features: Add demographics, location\n4.  \\+ Station fixed effects: Control for station-specific baselines\n5.  \\+ Holiday effects: Account for Memorial Day weekend\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel5 <- lm(\n  Trip_Count ~ hour + dotw + Temperature + Precipitation + #1: time + weather\n               lag1Hour + lag3Hours + lag1day +            #2: temporal lag\n               Med_Inc + Percent_Taking_Public_Trans +     #3: spatial features\n               Percent_White + \n               as.factor(from_station_id) +                #4: stn fixed effect\n               holiday + holiday_lag1 + holiday_lag2,      #5: holiday indicator\n  data = train\n)\n```\n:::\n\n\n### Space-Time Error Analysis\n\n-   High MAE at high-volume stations might be acceptable\n-   High MAE at low-volume stations might indicate systematic bias\n-   Spatial patterns in errors suggest missing features\n-   Temporal patterns suggest missing time dynamics\n\n**Common Error Patterns**\n\n-   **Underpredicting peaks:** Missing high-demand periods (rush hour)\n-   **Weekend vs. weekday differences:** Holiday patterns not fully captured\n-   **Spatial clustering:** Errors concentrated in certain neighborhoods\n    -   Waterfront (leisure rides?)\n    -   Downtown (tourist activity?)\n    -   Transit hubs (commuter substitution?)\n-   **Critical question:** Are errors related to demographics? (Equity concern!)\n\n------------------------------------------------------------------------\n\n## Coding Techniques\n\n-   **Binning Data into Time Intervals**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Hourly Binning\ndat60 <- dat %>%\n  mutate(interval60 = floor_date(ymd_hms(start_time), unit = \"hour\"))\ndat15 <- dat %>%\n  mutate(interval15 = floor_date(ymd_hms(start_time), unit = \"15 mins\"))\n\n# Extracting Time Features\ndat60 <- dat %>%\n  mutate(\n    interval60 = floor_date(ymd_hms(start_time), unit = \"hour\"),\n    week = week(interval60),             # Week of year (1-52)\n    dotw = wday(interval60, label=TRUE), # Day of week (Mon, Tue, ...)\n    hour = hour(interval60)              # Hour of day (0-23)\n  )\n```\n:::\n\n\n-   **Temporal Lags**\n    -   Note: lags are calculated *within* each station; model will learn which lags are most predictive for each station/time combination\n        -   lag1Hour: Short-term persistence (smooth demand changes)\n\n        -   lag3Hours: Medium-term trends (morning rush building)\n\n        -   lag12Hours: Half-day cycle (AM vs. PM patterns)\n\n        -   lag1day (24 hours): Daily periodicity (same time yesterday)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstudy.panel <- study.panel %>%\n  arrange(from_station_id, interval60) %>%  # Sort by station, then time\n  group_by(from_station_id) %>%\n  mutate(\n    lag1Hour = lag(Trip_Count, 1),    # Previous hour\n    lag2Hours = lag(Trip_Count, 2),   # 2 hours ago\n    lag3Hours = lag(Trip_Count, 3),   # 3 hours ago\n    lag12Hours = lag(Trip_Count, 12), # 12 hours ago\n    lag1day = lag(Trip_Count, 24)     # Yesterday same time\n  ) %>%\n  ungroup()\n```\n:::\n\n\n-   **Creating a Complete Space-Time Panel**\n    -   Not every station has trips every hour; lag calculations break if rows are missing\n\n    -   use expand.grid() to create all combinations of the supplied vectors – it essentially build a full grid (a Carteisan product) of every possible pairing\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create every possible station-hour combination\nstudy.panel <- expand.grid(\n  interval60 = unique(dat_census$interval60),\n  from_station_id = unique(dat_census$from_station_id)\n)\n\n# Join to actual trip counts\nstudy.panel <- study.panel %>%\n  left_join(\n    dat_census %>% \n      group_by(interval60, from_station_id) %>%\n      summarize(Trip_Count = n()),\n    by = c(\"interval60\", \"from_station_id\")\n  ) %>%\n  mutate(Trip_Count = replace_na(Trip_Count, 0))  # Fill missing with 0\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Joining Station Attributes\nstation_data <- dat_census %>%\n  group_by(from_station_id) %>%\n  summarize(\n    from_latitude = first(from_latitude),\n    from_longitude = first(from_longitude),\n    Med_Inc = first(Med_Inc),\n    Percent_White = first(Percent_White),\n    # ... other demographics\n  )\n\n# Join to panel\nstudy.panel <- study.panel %>%\n  left_join(station_data, by = \"from_station_id\")\n```\n:::\n\n\n-   **Errors and Demographics**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join errors back to demographic data\nstation_errors <- station_errors %>%\n  left_join(\n    dat_census %>% \n      distinct(from_station_id, Med_Inc, \n               Percent_Taking_Public_Trans, Percent_White),\n    by = \"from_station_id\"\n  )\n\n# Plot relationships\nstation_errors %>%\n  pivot_longer(cols = c(Med_Inc, Percent_Taking_Public_Trans, \n                        Percent_White),\n               names_to = \"variable\", values_to = \"value\") %>%\n  ggplot(aes(x = value, y = MAE)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~variable, scales = \"free_x\")\n```\n:::\n\n\n## Next Steps to Improve\n\n1.  **More temporal features:**\n    -   Precipitation *forecast* (not just current)\n    -   Event calendars (concerts, sports games)\n    -   School schedules\n2.  **More spatial features:**\n    -   Points of interest (offices, restaurants, parks)\n    -   Transit service frequency\n    -   Bike lane connectivity\n3.  **Better model specification:**\n    -   Interactions (e.g., `weekend * hour`)\n\n    -   Non-linear effects (splines for time of day)\n\n    -   Different models for different station types\n\n## Connections to Policy (Bike Rebalancing System)\n\n1.  **Prediction accuracy matters most at high-volume stations**\n    -   Running out of bikes downtown causes more complaints\n    -   But: Is this equitable?\n2.  **Temporal patterns reveal operational windows**\n    -   Rebalance during overnight hours (low demand)\n    -   Pre-position bikes before AM rush\n3.  **Spatial patterns suggest infrastructure gaps**\n    -   Persistent errors in certain neighborhoods\n\n    -   Maybe add more stations? Increase capacity?\n\n**Other Applications for Panel Data**\n\n-   Transportation: Transit ridership over time\n-   Public safety: Crime patterns by beat over months\n-   Housing: Rent changes in neighborhoods over years\n-   Health: Disease incidence by zip code over weeks\n-   Education: School performance over academic years\n-   Environment: Air quality at monitoring sites over days\n\n## Reflection/Further Reading – Citi Bike Rebalancing\n\n<https://c4sr.columbia.edu/projects/citibike-rebalancing-study>:\n\n-   Imbalance Matrices by hour of day for every single station & Imbalance Hotspots\n\n![](images/clipboard-69962528.png)\n\n![](images/clipboard-4237440262.png)\n\n-   <https://people.orie.cornell.edu/shane/pubs/BSOvernight.pdf>\n\nAbstract: \"As bike-share systems expand in urban areas, the wealth of publicly available data has drawn researchers to address the novel operational challenges” these systems face. One key challenge is to meet user demand for available bikes and docks by rebalancing the system. This chapter reports on a collaborative effort with Citi Bike to develop and implement real data-driven optimization to guide their rebalancing efforts. In particular, we provide new models to guide truck routing for overnight rebalancing and new optimization problems for other non-motorized rebalancing efforts during the day. Finally, we evaluate how our practical methods have impacted rebalancing in New York City.\"\n\n-   <https://nycdatascience.com/blog/student-works/citi-bike-rebalancing-operations/> \\| <https://goutam.io/projects/predicting-citi-bike-trip-demand/> \\| \\\n    <https://docs.google.com/presentation/d/1hLECuh326kjMFXcSYRieEquXj7Ms78OUbU8vR350Tzs/edit?slide=id.g120f23f450c_0_62#slide=id.g120f23f450c_0_62>\n\nPrediction Timescale: \"Weekly resolution is far too sparse to capture meaningful relationships. Therefore, we would like to build models that predict at the Hourly timescale if we can, and if not, then use the Daily timescale. At the sub hourly timescale, the data became too unwieldy and noisy for a years worth, let alone for the many years of data Citi Bike has available. However in future extensions of this project we would like to take a second level resolution for one week for one station and predict the ridership at that level.\"\n\nWeather Data:\n\n![](images/clipboard-2353138133.png){width=\"452\"}\n\nModels Used: \"We attempted two models, the first of our models is the traditional SARIMA model, the second was a Long Short-Term Memory Recurrent Neural Network (LSTM-RNN RNN Recurrent Neural Network: This is a type of Artificial Neural Network that can also update all of its weights through time. RNN's are extremely powerful techniques that can allow for short-term memory to be introduced into the model. ). In this, we further distinguish the models by the time resolution, and whether or not the model was including weather data (i.e. had multidimensional inputs).\"\n\nIdentifying Rebalance Movements: \"The easiest method for a given bike is to compare the starting station for each trip with the ending station of the previous trip. If the bike appears to have teleported from one station to another between trips, it most likely was rebalanced!\"\n\n![](images/clipboard-1302163798.png)\n\n-   <https://www.nytimes.com/2024/09/19/nyregion/citi-bike-scam-nyc.html>\n\nTo fix the imbalance, Citi Bike uses various tactics to move bikes to in-demand stations. One involves hiring workers to drive panel trucks around the city, delivering bikes where they’re needed.\n\nAnother, created in 2016, is a program called Bike Angels, in which Citi Bike users move bikes in exchange for points that could be cashed in for swag like water bottles and backpacks, membership discounts and gift cards. Lyft pays 20 cents per point. Each ride generates a maximum of 24 points.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}